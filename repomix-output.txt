This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
VoiceInk/
  Assets.xcassets/
    AccentColor.colorset/
      Contents.json
    AppIcon.appiconset/
      Contents.json
    menuBarIcon.imageset/
      Contents.json
    Contents.json
  Models/
    CustomPrompt.swift
    PowerModeConfig.swift
    PredefinedModels.swift
    PredefinedPrompts.swift
    PromptTemplates.swift
    Transcription.swift
  Preview Content/
    Preview Assets.xcassets/
      Contents.json
  Resources/
    arcURL.scpt
    braveURL.scpt
    chromeURL.scpt
    edgeURL.scpt
    firefoxURL.scpt
    operaURL.scpt
    orionURL.scpt
    safariURL.scpt
    vivaldiURL.scpt
    zenURL.scpt
  Services/
    ActiveWindowService.swift
    AIEnhancementService.swift
    AIPrompts.swift
    AIService.swift
    AudioDeviceConfiguration.swift
    AudioDeviceManager.swift
    AudioProcessor.swift
    AudioTranscriptionManager.swift
    AudioTranscriptionService.swift
    BrowserURLService.swift
    OllamaService.swift
    PolarService.swift
    ScreenCaptureService.swift
    UserDefaultsManager.swift
    WordReplacementService.swift
  ViewModels/
    LicenseViewModel.swift
  Views/
    Components/
      ProBadge.swift
      TrialMessageView.swift
      VideoCTAView.swift
    Dictionary/
      DictionarySettingsView.swift
      DictionaryView.swift
      WordReplacementView.swift
    Metrics/
      AppIconView.swift
      MetricCard.swift
      MetricsContent.swift
      MetricsSetupView.swift
      TimeEfficiencyView.swift
    Onboarding/
      OnboardingModelDownloadView.swift
      OnboardingPermissionsView.swift
      OnboardingTutorialView.swift
      OnboardingView.swift
    Settings/
      AudioCleanupManager.swift
      AudioCleanupSettingsView.swift
      AudioInputSettingsView.swift
      SettingsView.swift
    AboutView.swift
    APIKeyManagementView.swift
    AudioPlayerView.swift
    AudioTranscribeView.swift
    ContentView.swift
    EnhancementSettingsView.swift
    KeyboardShortcutView.swift
    LanguageSelectionView.swift
    LicenseManagementView.swift
    LicenseView.swift
    MenuBarView.swift
    MetricsView.swift
    MiniRecorderPanel.swift
    MiniRecorderView.swift
    MiniWindowManager.swift
    ModelManagementView.swift
    NotchRecorderPanel.swift
    NotchRecorderView.swift
    NotchShape.swift
    NotchWindowManager.swift
    PermissionsView.swift
    PowerModeView.swift
    PowerModeViewComponents.swift
    PromptEditorView.swift
    RecordView.swift
    TranscriptionCard.swift
    TranscriptionHistoryView.swift
  Whisper/
    LibWhisper.swift
    WhisperError.swift
    WhisperPrompt.swift
    WhisperState.swift
  AppDelegate.swift
  ClipboardManager.swift
  CursorPaster.swift
  HotkeyManager.swift
  Info.plist
  MediaController.swift
  MenuBarManager.swift
  Recorder.swift
  repomix.config.json
  SoundManager.swift
  VisualizerView.swift
  VoiceInk.entitlements
  VoiceInk.swift
  WindowManager.swift
VoiceInk.xcodeproj/
  project.xcworkspace/
    xcshareddata/
      swiftpm/
        Package.resolved
      IDEWorkspaceChecks.plist
    contents.xcworkspacedata
  project.pbxproj
VoiceInkTests/
  VoiceInkTests.swift
VoiceInkUITests/
  VoiceInkUITests.swift
  VoiceInkUITestsLaunchTests.swift
.gitignore
appcast.xml
BUILDING.md
CODE_OF_CONDUCT.md
CONTRIBUTING.md
LICENSE
README.md

================================================================
Files
================================================================

================
File: VoiceInk/Assets.xcassets/AccentColor.colorset/Contents.json
================
{
  "colors" : [
    {
      "idiom" : "universal"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: VoiceInk/Assets.xcassets/AppIcon.appiconset/Contents.json
================
{"images":[{"size":"1024x1024","filename":"1024-mac.png","expected-size":"1024","idiom":"ios-marketing","folder":"Assets.xcassets/AppIcon.appiconset/","scale":"1x"},{"size":"128x128","expected-size":"128","filename":"128-mac.png","folder":"Assets.xcassets/AppIcon.appiconset/","idiom":"mac","scale":"1x"},{"size":"256x256","expected-size":"256","filename":"256-mac.png","folder":"Assets.xcassets/AppIcon.appiconset/","idiom":"mac","scale":"1x"},{"size":"128x128","expected-size":"256","filename":"256-mac.png","folder":"Assets.xcassets/AppIcon.appiconset/","idiom":"mac","scale":"2x"},{"size":"256x256","expected-size":"512","filename":"512-mac.png","folder":"Assets.xcassets/AppIcon.appiconset/","idiom":"mac","scale":"2x"},{"size":"32x32","expected-size":"32","filename":"32-mac.png","folder":"Assets.xcassets/AppIcon.appiconset/","idiom":"mac","scale":"1x"},{"size":"512x512","expected-size":"512","filename":"512-mac.png","folder":"Assets.xcassets/AppIcon.appiconset/","idiom":"mac","scale":"1x"},{"size":"16x16","expected-size":"16","filename":"16-mac.png","folder":"Assets.xcassets/AppIcon.appiconset/","idiom":"mac","scale":"1x"},{"size":"16x16","expected-size":"32","filename":"32-mac.png","folder":"Assets.xcassets/AppIcon.appiconset/","idiom":"mac","scale":"2x"},{"size":"32x32","expected-size":"64","filename":"64-mac.png","folder":"Assets.xcassets/AppIcon.appiconset/","idiom":"mac","scale":"2x"},{"size":"512x512","expected-size":"1024","filename":"1024-mac.png","folder":"Assets.xcassets/AppIcon.appiconset/","idiom":"mac","scale":"2x"}]}

================
File: VoiceInk/Assets.xcassets/menuBarIcon.imageset/Contents.json
================
{
  "images" : [
    {
      "filename" : "Frame 1.png",
      "idiom" : "universal"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  },
  "properties" : {
    "template-rendering-intent" : "template"
  }
}

================
File: VoiceInk/Assets.xcassets/Contents.json
================
{
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: VoiceInk/Models/CustomPrompt.swift
================
import Foundation

enum PromptIcon: String, Codable, CaseIterable {
    // Document & Text
    case documentFill = "doc.text.fill"
    case textbox = "textbox"
    case sealedFill = "checkmark.seal.fill"
    
    // Communication
    case chatFill = "bubble.left.and.bubble.right.fill"
    case messageFill = "message.fill"
    case emailFill = "envelope.fill"
    
    // Professional
    case meetingFill = "person.2.fill"
    case presentationFill = "person.wave.2.fill"
    case briefcaseFill = "briefcase.fill"
    
    // Technical
    case codeFill = "chevron.left.forwardslash.chevron.right.fill"
    case terminalFill = "terminal.fill"
    case gearFill = "gearshape.fill"
    
    // Content
    case blogFill = "doc.text.image.fill"
    case notesFill = "note.text"
    case bookFill = "book.fill"
    case bookmarkFill = "bookmark.fill"
    case pencilFill = "pencil.circle.fill"
    
    // Media & Creative
    case videoFill = "video.fill"
    case micFill = "mic.fill"
    case musicFill = "music.note.list"
    case photoFill = "photo.fill"
    case brushFill = "paintbrush.fill"
    
    var title: String {
        switch self {
        // Document & Text
        case .documentFill: return "Document"
        case .textbox: return "Textbox"
        case .sealedFill: return "Sealed"
            
        // Communication
        case .chatFill: return "Chat"
        case .messageFill: return "Message"
        case .emailFill: return "Email"
            
        // Professional
        case .meetingFill: return "Meeting"
        case .presentationFill: return "Presentation"
        case .briefcaseFill: return "Briefcase"
            
        // Technical
        case .codeFill: return "Code"
        case .terminalFill: return "Terminal"
        case .gearFill: return "Settings"
            
        // Content
        case .blogFill: return "Blog"
        case .notesFill: return "Notes"
        case .bookFill: return "Book"
        case .bookmarkFill: return "Bookmark"
        case .pencilFill: return "Edit"
            
        // Media & Creative
        case .videoFill: return "Video"
        case .micFill: return "Audio"
        case .musicFill: return "Music"
        case .photoFill: return "Photo"
        case .brushFill: return "Design"
        }
    }
}

struct CustomPrompt: Identifiable, Codable, Equatable {
    let id: UUID
    let title: String
    let promptText: String
    var isActive: Bool
    let icon: PromptIcon
    let description: String?
    let isPredefined: Bool
    
    init(
        id: UUID = UUID(),
        title: String,
        promptText: String,
        isActive: Bool = false,
        icon: PromptIcon = .documentFill,
        description: String? = nil,
        isPredefined: Bool = false
    ) {
        self.id = id
        self.title = title
        self.promptText = promptText
        self.isActive = isActive
        self.icon = icon
        self.description = description
        self.isPredefined = isPredefined
    }
}

================
File: VoiceInk/Models/PowerModeConfig.swift
================
import Foundation

struct PowerModeConfig: Codable, Identifiable, Equatable {
    var id: String { bundleIdentifier }
    let bundleIdentifier: String
    var appName: String
    var isAIEnhancementEnabled: Bool
    var selectedPrompt: String? // UUID string of the selected prompt
    var urlConfigs: [URLConfig]? // Optional URL configurations
    
    static func == (lhs: PowerModeConfig, rhs: PowerModeConfig) -> Bool {
        lhs.bundleIdentifier == rhs.bundleIdentifier
    }
}

// Simple URL configuration
struct URLConfig: Codable, Identifiable, Equatable {
    let id: UUID
    var url: String // Simple URL like "google.com"
    var promptId: String? // UUID string of the selected prompt for this URL
    
    init(url: String, promptId: String? = nil) {
        self.id = UUID()
        self.url = url
        self.promptId = promptId
    }
}

class PowerModeManager: ObservableObject {
    static let shared = PowerModeManager()
    @Published var configurations: [PowerModeConfig] = []
    @Published var defaultConfig: PowerModeConfig
    @Published var isPowerModeEnabled: Bool
    
    private let configKey = "powerModeConfigurations"
    private let defaultConfigKey = "defaultPowerModeConfig"
    private let powerModeEnabledKey = "isPowerModeEnabled"
    
    private init() {
        // Load power mode enabled state
        self.isPowerModeEnabled = UserDefaults.standard.bool(forKey: powerModeEnabledKey)
        
        // Initialize default config with default values
        if let data = UserDefaults.standard.data(forKey: defaultConfigKey),
           let config = try? JSONDecoder().decode(PowerModeConfig.self, from: data) {
            defaultConfig = config
        } else {
            defaultConfig = PowerModeConfig(
                bundleIdentifier: "default",
                appName: "Default Configuration",
                isAIEnhancementEnabled: false,
                selectedPrompt: nil
            )
            saveDefaultConfig()
        }
        loadConfigurations()
    }
    
    private func loadConfigurations() {
        if let data = UserDefaults.standard.data(forKey: configKey),
           let configs = try? JSONDecoder().decode([PowerModeConfig].self, from: data) {
            configurations = configs
        }
    }
    
    func saveConfigurations() {
        if let data = try? JSONEncoder().encode(configurations) {
            UserDefaults.standard.set(data, forKey: configKey)
        }
    }
    
    private func saveDefaultConfig() {
        if let data = try? JSONEncoder().encode(defaultConfig) {
            UserDefaults.standard.set(data, forKey: defaultConfigKey)
        }
    }
    
    func addConfiguration(_ config: PowerModeConfig) {
        if !configurations.contains(config) {
            configurations.append(config)
            saveConfigurations()
        }
    }
    
    func removeConfiguration(for bundleIdentifier: String) {
        configurations.removeAll { $0.bundleIdentifier == bundleIdentifier }
        saveConfigurations()
    }
    
    func getConfiguration(for bundleIdentifier: String) -> PowerModeConfig? {
        if bundleIdentifier == "default" {
            return defaultConfig
        }
        return configurations.first { $0.bundleIdentifier == bundleIdentifier }
    }
    
    func updateConfiguration(_ config: PowerModeConfig) {
        if config.bundleIdentifier == "default" {
            defaultConfig = config
            saveDefaultConfig()
        } else if let index = configurations.firstIndex(where: { $0.bundleIdentifier == config.bundleIdentifier }) {
            configurations[index] = config
            saveConfigurations()
        }
    }
    
    // Get configuration for a specific URL
    func getConfigurationForURL(_ url: String) -> (config: PowerModeConfig, urlConfig: URLConfig)? {
        let cleanedURL = url.lowercased()
            .replacingOccurrences(of: "https://", with: "")
            .replacingOccurrences(of: "http://", with: "")
            .replacingOccurrences(of: "www.", with: "")
        
        for config in configurations {
            if let urlConfigs = config.urlConfigs {
                for urlConfig in urlConfigs {
                    let configURL = urlConfig.url.lowercased()
                        .replacingOccurrences(of: "https://", with: "")
                        .replacingOccurrences(of: "http://", with: "")
                        .replacingOccurrences(of: "www.", with: "")
                    
                    if cleanedURL.contains(configURL) {
                        return (config, urlConfig)
                    }
                }
            }
        }
        return nil
    }
    
    // Add URL configuration
    func addURLConfig(_ urlConfig: URLConfig, to config: PowerModeConfig) {
        if var updatedConfig = configurations.first(where: { $0.id == config.id }) {
            var configs = updatedConfig.urlConfigs ?? []
            configs.append(urlConfig)
            updatedConfig.urlConfigs = configs
            updateConfiguration(updatedConfig)
        }
    }
    
    // Remove URL configuration
    func removeURLConfig(_ urlConfig: URLConfig, from config: PowerModeConfig) {
        if var updatedConfig = configurations.first(where: { $0.id == config.id }) {
            updatedConfig.urlConfigs?.removeAll(where: { $0.id == urlConfig.id })
            updateConfiguration(updatedConfig)
        }
    }
    
    // Update URL configuration
    func updateURLConfig(_ urlConfig: URLConfig, in config: PowerModeConfig) {
        if var updatedConfig = configurations.first(where: { $0.id == config.id }) {
            if let index = updatedConfig.urlConfigs?.firstIndex(where: { $0.id == urlConfig.id }) {
                updatedConfig.urlConfigs?[index] = urlConfig
                updateConfiguration(updatedConfig)
            }
        }
    }
    
    // Save power mode enabled state
    func savePowerModeEnabled() {
        UserDefaults.standard.set(isPowerModeEnabled, forKey: powerModeEnabledKey)
    }
}

================
File: VoiceInk/Models/PredefinedModels.swift
================
import Foundation

struct PredefinedModel: Identifiable, Hashable {
    let id = UUID()
    let name: String
    let displayName: String
    let size: String
    let language: String
    let description: String
    let speed: Double
    let accuracy: Double
    let ramUsage: Double
    let hash: String
    
    var downloadURL: String {
        "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/\(filename)"
    }
    
    var filename: String {
        "\(name).bin"
    }
    
    func hash(into hasher: inout Hasher) {
        hasher.combine(id)
    }
    
    static func == (lhs: PredefinedModel, rhs: PredefinedModel) -> Bool {
        lhs.id == rhs.id
    }
}

struct PredefinedModels {
    static let models: [PredefinedModel] = [
        PredefinedModel(
            name: "ggml-tiny",
            displayName: "Tiny",
            size: "75 MiB",
            language: "Multilingual",
            description: "Tiny model, fastest, least accurate, supports multiple languages",
            speed: 0.95,
            accuracy: 0.6,
            ramUsage: 0.3,
            hash: "bd577a113a864445d4c299885e0cb97d4ba92b5f"
        ),
        PredefinedModel(
            name: "ggml-tiny.en",
            displayName: "Tiny (English)",
            size: "75 MiB",
            language: "English",
            description: "Tiny model optimized for English, fastest, least accurate",
            speed: 0.95,
            accuracy: 0.65,
            ramUsage: 0.3,
            hash: "c78c86eb1a8faa21b369bcd33207cc90d64ae9df"
        ),
        PredefinedModel(
            name: "ggml-base",
            displayName: "Base",
            size: "142 MiB",
            language: "Multilingual",
            description: "Base model, good balance of speed and accuracy, supports multiple languages",
            speed: 0.8,
            accuracy: 0.75,
            ramUsage: 0.5,
            hash: "465707469ff3a37a2b9b8d8f89f2f99de7299dac"
        ),
        PredefinedModel(
            name: "ggml-base.en",
            displayName: "Base (English)",
            size: "142 MiB",
            language: "English",
            description: "Base model optimized for English, good balance of speed and accuracy",
            speed: 0.8,
            accuracy: 0.8,
            ramUsage: 0.5,
            hash: "137c40403d78fd54d454da0f9bd998f78703390c"
        ),
        PredefinedModel(
            name: "ggml-small",
            displayName: "Small",
            size: "466 MiB",
            language: "Multilingual",
            description: "Small model, slower but more accurate than base, supports multiple languages",
            speed: 0.6,
            accuracy: 0.85,
            ramUsage: 0.7,
            hash: "55356645c2b361a969dfd0ef2c5a50d530afd8d5"
        ),
        PredefinedModel(
            name: "ggml-small.en",
            displayName: "Small (English)",
            size: "466 MiB",
            language: "English",
            description: "Small model optimized for English, slower but more accurate than base",
            speed: 0.6,
            accuracy: 0.9,
            ramUsage: 0.7,
            hash: "db8a495a91d927739e50b3fc1cc4c6b8f6c2d022"
        ),
        PredefinedModel(
            name: "ggml-medium",
            displayName: "Medium",
            size: "1.5 GiB",
            language: "Multilingual",
            description: "Medium model, slow but very accurate, supports multiple languages",
            speed: 0.4,
            accuracy: 0.92,
            ramUsage: 2.5,
            hash: "fd9727b6e1217c2f614f9b698455c4ffd82463b4"
        ),
        PredefinedModel(
            name: "ggml-medium.en",
            displayName: "Medium (English)",
            size: "1.5 GiB",
            language: "English",
            description: "Medium model optimized for English, slow but very accurate",
            speed: 0.4,
            accuracy: 0.95,
            ramUsage: 2.0,
            hash: "8c30f0e44ce9560643ebd10bbe50cd20eafd3723"
        ),
        PredefinedModel(
            name: "ggml-large-v3",
            displayName: "Large v3",
            size: "2.9 GiB",
            language: "Multilingual",
            description: "Large model v3, very slow but most accurate, supports multiple languages",
            speed: 0.2,
            accuracy: 0.98,
            ramUsage: 3.9,
            hash: "ad82bf6a9043ceed055076d0fd39f5f186ff8062"
        ),
        PredefinedModel(
            name: "ggml-large-v3-q5_0",
            displayName: "Large v3 (Quantized)",
            size: "1.1 GiB",
            language: "Multilingual",
            description: "Quantized version of Large v3, faster with slightly lower accuracy",
            speed: 0.3,
            accuracy: 0.97,
            ramUsage: 1.5,
            hash: "e6e2ed78495d403bef4b7cff42ef4aaadcfea8de"
        ),
        PredefinedModel(
            name: "ggml-large-v3-turbo",
            displayName: "Large v3 Turbo",
            size: "1.5 GiB",
            language: "Multilingual",
            description: "Large model v3 Turbo, faster than v3 with similar accuracy, supports multiple languages",
            speed: 0.5,
            accuracy: 0.97,
            ramUsage: 1.8,
            hash: "4af2b29d7ec73d781377bfd1758ca957a807e941"
        ),
        PredefinedModel(
            name: "ggml-large-v3-turbo-q5_0",
            displayName: "Large v3 Turbo (Quantized)",
            size: "547 MiB",
            language: "Multilingual",
            description: "Quantized version of Large v3 Turbo, faster with slightly lower accuracy",
            speed: 0.6,
            accuracy: 0.96,
            ramUsage: 1.0,
            hash: "e050f7970618a659205450ad97eb95a18d69c9ee"
        )
    ]
}

================
File: VoiceInk/Models/PredefinedPrompts.swift
================
import Foundation

enum PredefinedPrompts {
    private static let predefinedPromptsKey = "PredefinedPrompts"
    
    // Static UUIDs for predefined prompts
    private static let defaultPromptId = UUID(uuidString: "00000000-0000-0000-0000-000000000001")!
    private static let chatStylePromptId = UUID(uuidString: "00000000-0000-0000-0000-000000000002")!
    private static let emailPromptId = UUID(uuidString: "00000000-0000-0000-0000-000000000003")!
    
    static var all: [CustomPrompt] {
        // Always return the latest predefined prompts from source code
        createDefaultPrompts()
    }
    
    static func createDefaultPrompts() -> [CustomPrompt] {
        [
            CustomPrompt(
                id: defaultPromptId,
                title: "Default",
                promptText: """
                You are tasked with cleaning up text that has been transcribed from voice. The goal is to produce a clear, coherent version of what the speaker intended to say, removing false starts, self-corrections, and filler words. Use the available context if directly related to the user's query. 
                Primary Rules:
                0. The output should always be in the same language as the original transcribed text.
                1. Maintain the original meaning and intent of the speaker. Do not add new information or change the substance of what was said.
                2. Ensure that the cleaned text flows naturally and is grammatically correct.
                3. When the speaker corrects themselves, keep only the corrected version.
                   Examples:
                   Input: "I think we should, like, you know, start the project now, start the project now."
                   Output: "I think we should start the project now."

                   Input: "The meeting is going to be, um, going to be at like maybe 3 PM tomorrow."
                   Output: "The meeting is going to be at 3 PM tomorrow."

                   Input: "We need to finish by Monday... actually no... by Wednesday" 
                   Output: "We need to finish by Wednesday"

                   Input: "Please order ten... I mean twelve units" 
                   Output: "Please order twelve units"
                4. Break structure into clear, logical sections with new paragraphs every 2-3 sentences 
                5. NEVER answer questions that appear in the text. Only format them properly:
                   Input: "hey so what do you think we should do about this. Do you like this idea."
                   Output: "What do you think we should do about this. Do you like this idea?"

                   Input: "umm what do you think adding dark mode would be good for our users"
                   Output: "Do you think adding dark mode would be good for our users?"

                   Input: "This needs to be properly written somewhere. Please do it. How can we do it? Give me three to four ways that would help the AI work properly."
                   Output: "This needs to be properly written somewhere. How can we do it? Give me 3-4 ways that would help the AI work properly?"
                6. Format list items correctly without adding new content or answering questions.
                    - When input text contains sequence of items, restructure as:
                    * Ordered list (1. 2. 3.) for sequential or prioritized items
                    * Unordered list (‚Ä¢) for non-sequential items
                    Examples:
                    Input: "i need to do three things first buy groceries second call mom and third finish the report"
                    Output: I need to do three things:
                            1. Buy groceries
                            2. Call mom
                            3. Finish the report
                7. Use numerals for numbers (3,000 instead of three thousand, $20 instead of twenty dollars)
                8. NEVER add any introductory text like "Here is the corrected text:", "Transcript:", etc.
                9. Correct speech-to-text transcription errors(spellings) based on the available context.

                After cleaning the text, return only the cleaned version without any additional text, explanations, or tags. The output should be ready for direct use without further editing.

                Here is the transcribed text: 
                """,
                icon: .sealedFill,
                description: "Defeault mode to improved clarity and accuracy of the transcription",
                isPredefined: true
            ),
            
            CustomPrompt(
                id: chatStylePromptId,
                title: "Chat",
                promptText: """
                Primary Rules:
                We are in a causual chat conversation.
                1. Focus on clarity while preserving the speaker's personality:
                   - Keep personality markers that show intent or style (e.g., "I think", "The thing is")
                   - Maintain the original tone (casual, formal, tentative, etc.)
                2. Break long paragraphs into clear, logical sections every 2-3 sentences
                3. Fix grammar and punctuation errors based on context
                4. Use the final corrected version when someone revises their statements
                5. Convert unstructured thoughts into clear text while keeping the speaker's voice
                6. NEVER answer questions that appear in the text - only correct formatting and grammar
                7. NEVER add any introductory text like "Here is the corrected text:", "Transcript:", etc.
                8. NEVER add content not present in the source text
                9. NEVER add sign-offs or acknowledgments
                10. Correct speech-to-text transcription errors based on context.

                Examples:

                Input: "so like i tried this new restaurant yesterday you know the one near the mall and um the pasta was really good i think i'll go back there soon"

                Output: "I tried this new restaurant near the mall yesterday! üçΩÔ∏è

                The pasta was really good. I think I'll go back there soon! üòä"

                Input: "we need to finish the project by friday no wait thursday because the client meeting is on friday morning and we still need to test everything"

                Output: "We need to finish the project by Thursday (not Friday) ‚è∞ because the client meeting is on Friday morning.

                We still need to test everything! ‚úÖ"

                Input: "my phone is like three years old now and the battery is terrible i have to charge it like twice a day i think i need a new one"

                Output: "My phone is three years old now and the battery is terrible. üì±

                I have to charge it twice a day. I think I need a new one! üîã"

                Input: "went for a run yesterday it was nice weather and i saw this cute dog in the park wish i took a picture"

                Output: "Went for a run yesterday! üèÉ‚Äç‚ôÄÔ∏è

                It was nice weather and I saw this cute dog in the park. üê∂

                Wish I took a picture! üì∏"
                """,
                icon: .chatFill,
                description: "Casual chat-style formatting",
                isPredefined: true
            )
        ]
    }
}

================
File: VoiceInk/Models/PromptTemplates.swift
================
import Foundation

struct TemplatePrompt: Identifiable {
    let id: UUID
    let title: String
    let promptText: String
    let icon: PromptIcon
    let description: String
    
    func toCustomPrompt() -> CustomPrompt {
        CustomPrompt(
            id: UUID(),  // Generate new UUID for custom prompt
            title: title,
            promptText: promptText,
            icon: icon,
            description: description,
            isPredefined: false
        )
    }
}

enum PromptTemplates {
    static var all: [TemplatePrompt] {
        createTemplatePrompts()
    }
    
    static func createTemplatePrompts() -> [TemplatePrompt] {
        [
            TemplatePrompt(
                id: UUID(),
                title: "Email",
                promptText: """
                Primary Rules:
                1. Preserve the speaker's original tone and personality
                2. Maintain professional tone while keeping personal speaking style
                3. Structure content into clear paragraphs
                4. Fix grammar and punctuation while preserving key points
                5. Remove filler words and redundancies
                6. Keep important details and context
                7. Format lists and bullet points properly
                8. Preserve any specific requests or action items
                9. Always include a professional sign-off
                10. Use appropriate greeting based on context

                Examples:

                Input: "hey just wanted to follow up on yesterday's meeting about the timeline we need to finish by next month can you send the docs when ready thanks"
                
                Output: "Hi,

                I wanted to follow up on yesterday's meeting about the timeline. We need to finish by next month.

                Could you send the docs when ready?

                Thanks,
                [Your Name]"

                Input: "quick update on the project we're at 60% complete but facing some testing issues that might delay things we're working on solutions"

                Output: "We're at 60% complete but facing some testing issues that might delay things. We're working on solutions.
                
                I'll keep you updated.

                Regards,
                [Your Name]"

                Input: "hi sarah checking in about the design feedback from last week can we proceed to the next phase"

                Output: "Hi Sarah,

                I'm checking in about the design feedback from last week. Can we proceed to the next phase?

                Thanks,
                [Your Name]"
                """,
                icon: .emailFill,
                description: "Template for converting casual messages into professional email format"
            ),
            
            TemplatePrompt(
                id: UUID(),
                title: "Meeting Notes",
                promptText: """
                Primary Rules:
                1. Preserve speaker's original tone and communication style
                2. Organize content into clear sections
                3. Structure key points and action items
                4. Maintain chronological flow
                5. Preserve important details and decisions
                6. Format lists and bullet points clearly
                7. Remove unnecessary repetition
                8. Keep names and specific references
                9. Highlight action items and deadlines

                Examples:

                Input: "meeting with design team today we talked about UI changes Sarah will update colors by next week John will work on accessibility and we'll launch next month"

                Output: "Design Team Meeting:

                Discussion:
                ‚Ä¢ UI changes
                ‚Ä¢ Color updates
                ‚Ä¢ Accessibility improvements

                Action Items:
                ‚Ä¢ Sarah: Update colors by next week
                ‚Ä¢ John: Work on accessibility

                Decision:
                ‚Ä¢ Launch next month"

                Input: "backend sync meeting we need to optimize database queries Mark will do this week Lisa will help with caching done by Friday then testing"

                Output: "Backend Sync Meeting:

                Focus: Database optimization

                Tasks:
                ‚Ä¢ Mark: Optimize database queries this week
                ‚Ä¢ Lisa: Help with caching

                Timeline:
                ‚Ä¢ Complete by Friday
                ‚Ä¢ Begin testing after"
                """,
                icon: .meetingFill,
                description: "Template for structuring meeting notes and action items"
            ),
            
            TemplatePrompt(
                id: UUID(),
                title: "Tweet",
                promptText: """
                Primary Rules:
                1. Keep it casual and conversational
                2. Use natural, informal language
                3. Include relevant emojis while maintaining authenticity
                4. For replies, acknowledge the person (@username)
                5. Break longer thoughts into multiple lines
                6. Keep the original personality and style
                7. Use hashtags when relevant
                8. Maintain the context of the conversation

                Examples:

                Input: "tried ios 17 today and the standby mode is amazing turns your phone into a smart display while charging"

                Output: "Tried iOS 17 today and the standby mode is amazing! ü§Ø

                Turns your phone into a smart display while charging ‚ö°Ô∏è #iOS17"

                Input: "just switched from membrane to mechanical keyboard with brown switches and my typing feels so much better"

                Output: "Just switched from membrane to mechanical keyboard with brown switches and my typing feels so much better! üéπ

                That tactile feedback is perfect ü§å #MechKeys"

                Input: "found a nice coffee shop downtown with great lavender latte and cozy spots with plants perfect for working"

                Output: "Found a nice coffee shop downtown! ‚òïÔ∏è

                Great lavender latte and cozy spots with plants - perfect for working ü™¥ #CoffeeVibes"

                Input: "for cold brew coffee medium roast guatemalan beans steeped for 18 hours makes the smoothest flavor"

                Output: "For cold brew coffee: medium roast Guatemalan beans steeped for 18 hours makes the smoothest flavor! ‚òïÔ∏è

                Absolute liquid gold ‚ú® #ColdBrew"
                """,
                icon: .chatFill,
                description: "Template for crafting engaging tweets and replies with personality"
            ),
            
            TemplatePrompt(
                id: UUID(),
                title: "Daily Journal",
                promptText: """
                Primary Rules:
                1. Preserve personal voice and emotional expression
                2. Keep personal tone and natural language
                3. Structure into morning, afternoon, evening sections
                4. Preserve emotions and reflections
                5. Highlight important moments
                6. Maintain chronological flow
                7. Keep authentic reactions and feelings

                Output Format:
                ### Morning
                Morning section

                ### Afternoon
                Afternoon section

                ### Evening
                Evening section

                Summary:: Key events, mood, highlights, learnings(Add it here)
                """,
                icon: .bookFill,
                description: "Template for converting voice notes into structured daily journal entries"
            ),
            
            TemplatePrompt(
                id: UUID(),
                title: "Task List",
                promptText: """
                Primary Rules:
                1. Preserve speaker's task organization style
                2. Convert into markdown checklist format
                3. Start each task with "- [ ]"
                4. Group related tasks together as subtasks
                5. Add priorities if mentioned
                6. Keep deadlines if specified
                7. Maintain original task descriptions

                Output Format:
                - [ ] Main task 1
                    - [ ] Subtask 1.1
                    - [ ] Subtask 1.2
                - [ ] Task 2 (Deadline: date)
                - [ ] Task 3
                    - [ ] Subtask 3.1
                - [ ] Follow-up item 1
                - [ ] Follow-up item 2
                """,
                icon: .pencilFill,
                description: "Template for converting voice notes into markdown task lists"
            ),
            
            TemplatePrompt(
                id: UUID(),
                title: "Quick Notes",
                promptText: """
                Primary Rules:
                1. Preserve speaker's thought process and emphasis
                2. Keep it brief and clear
                3. Use bullet points for key information
                4. Preserve important details
                5. Remove filler words while keeping style
                6. Maintain core message and intent
                7. Keep original terminology and phrasing

                Output Format:
                ## Main Topic
                ‚Ä¢ Main point 1
                  - Supporting detail
                  - Additional info
                ‚Ä¢ Main point 2
                  - Related informations
                """,
                icon: .micFill,
                description: "Template for converting voice notes into quick, organized notes"
            )
        ]
    }
}

================
File: VoiceInk/Models/Transcription.swift
================
import Foundation
import SwiftData

@Model
final class Transcription {
    var id: UUID
    var text: String
    var enhancedText: String?
    var timestamp: Date
    var duration: TimeInterval
    var audioFileURL: String?
    
    init(text: String, duration: TimeInterval, enhancedText: String? = nil, audioFileURL: String? = nil) {
        self.id = UUID()
        self.text = text
        self.enhancedText = enhancedText
        self.timestamp = Date()
        self.duration = duration
        self.audioFileURL = audioFileURL
    }
}

================
File: VoiceInk/Preview Content/Preview Assets.xcassets/Contents.json
================
{
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: VoiceInk/Resources/arcURL.scpt
================
tell application "Arc"
    tell front window
        tell active tab
            return URL
        end tell
    end tell
end tell

================
File: VoiceInk/Resources/braveURL.scpt
================
tell application "Brave Browser"
    tell active tab of front window
        return URL
    end tell
end tell

================
File: VoiceInk/Resources/chromeURL.scpt
================
tell application "Google Chrome"
    tell active tab of front window
        return URL
    end tell
end tell

================
File: VoiceInk/Resources/edgeURL.scpt
================
tell application "Microsoft Edge"
    tell active tab of front window
        return URL
    end tell
end tell

================
File: VoiceInk/Resources/firefoxURL.scpt
================
try
	tell application "Firefox"
		try
			activate
			delay 0.1
			tell application "System Events"
				try
					keystroke "l" using command down
					delay 0.1
					keystroke "c" using command down
					delay 0.1
					keystroke tab
				on error errMsg
					return "ERROR: System Events failed: " & errMsg
				end try
			end tell
			delay 0.1
			return (the clipboard as text)
		on error errMsg
			return "ERROR: Firefox activation failed: " & errMsg
		end try
	end tell
on error errMsg
	return "ERROR: Firefox application not available: " & errMsg
end try

================
File: VoiceInk/Resources/operaURL.scpt
================
tell application "Opera"
    tell active tab of front window
        return URL
    end tell
end tell

================
File: VoiceInk/Resources/orionURL.scpt
================
tell application "Orion"
    tell front window
        tell active tab
            return URL
        end tell
    end tell
end tell

================
File: VoiceInk/Resources/safariURL.scpt
================
tell application "Safari"
    tell front window
        tell current tab
            return URL
        end tell
    end tell
end tell

================
File: VoiceInk/Resources/vivaldiURL.scpt
================
tell application "Vivaldi"
    tell active tab of front window
        return URL
    end tell
end tell

================
File: VoiceInk/Resources/zenURL.scpt
================
try
	tell application "Zen Browser"
		try
			activate
			delay 0.1
			tell application "System Events"
				try
					keystroke "l" using command down
					delay 0.1
					keystroke "c" using command down
					delay 0.1
					keystroke tab
				on error errMsg
					return "ERROR: System Events failed: " & errMsg
				end try
			end tell
			delay 0.1
			return (the clipboard as text)
		on error errMsg
			return "ERROR: Zen Browser activation failed: " & errMsg
		end try
	end tell
on error errMsg
	return "ERROR: Zen Browser application not available: " & errMsg
end try

================
File: VoiceInk/Services/ActiveWindowService.swift
================
import Foundation
import AppKit
import os

class ActiveWindowService: ObservableObject {
    static let shared = ActiveWindowService()
    @Published var currentApplication: NSRunningApplication?
    private var enhancementService: AIEnhancementService?
    private let browserURLService = BrowserURLService.shared
    
    private let logger = Logger(
        subsystem: "com.prakashjoshipax.VoiceInk",
        category: "browser.detection"
    )
    
    private init() {}
    
    func configure(with enhancementService: AIEnhancementService) {
        self.enhancementService = enhancementService
    }
    
    func applyConfigurationForCurrentApp() async {
        // If power mode is disabled, don't do anything
        guard PowerModeManager.shared.isPowerModeEnabled else {
            print("üîå Power Mode is disabled globally - skipping configuration application")
            return
        }

        guard let frontmostApp = NSWorkspace.shared.frontmostApplication,
              let bundleIdentifier = frontmostApp.bundleIdentifier else { return }
        
        print("üéØ Active Application: \(frontmostApp.localizedName ?? "Unknown") (\(bundleIdentifier))")
        await MainActor.run {
            currentApplication = frontmostApp
        }
        
        // Check if the current app is a supported browser
        if let browserType = BrowserType.allCases.first(where: { $0.bundleIdentifier == bundleIdentifier }) {
            logger.debug("üåê Detected Browser: \(browserType.displayName)")
            
            do {
                // Try to get the current URL
                logger.debug("üìù Attempting to get URL from \(browserType.displayName)")
                let currentURL = try await browserURLService.getCurrentURL(from: browserType)
                logger.debug("üìç Successfully got URL: \(currentURL)")
                
                // Check for URL-specific configuration
                if let (config, urlConfig) = PowerModeManager.shared.getConfigurationForURL(currentURL) {
                    logger.debug("‚öôÔ∏è Found URL Configuration: \(config.appName) - URL: \(urlConfig.url)")
                    // Apply URL-specific configuration
                    var updatedConfig = config
                    updatedConfig.selectedPrompt = urlConfig.promptId
                    await applyConfiguration(updatedConfig)
                    return
                } else {
                    logger.debug("üìù No URL configuration found for: \(currentURL)")
                }
            } catch {
                logger.error("‚ùå Failed to get URL from \(browserType.displayName): \(error.localizedDescription)")
            }
        }
        
        // Get configuration for the current app or use default if none exists
        let config = PowerModeManager.shared.getConfiguration(for: bundleIdentifier) ?? PowerModeManager.shared.defaultConfig
        print("‚ö°Ô∏è Using Configuration: \(config.appName) (AI Enhancement: \(config.isAIEnhancementEnabled ? "Enabled" : "Disabled"))")
        await applyConfiguration(config)
    }
    
    private func applyConfiguration(_ config: PowerModeConfig) async {
        guard let enhancementService = enhancementService else { return }
        
        await MainActor.run {
            // Only apply settings if power mode is enabled globally
            if PowerModeManager.shared.isPowerModeEnabled {
                // Apply AI enhancement settings
                enhancementService.isEnhancementEnabled = config.isAIEnhancementEnabled
                
                // Handle prompt selection
                if config.isAIEnhancementEnabled {
                    if let promptId = config.selectedPrompt,
                       let uuid = UUID(uuidString: promptId) {
                        print("üéØ Applied Prompt: \(enhancementService.allPrompts.first(where: { $0.id == uuid })?.title ?? "Unknown")")
                        enhancementService.selectedPromptId = uuid
                    } else {
                        // Auto-select first prompt if none is selected and AI is enabled
                        if let firstPrompt = enhancementService.allPrompts.first {
                            print("üéØ Auto-selected Prompt: \(firstPrompt.title)")
                            enhancementService.selectedPromptId = firstPrompt.id
                        }
                    }
                }
            } else {
                print("üîå Power Mode is disabled globally - skipping configuration application")
                return
            }
        }
    }
}

================
File: VoiceInk/Services/AIEnhancementService.swift
================
import Foundation
import os
import SwiftData
import AppKit

enum EnhancementMode {
    case transcriptionEnhancement
    case aiAssistant
}

class AIEnhancementService: ObservableObject {
    private let logger = Logger(
        subsystem: "com.prakashjoshipax.VoiceInk",
        category: "aienhancement"
    )
    
    @Published var isEnhancementEnabled: Bool {
        didSet {
            UserDefaults.standard.set(isEnhancementEnabled, forKey: "isAIEnhancementEnabled")
            // When enhancement is enabled, ensure a prompt is selected
            if isEnhancementEnabled && selectedPromptId == nil {
                // Select the first prompt (default) if none is selected
                selectedPromptId = customPrompts.first?.id
            }
            
            // Cancel any existing capture task
            currentCaptureTask?.cancel()
            
            // Trigger screen capture when enhancement is enabled and screen capture is on
            if isEnhancementEnabled && useScreenCaptureContext {
                currentCaptureTask = Task {
                    await captureScreenContext()
                }
            }
        }
    }        
    @Published var useClipboardContext: Bool {
        didSet {
            UserDefaults.standard.set(useClipboardContext, forKey: "useClipboardContext")
        }
    }
    
    @Published var useScreenCaptureContext: Bool {
        didSet {
            UserDefaults.standard.set(useScreenCaptureContext, forKey: "useScreenCaptureContext")
        }
    }
    
    @Published var assistantTriggerWord: String {
        didSet {
            UserDefaults.standard.set(assistantTriggerWord, forKey: "assistantTriggerWord")
        }
    }
    
    @Published var customPrompts: [CustomPrompt] {
        didSet {
            if let encoded = try? JSONEncoder().encode(customPrompts.filter { !$0.isPredefined }) {
                UserDefaults.standard.set(encoded, forKey: "customPrompts")
            }
        }
    }
    
    @Published var selectedPromptId: UUID? {
        didSet {
            UserDefaults.standard.set(selectedPromptId?.uuidString, forKey: "selectedPromptId")
        }
    }
    
    var activePrompt: CustomPrompt? {
        allPrompts.first { $0.id == selectedPromptId }
    }
    
    var allPrompts: [CustomPrompt] {
        // Always include the latest default prompt first, followed by custom prompts
        PredefinedPrompts.createDefaultPrompts() + customPrompts.filter { !$0.isPredefined }
    }
    
    private let aiService: AIService
    private let screenCaptureService: ScreenCaptureService
    private var currentCaptureTask: Task<Void, Never>?
    private let maxRetries = 3
    private let baseTimeout: TimeInterval = 4
    private let rateLimitInterval: TimeInterval = 1.0 // 1 request per second
    private var lastRequestTime: Date?
    private let modelContext: ModelContext
    
    init(aiService: AIService = AIService(), modelContext: ModelContext) {
        self.aiService = aiService
        self.modelContext = modelContext
        self.screenCaptureService = ScreenCaptureService()
        
        // Print UserDefaults domain
        if let domain = Bundle.main.bundleIdentifier {
            print("‚öôÔ∏è UserDefaults domain: \(domain)")
            if let prefsPath = NSSearchPathForDirectoriesInDomains(.libraryDirectory, .userDomainMask, true).first {
                print("‚öôÔ∏è Preferences directory: \(prefsPath)/Preferences/\(domain).plist")
            }
        }
        
        self.isEnhancementEnabled = UserDefaults.standard.bool(forKey: "isAIEnhancementEnabled")
        self.useClipboardContext = UserDefaults.standard.bool(forKey: "useClipboardContext")
        self.useScreenCaptureContext = UserDefaults.standard.bool(forKey: "useScreenCaptureContext")
        self.assistantTriggerWord = UserDefaults.standard.string(forKey: "assistantTriggerWord") ?? "hey"
        
        // Load only custom prompts (non-predefined ones)
        if let savedPromptsData = UserDefaults.standard.data(forKey: "customPrompts"),
           let decodedPrompts = try? JSONDecoder().decode([CustomPrompt].self, from: savedPromptsData) {
            self.customPrompts = decodedPrompts
        } else {
            self.customPrompts = []
        }
        
        // Load selected prompt ID
        if let savedPromptId = UserDefaults.standard.string(forKey: "selectedPromptId") {
            self.selectedPromptId = UUID(uuidString: savedPromptId)
        }
        
        // Ensure a prompt is selected if enhancement is enabled
        if isEnhancementEnabled && (selectedPromptId == nil || !allPrompts.contains(where: { $0.id == selectedPromptId })) {
            // Set first prompt (default) as selected
            self.selectedPromptId = allPrompts.first?.id
        }
        
        // Setup notification observer for API key changes
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleAPIKeyChange),
            name: .aiProviderKeyChanged,
            object: nil
        )
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self)
    }
    
    @objc private func handleAPIKeyChange() {
        DispatchQueue.main.async {
            self.objectWillChange.send()
            // Optionally disable enhancement if API key is cleared
            if !self.aiService.isAPIKeyValid {
                self.isEnhancementEnabled = false
            }
        }
    }
    
    var isConfigured: Bool {
        aiService.isAPIKeyValid
    }
    
    private func waitForRateLimit() async throws {
        if let lastRequest = lastRequestTime {
            let timeSinceLastRequest = Date().timeIntervalSince(lastRequest)
            if timeSinceLastRequest < rateLimitInterval {
                try await Task.sleep(nanoseconds: UInt64((rateLimitInterval - timeSinceLastRequest) * 1_000_000_000))
            }
        }
        lastRequestTime = Date()
    }
    
    private func determineMode(text: String) -> EnhancementMode {
        // Only use AI assistant mode if text starts with configured trigger word
        if text.lowercased().hasPrefix(assistantTriggerWord.lowercased()) {
            return .aiAssistant
        }
        return .transcriptionEnhancement
    }
    
    private func getSystemMessage(for mode: EnhancementMode) -> String {
        // Get clipboard context if enabled and available
        let clipboardContext = if useClipboardContext,
                              let clipboardText = NSPasteboard.general.string(forType: .string),
                              !clipboardText.isEmpty {
            """
            
            Context Awareness
            Available Clipboard Context: \(clipboardText)
            """
        } else {
            ""
        }
        
        // Get screen capture context if enabled and available
        let screenCaptureContext = if useScreenCaptureContext,
                                   let capturedText = screenCaptureService.lastCapturedText,
                                   !capturedText.isEmpty {
            """
            
            Active Window Context: \(capturedText)
            """
        } else {
            ""
        }
        
        switch mode {
        case .transcriptionEnhancement:
            // Always use activePrompt since we've removed the toggle
            var systemMessage = String(format: AIPrompts.customPromptTemplate, activePrompt!.promptText)
            systemMessage += "\n\n" + AIPrompts.contextInstructions
            systemMessage += clipboardContext + screenCaptureContext
            return systemMessage

        case .aiAssistant:
            return AIPrompts.assistantMode + clipboardContext + screenCaptureContext
        }
    }
    
    private func makeRequest(text: String, retryCount: Int = 0) async throws -> String {
        guard isConfigured else {
            logger.error("AI Enhancement: API not configured")
            throw EnhancementError.notConfigured
        }
        
        guard !text.isEmpty else {
            logger.error("AI Enhancement: Empty text received")
            throw EnhancementError.emptyText
        }
        
        // Determine mode and get system message
        let mode = determineMode(text: text)
        let systemMessage = getSystemMessage(for: mode)
        
        // Handle Ollama requests differently
        if aiService.selectedProvider == .ollama {
            logger.notice("üì§ Request to Ollama")
            logger.notice("ü§ñ System: \(systemMessage, privacy: .public)")
            logger.notice("üìù Sending: \(text, privacy: .public)")
            do {
                let result = try await aiService.enhanceWithOllama(text: text, systemPrompt: systemMessage)
                logger.notice("‚úÖ Ollama enhancement successful")
                logger.notice("üìù Received: \(result, privacy: .public)")
                return result
            } catch let error as LocalAIError {
                switch error {
                case .serviceUnavailable:
                    logger.error("üîå Ollama service unavailable")
                    throw EnhancementError.notConfigured
                case .modelNotFound:
                    logger.error("ü§ñ Ollama model not found")
                    throw EnhancementError.enhancementFailed
                case .serverError:
                    logger.error("üî• Ollama server error")
                    throw EnhancementError.serverError
                default:
                    logger.error("‚ùå Ollama enhancement failed")
                    throw EnhancementError.enhancementFailed
                }
            }
        }
        
        // Handle cloud provider requests
        // Wait for rate limit
        try await waitForRateLimit()
        
        // Special handling for Gemini and Anthropic
        switch aiService.selectedProvider {
        case .gemini:
            var urlComponents = URLComponents(string: aiService.selectedProvider.baseURL)!
            urlComponents.queryItems = [URLQueryItem(name: "key", value: aiService.apiKey)]
            
            guard let url = urlComponents.url else {
                throw EnhancementError.invalidResponse
            }
            
            var request = URLRequest(url: url)
            request.httpMethod = "POST"
            request.addValue("application/json", forHTTPHeaderField: "Content-Type")
            
            let timeout = baseTimeout * pow(2.0, Double(retryCount))
            request.timeoutInterval = timeout
            
            let requestBody: [String: Any] = [
                "contents": [
                    [
                        "parts": [
                            ["text": systemMessage],
                            ["text": "Transcript:\n\(text)"]
                        ]
                    ]
                ],
                "generationConfig": [
                    "temperature": 0.3,
                ]
            ]
            
            request.httpBody = try? JSONSerialization.data(withJSONObject: requestBody)
            
            do {
                logger.notice("üì§ Request to Gemini")
                logger.notice("ü§ñ System: \(systemMessage, privacy: .public)")
                logger.notice("üìù Sending: \(text, privacy: .public)")
                let (data, response) = try await URLSession.shared.data(for: request)
                
                guard let httpResponse = response as? HTTPURLResponse else {
                    logger.error("‚ùå Invalid Gemini response")
                    throw EnhancementError.invalidResponse
                }
                
                switch httpResponse.statusCode {
                case 200:
                    guard let jsonResponse = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
                          let candidates = jsonResponse["candidates"] as? [[String: Any]],
                          let firstCandidate = candidates.first,
                          let content = firstCandidate["content"] as? [String: Any],
                          let parts = content["parts"] as? [[String: Any]],
                          let firstPart = parts.first,
                          let enhancedText = firstPart["text"] as? String else {
                        logger.error("‚ùå Failed to parse Gemini response")
                        throw EnhancementError.enhancementFailed
                    }
                    
                    let result = enhancedText.trimmingCharacters(in: .whitespacesAndNewlines)
                    logger.notice("‚úÖ Gemini enhancement successful")
                    logger.notice("üìù Received: \(result, privacy: .public)")
                    return result
                    
                case 401:
                    logger.error("üîí Authentication failed")
                    throw EnhancementError.authenticationFailed
                    
                case 429:
                    logger.error("‚è≥ Rate limit exceeded")
                    throw EnhancementError.rateLimitExceeded
                    
                case 500...599:
                    logger.error("üî• Server error (\(httpResponse.statusCode))")
                    throw EnhancementError.serverError
                    
                default:
                    logger.error("‚ùå Unexpected status (\(httpResponse.statusCode))")
                    throw EnhancementError.apiError
                }
            } catch let error as EnhancementError {
                throw error
            } catch {
                logger.error("‚ùå Network error: \(error.localizedDescription)")
                
                if retryCount < maxRetries {
                    try await Task.sleep(nanoseconds: UInt64(pow(2.0, Double(retryCount)) * 1_000_000_000))
                    return try await makeRequest(text: text, retryCount: retryCount + 1)
                }
                
                throw EnhancementError.networkError
            }
            
        case .anthropic:
            let requestBody: [String: Any] = [
                "model": aiService.selectedProvider.defaultModel,
                "max_tokens": 1024,
                "system": systemMessage,
                "messages": [
                    ["role": "user", "content": text]
                ]
            ]
            
            var request = URLRequest(url: URL(string: aiService.selectedProvider.baseURL)!)
            request.httpMethod = "POST"
            request.addValue("application/json", forHTTPHeaderField: "Content-Type")
            request.addValue(aiService.apiKey, forHTTPHeaderField: "x-api-key")
            request.addValue("2023-06-01", forHTTPHeaderField: "anthropic-version")
            
            let timeout = baseTimeout * pow(2.0, Double(retryCount))
            request.timeoutInterval = timeout
            
            request.httpBody = try? JSONSerialization.data(withJSONObject: requestBody)
            
            do {
                logger.notice("üì§ Request to Anthropic")
                logger.notice("ü§ñ System: \(systemMessage, privacy: .public)")
                logger.notice("üìù Sending: \(text, privacy: .public)")
                let (data, response) = try await URLSession.shared.data(for: request)
                
                guard let httpResponse = response as? HTTPURLResponse else {
                    logger.error("‚ùå Invalid Anthropic response")
                    throw EnhancementError.invalidResponse
                }
                
                switch httpResponse.statusCode {
                case 200:
                    guard let jsonResponse = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
                          let content = jsonResponse["content"] as? [[String: Any]],
                          let firstContent = content.first,
                          let enhancedText = firstContent["text"] as? String else {
                        logger.error("‚ùå Failed to parse Anthropic response")
                        throw EnhancementError.enhancementFailed
                    }
                    
                    let result = enhancedText.trimmingCharacters(in: .whitespacesAndNewlines)
                    logger.notice("‚úÖ Anthropic enhancement successful")
                    logger.notice("üìù Received: \(result, privacy: .public)")
                    return result
                    
                case 401:
                    logger.error("üîí Authentication failed")
                    throw EnhancementError.authenticationFailed
                    
                case 429:
                    logger.error("‚è≥ Rate limit exceeded")
                    throw EnhancementError.rateLimitExceeded
                    
                case 500...599:
                    logger.error("üî• Server error (\(httpResponse.statusCode))")
                    throw EnhancementError.serverError
                    
                default:
                    logger.error("‚ùå Unexpected status (\(httpResponse.statusCode))")
                    throw EnhancementError.apiError
                }
            } catch let error as EnhancementError {
                throw error
            } catch {
                logger.error("‚ùå Network error: \(error.localizedDescription)")
                
                if retryCount < maxRetries {
                    try await Task.sleep(nanoseconds: UInt64(pow(2.0, Double(retryCount)) * 1_000_000_000))
                    return try await makeRequest(text: text, retryCount: retryCount + 1)
                }
                
                throw EnhancementError.networkError
            }
            
        default:
            // Handle OpenAI compatible providers
            let url = URL(string: aiService.selectedProvider.baseURL)!
            var request = URLRequest(url: url)
            request.httpMethod = "POST"
            request.addValue("application/json", forHTTPHeaderField: "Content-Type")
            request.addValue("Bearer \(aiService.apiKey)", forHTTPHeaderField: "Authorization")
            
            // Set timeout based on retry count with exponential backoff
            let timeout = baseTimeout * pow(2.0, Double(retryCount))
            request.timeoutInterval = timeout
            
            logger.debug("Full system message: \(systemMessage)")
            
            let messages: [[String: Any]] = [
                ["role": "system", "content": systemMessage],
                ["role": "user", "content": "Transcript:\n\(text)"]
            ]
            
            logger.info("Making request to \(self.aiService.selectedProvider.rawValue) with text length: \(text.count) characters")
            
            let requestBody: [String: Any] = [
                "model": aiService.selectedProvider.defaultModel,
                "messages": messages,
                "temperature": 0.3,
                "frequency_penalty": 0.0,
                "presence_penalty": 0.0,
                "stream": false
            ]
            
            request.httpBody = try? JSONSerialization.data(withJSONObject: requestBody)
            
            do {
                logger.notice("üì§ Request to \(self.aiService.selectedProvider.rawValue, privacy: .public)")
                logger.notice("ü§ñ System: \(systemMessage, privacy: .public)")
                logger.notice("üìù Sending: \(text, privacy: .public)")
                let (data, response) = try await URLSession.shared.data(for: request)
                
                guard let httpResponse = response as? HTTPURLResponse else {
                    logger.error("‚ùå Invalid response")
                    throw EnhancementError.invalidResponse
                }
                
                switch httpResponse.statusCode {
                case 200:
                    guard let jsonResponse = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
                          let choices = jsonResponse["choices"] as? [[String: Any]],
                          let firstChoice = choices.first,
                          let message = firstChoice["message"] as? [String: Any],
                          let enhancedText = message["content"] as? String else {
                        logger.error("‚ùå Failed to parse response")
                        throw EnhancementError.enhancementFailed
                    }
                    
                    let result = enhancedText.trimmingCharacters(in: .whitespacesAndNewlines)
                    logger.notice("‚úÖ Enhancement successful")
                    logger.notice("üìù Received: \(result, privacy: .public)")
                    return result
                    
                case 401:
                    logger.error("üîí Authentication failed")
                    throw EnhancementError.authenticationFailed
                    
                case 429:
                    logger.error("‚è≥ Rate limit exceeded")
                    throw EnhancementError.rateLimitExceeded
                    
                case 500...599:
                    logger.error("üî• Server error (\(httpResponse.statusCode))")
                    throw EnhancementError.serverError
                    
                default:
                    logger.error("‚ùå Unexpected status (\(httpResponse.statusCode))")
                    throw EnhancementError.apiError
                }
                
            } catch let error as EnhancementError {
                throw error
            } catch {
                logger.error("‚ùå Network error: \(error.localizedDescription)")
                
                if retryCount < maxRetries {
                    try await Task.sleep(nanoseconds: UInt64(pow(2.0, Double(retryCount)) * 1_000_000_000))
                    return try await makeRequest(text: text, retryCount: retryCount + 1)
                }
                
                throw EnhancementError.networkError
            }
        }
    }
    
    func enhance(_ text: String) async throws -> String {
        var retryCount = 0
        while retryCount < maxRetries {
            do {
                return try await makeRequest(text: text, retryCount: retryCount)
            } catch EnhancementError.rateLimitExceeded where retryCount < maxRetries - 1 {
                retryCount += 1
                try await Task.sleep(nanoseconds: UInt64(pow(2.0, Double(retryCount)) * 1_000_000_000))
                continue
            } catch {
                throw error
            }
        }
        throw EnhancementError.maxRetriesExceeded
    }
    
    // Add a new method to capture screen context
    func captureScreenContext() async {
        // Only check for screen capture context toggle
        guard useScreenCaptureContext else { 
            logger.notice("üì∑ Screen capture context is disabled")
            return 
        }
        
        logger.notice("üì∑ Initiating screen capture for context")
        // Wait for the screen capture to complete and check result
        if let capturedText = await screenCaptureService.captureAndExtractText() {
            logger.notice("üì∑ Screen capture successful, got \(capturedText.count, privacy: .public) characters")
            // Ensure we're on the main thread when updating published properties
            await MainActor.run {
                // Manually trigger objectWillChange to ensure UI updates
                self.objectWillChange.send()
            }
        } else {
            logger.notice("üì∑ Screen capture failed or returned empty result")
        }
    }
    
    // MARK: - Prompt Management
    
    func addPrompt(title: String, promptText: String, icon: PromptIcon = .documentFill, description: String? = nil) {
        let newPrompt = CustomPrompt(title: title, promptText: promptText, icon: icon, description: description, isPredefined: false)
        customPrompts.append(newPrompt)
        if customPrompts.count == 1 {
            selectedPromptId = newPrompt.id
        }
    }
    
    func updatePrompt(_ prompt: CustomPrompt) {
        // Don't allow updates to predefined prompts
        if prompt.isPredefined {
            return
        }
        
        if let index = customPrompts.firstIndex(where: { $0.id == prompt.id }) {
            customPrompts[index] = prompt
        }
    }
    
    func deletePrompt(_ prompt: CustomPrompt) {
        // Don't allow deletion of predefined prompts
        if prompt.isPredefined {
            return
        }
        
        customPrompts.removeAll { $0.id == prompt.id }
        if selectedPromptId == prompt.id {
            selectedPromptId = allPrompts.first?.id
        }
    }
    
    func setActivePrompt(_ prompt: CustomPrompt) {
        selectedPromptId = prompt.id
    }
}

enum EnhancementError: Error {
    case notConfigured
    case emptyText
    case invalidResponse
    case enhancementFailed
    case authenticationFailed
    case rateLimitExceeded
    case serverError
    case apiError
    case networkError
    case maxRetriesExceeded
}

================
File: VoiceInk/Services/AIPrompts.swift
================
enum AIPrompts {
    static let customPromptTemplate = """
    Reformat the input message according to the given guidelines:

    %@
    """
    
    static let assistantMode = """
    Provide a direct clear, and concise reply to the user's query. Use the available context if directly related to the user's query. 
    Remember to:
    1. Be helpful and informative
    2. Be accurate and precise
    3. Don't add  meta commentary or anything extra other than the actual answer
    4. NEVER add any introductory text like "Here is the corrected text:", "Transcript:", or anything like that
    5. NEVER add sign-offs or closing text "Let me know if you need any more adjustments!", or anything like that except the actual answer.
    6. Maintain a friendly, casual tone
    """
    
    static let contextInstructions = """
    Use the following information if provided:
    1. Active Window Context:
       IMPORTANT: Only use window content when directly relevant to input
       - Use application name and window title for understanding the context
       - Reference captured text from the window
       - Preserve application-specific terms and formatting
       - Help resolve unclear terms or phrases

    2. Available Clipboard Content:
       IMPORTANT: Only use when directly relevant to input
       - Use for additional context
       - Help resolve unclear references
       - Ignore unrelated clipboard content

    3. Examples:
       - Follow the correction patterns shown in examples
       - Match the formatting style of similar texts
       - Use consistent terminology with examples
       - Learn from previous corrections
    """
}

================
File: VoiceInk/Services/AIService.swift
================
import Foundation

enum AIProvider: String, CaseIterable {
    case groq = "GROQ"
    case openAI = "OpenAI"
    case deepSeek = "DeepSeek"
    case gemini = "Gemini"
    case anthropic = "Anthropic"
    case ollama = "Ollama"
    case custom = "Custom"
    
    var baseURL: String {
        switch self {
        case .groq:
            return "https://api.groq.com/openai/v1/chat/completions"
        case .openAI:
            return "https://api.openai.com/v1/chat/completions"
        case .deepSeek:
            return "https://api.deepseek.com/v1/chat/completions"
        case .gemini:
            return "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
        case .anthropic:
            return "https://api.anthropic.com/v1/messages"
        case .ollama:
            return UserDefaults.standard.string(forKey: "ollamaBaseURL") ?? "http://localhost:11434"
        case .custom:
            return UserDefaults.standard.string(forKey: "customProviderBaseURL") ?? ""
        }
    }
    
    var defaultModel: String {
        switch self {
        case .groq:
            return "llama-3.3-70b-versatile"
        case .openAI:
            return "gpt-4o-mini-2024-07-18"
        case .deepSeek:
            return "deepseek-chat"
        case .gemini:
            return "gemini-2.0-flash"
        case .anthropic:
            return "claude-3-5-sonnet-20241022"
        case .ollama:
            return UserDefaults.standard.string(forKey: "ollamaSelectedModel") ?? "mistral"
        case .custom:
            return UserDefaults.standard.string(forKey: "customProviderModel") ?? ""
        }
    }
    
    var requiresAPIKey: Bool {
        switch self {
        case .ollama:
            return false
        default:
            return true
        }
    }
}

class AIService: ObservableObject {
    @Published var apiKey: String = ""
    @Published var isAPIKeyValid: Bool = false
    @Published var customBaseURL: String = UserDefaults.standard.string(forKey: "customProviderBaseURL") ?? "" {
        didSet {
            userDefaults.set(customBaseURL, forKey: "customProviderBaseURL")
        }
    }
    @Published var customModel: String = UserDefaults.standard.string(forKey: "customProviderModel") ?? "" {
        didSet {
            userDefaults.set(customModel, forKey: "customProviderModel")
        }
    }
    @Published var selectedProvider: AIProvider {
        didSet {
            userDefaults.set(selectedProvider.rawValue, forKey: "selectedAIProvider")
            // Load API key for the selected provider if it requires one
            if selectedProvider.requiresAPIKey {
                if let savedKey = userDefaults.string(forKey: "\(selectedProvider.rawValue)APIKey") {
                    self.apiKey = savedKey
                    self.isAPIKeyValid = true
                } else {
                    self.apiKey = ""
                    self.isAPIKeyValid = false
                }
            } else {
                // For providers that don't require API key (like Ollama)
                self.apiKey = ""
                self.isAPIKeyValid = true
                // Check Ollama connection
                if selectedProvider == .ollama {
                    Task {
                        await ollamaService.checkConnection()
                        await ollamaService.refreshModels()
                    }
                }
            }
        }
    }
    
    private let userDefaults = UserDefaults.standard
    private let ollamaService = OllamaService()
    
    var connectedProviders: [AIProvider] {
        AIProvider.allCases.filter { provider in
            if provider == .ollama {
                return ollamaService.isConnected
            } else if provider.requiresAPIKey {
                return userDefaults.string(forKey: "\(provider.rawValue)APIKey") != nil
            }
            return false
        }
    }
    
    init() {
        // Load selected provider
        if let savedProvider = userDefaults.string(forKey: "selectedAIProvider"),
           let provider = AIProvider(rawValue: savedProvider) {
            self.selectedProvider = provider
        } else {
            self.selectedProvider = .gemini // Default to Gemini
        }
        
        // Load API key for the current provider if it requires one
        if selectedProvider.requiresAPIKey {
            if let savedKey = userDefaults.string(forKey: "\(selectedProvider.rawValue)APIKey") {
                self.apiKey = savedKey
                self.isAPIKeyValid = true
            }
        } else {
            // For providers that don't require API key
            self.isAPIKeyValid = true
            // Check Ollama connection if it's the selected provider
            if selectedProvider == .ollama {
                Task {
                    await ollamaService.checkConnection()
                    await ollamaService.refreshModels()
                }
            }
        }
    }
    
    func saveAPIKey(_ key: String, completion: @escaping (Bool) -> Void) {
        // Skip verification for providers that don't require API key
        guard selectedProvider.requiresAPIKey else {
            print("üìù [\(selectedProvider.rawValue)] API key not required, skipping verification")
            completion(true)
            return
        }
        
        print("üîë [\(selectedProvider.rawValue)] Starting API key verification...")
        // Verify the API key before saving
        verifyAPIKey(key) { [weak self] isValid in
            guard let self = self else { return }
            DispatchQueue.main.async {
                if isValid {
                    print("‚úÖ [\(self.selectedProvider.rawValue)] API key verified successfully")
                    self.apiKey = key
                    self.isAPIKeyValid = true
                    self.userDefaults.set(key, forKey: "\(self.selectedProvider.rawValue)APIKey")
                    NotificationCenter.default.post(name: .aiProviderKeyChanged, object: nil)
                } else {
                    print("‚ùå [\(self.selectedProvider.rawValue)] API key verification failed")
                    self.isAPIKeyValid = false
                }
                completion(isValid)
            }
        }
    }
    
    func verifyAPIKey(_ key: String, completion: @escaping (Bool) -> Void) {
        // Skip verification for providers that don't require API key
        guard selectedProvider.requiresAPIKey else {
            print("üìù [\(selectedProvider.rawValue)] API key verification skipped - not required")
            completion(true)
            return
        }
        
        print("üîç [\(selectedProvider.rawValue)] Verifying API key...")
        print("üåê Using base URL: \(selectedProvider.baseURL)")
        print("ü§ñ Using model: \(selectedProvider.defaultModel)")
        
        // Special handling for different providers
        switch selectedProvider {
        case .gemini:
            verifyGeminiAPIKey(key, completion: completion)
        case .anthropic:
            verifyAnthropicAPIKey(key, completion: completion)
        default:
            verifyOpenAICompatibleAPIKey(key, completion: completion)
        }
    }
    
    private func verifyOpenAICompatibleAPIKey(_ key: String, completion: @escaping (Bool) -> Void) {
        let url = URL(string: selectedProvider.baseURL)!
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.addValue("application/json", forHTTPHeaderField: "Content-Type")
        request.addValue("Bearer \(key)", forHTTPHeaderField: "Authorization")
        
        let testBody: [String: Any] = [
            "model": selectedProvider.defaultModel,
            "messages": [
                ["role": "user", "content": "test"]
            ],
            "max_tokens": 1
        ]
        
        request.httpBody = try? JSONSerialization.data(withJSONObject: testBody)
        
        print("üì§ Sending verification request...")
        URLSession.shared.dataTask(with: request) { data, response, error in
            if let error = error {
                print("‚ùå Network error during verification: \(error.localizedDescription)")
                completion(false)
                return
            }
            
            if let httpResponse = response as? HTTPURLResponse {
                print("üì• Received response with status code: \(httpResponse.statusCode)")
                completion(httpResponse.statusCode == 200)
            } else {
                print("‚ùå Invalid response received")
                completion(false)
            }
        }.resume()
    }
    
    private func verifyAnthropicAPIKey(_ key: String, completion: @escaping (Bool) -> Void) {
        let url = URL(string: selectedProvider.baseURL)!
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.addValue("application/json", forHTTPHeaderField: "Content-Type")
        request.addValue(key, forHTTPHeaderField: "x-api-key")
        request.addValue("2023-06-01", forHTTPHeaderField: "anthropic-version")
        
        let testBody: [String: Any] = [
            "model": selectedProvider.defaultModel,
            "max_tokens": 1024,
            "system": "You are a test system.",
            "messages": [
                ["role": "user", "content": "test"]
            ]
        ]
        
        request.httpBody = try? JSONSerialization.data(withJSONObject: testBody)
        
        print("üì§ Sending Anthropic verification request...")
        URLSession.shared.dataTask(with: request) { data, response, error in
            if let error = error {
                print("‚ùå Network error during Anthropic verification: \(error.localizedDescription)")
                completion(false)
                return
            }
            
            if let httpResponse = response as? HTTPURLResponse {
                print("üì• Received Anthropic response with status code: \(httpResponse.statusCode)")
                completion(httpResponse.statusCode == 200)
            } else {
                print("‚ùå Invalid Anthropic response received")
                completion(false)
            }
        }.resume()
    }
    
    private func verifyGeminiAPIKey(_ key: String, completion: @escaping (Bool) -> Void) {
        var urlComponents = URLComponents(string: selectedProvider.baseURL)!
        urlComponents.queryItems = [URLQueryItem(name: "key", value: key)]
        
        guard let url = urlComponents.url else {
            completion(false)
            return
        }
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.addValue("application/json", forHTTPHeaderField: "Content-Type")
        
        let testBody: [String: Any] = [
            "contents": [
                [
                    "parts": [
                        ["text": "test"]
                    ]
                ]
            ]
        ]
        
        request.httpBody = try? JSONSerialization.data(withJSONObject: testBody)
        
        print("üì§ Sending Gemini verification request...")
        URLSession.shared.dataTask(with: request) { data, response, error in
            if let error = error {
                print("‚ùå Network error during Gemini verification: \(error.localizedDescription)")
                completion(false)
                return
            }
            
            if let httpResponse = response as? HTTPURLResponse {
                print("üì• Received Gemini response with status code: \(httpResponse.statusCode)")
                completion(httpResponse.statusCode == 200)
            } else {
                print("‚ùå Invalid Gemini response received")
                completion(false)
            }
        }.resume()
    }
    
    func clearAPIKey() {
        // Skip for providers that don't require API key
        guard selectedProvider.requiresAPIKey else { return }
        
        apiKey = ""
        isAPIKeyValid = false
        userDefaults.removeObject(forKey: "\(selectedProvider.rawValue)APIKey")
        NotificationCenter.default.post(name: .aiProviderKeyChanged, object: nil)
    }
    
    // Add method to check Ollama connection
    func checkOllamaConnection(completion: @escaping (Bool) -> Void) {
        Task { [weak self] in
            guard let self = self else { return }
            await self.ollamaService.checkConnection()
            DispatchQueue.main.async {
                completion(self.ollamaService.isConnected)
            }
        }
    }
    
    // Add method to get available Ollama models
    func fetchOllamaModels() async -> [OllamaService.OllamaModel] {
        await ollamaService.refreshModels()
        return ollamaService.availableModels
    }
    
    // Add method to enhance text using Ollama
    func enhanceWithOllama(text: String, systemPrompt: String) async throws -> String {
        return try await ollamaService.enhance(text, withSystemPrompt: systemPrompt)
    }
    
    // Add method to update Ollama base URL
    func updateOllamaBaseURL(_ newURL: String) {
        ollamaService.baseURL = newURL
        userDefaults.set(newURL, forKey: "ollamaBaseURL")
    }
    
    // Add method to update selected Ollama model
    func updateSelectedOllamaModel(_ modelName: String) {
        ollamaService.selectedModel = modelName
        userDefaults.set(modelName, forKey: "ollamaSelectedModel")
    }
}

// Add extension for notification name
extension Notification.Name {
    static let aiProviderKeyChanged = Notification.Name("aiProviderKeyChanged")
}

================
File: VoiceInk/Services/AudioDeviceConfiguration.swift
================
import Foundation
import AVFoundation
import CoreAudio
import os

class AudioDeviceConfiguration {
    private static let logger = Logger(subsystem: "com.prakashjoshipax.voiceink", category: "AudioDeviceConfiguration")
    
    /// Configures audio session for a specific device
    /// - Parameter deviceID: The ID of the audio device to configure
    /// - Returns: A tuple containing the configured format and any error that occurred
    static func configureAudioSession(with deviceID: AudioDeviceID) throws -> AudioStreamBasicDescription {
        var propertySize = UInt32(MemoryLayout<AudioStreamBasicDescription>.size)
        var streamFormat = AudioStreamBasicDescription()
        var propertyAddress = AudioObjectPropertyAddress(
            mSelector: kAudioDevicePropertyStreamFormat,
            mScope: kAudioDevicePropertyScopeInput,
            mElement: kAudioObjectPropertyElementMain
        )
        
        // First, ensure the device is ready
        var isAlive: UInt32 = 0
        var aliveSize = UInt32(MemoryLayout<UInt32>.size)
        var aliveAddress = AudioObjectPropertyAddress(
            mSelector: kAudioDevicePropertyDeviceIsAlive,
            mScope: kAudioObjectPropertyScopeGlobal,
            mElement: kAudioObjectPropertyElementMain
        )
        
        let aliveStatus = AudioObjectGetPropertyData(
            deviceID,
            &aliveAddress,
            0,
            nil,
            &aliveSize,
            &isAlive
        )
        
        if aliveStatus != noErr || isAlive == 0 {
            logger.error("Device \(deviceID) is not alive or ready")
            throw AudioConfigurationError.failedToGetDeviceFormat(status: aliveStatus)
        }
        
        // Get the device format
        let status = AudioObjectGetPropertyData(
            deviceID,
            &propertyAddress,
            0,
            nil,
            &propertySize,
            &streamFormat
        )
        
        if status != noErr {
            logger.error("Failed to get device format: \(status)")
            throw AudioConfigurationError.failedToGetDeviceFormat(status: status)
        }
        
        // Ensure we're using a standard PCM format
        streamFormat.mFormatID = kAudioFormatLinearPCM
        streamFormat.mFormatFlags = kAudioFormatFlagIsFloat | kAudioFormatFlagIsPacked
        
        return streamFormat
    }
    
    /// Sets up an audio device for the audio unit
    /// - Parameters:
    ///   - deviceID: The ID of the audio device
    ///   - audioUnit: The audio unit to configure
    static func configureAudioUnit(_ audioUnit: AudioUnit, with deviceID: AudioDeviceID) throws {
        var deviceIDCopy = deviceID
        let propertySize = UInt32(MemoryLayout<AudioDeviceID>.size)
        
        // First disable the audio unit
        let resetStatus = AudioUnitReset(audioUnit, kAudioUnitScope_Global, 0)
        if resetStatus != noErr {
            logger.error("Failed to reset audio unit: \(resetStatus)")
        }
        
        logger.info("Configuring audio unit for device ID: \(deviceID)")
        let setDeviceResult = AudioUnitSetProperty(
            audioUnit,
            kAudioOutputUnitProperty_CurrentDevice,
            kAudioUnitScope_Global,
            0,
            &deviceIDCopy,
            propertySize
        )
        
        if setDeviceResult != noErr {
            logger.error("Failed to set audio unit device: \(setDeviceResult)")
            logger.error("Device ID: \(deviceID)")
            if let deviceName = AudioDeviceManager.shared.getDeviceName(deviceID: deviceID) {
                logger.error("Failed device name: \(deviceName)")
            }
            throw AudioConfigurationError.failedToSetAudioUnitDevice(status: setDeviceResult)
        }
        
        logger.info("Successfully configured audio unit")
        // Add a small delay to allow the device to settle
        Thread.sleep(forTimeInterval: 0.1)
    }
    
    /// Sets the default input device for recording
    /// - Parameter deviceID: The ID of the audio device
    static func setDefaultInputDevice(_ deviceID: AudioDeviceID) throws {
        var deviceIDCopy = deviceID
        let propertySize = UInt32(MemoryLayout<AudioDeviceID>.size)
        var address = AudioObjectPropertyAddress(
            mSelector: kAudioHardwarePropertyDefaultInputDevice,
            mScope: kAudioObjectPropertyScopeGlobal,
            mElement: kAudioObjectPropertyElementMain
        )
        
        let setDeviceResult = AudioObjectSetPropertyData(
            AudioObjectID(kAudioObjectSystemObject),
            &address,
            0,
            nil,
            propertySize,
            &deviceIDCopy
        )
        
        if setDeviceResult != noErr {
            logger.error("Failed to set input device: \(setDeviceResult)")
            throw AudioConfigurationError.failedToSetInputDevice(status: setDeviceResult)
        }
    }
    
    /// Creates a device change observer
    /// - Parameters:
    ///   - handler: The closure to execute when device changes
    ///   - queue: The queue to execute the handler on (defaults to main queue)
    /// - Returns: The observer token
    static func createDeviceChangeObserver(
        handler: @escaping () -> Void,
        queue: OperationQueue = .main
    ) -> NSObjectProtocol {
        return NotificationCenter.default.addObserver(
            forName: NSNotification.Name("AudioDeviceChanged"),
            object: nil,
            queue: queue,
            using: { _ in handler() }
        )
    }
}

enum AudioConfigurationError: LocalizedError {
    case failedToGetDeviceFormat(status: OSStatus)
    case failedToSetAudioUnitDevice(status: OSStatus)
    case failedToSetInputDevice(status: OSStatus)
    case failedToGetAudioUnit
    
    var errorDescription: String? {
        switch self {
        case .failedToGetDeviceFormat(let status):
            return "Failed to get device format: \(status)"
        case .failedToSetAudioUnitDevice(let status):
            return "Failed to set audio unit device: \(status)"
        case .failedToSetInputDevice(let status):
            return "Failed to set input device: \(status)"
        case .failedToGetAudioUnit:
            return "Failed to get audio unit from input node"
        }
    }
}

================
File: VoiceInk/Services/AudioDeviceManager.swift
================
import Foundation
import CoreAudio
import AVFoundation
import os

struct PrioritizedDevice: Codable, Identifiable {
    let id: String // Device UID
    let name: String
    let priority: Int
}

enum AudioInputMode: String, CaseIterable {
    case systemDefault = "System Default"
    case custom = "Custom Device"
    case prioritized = "Prioritized"
}

class AudioDeviceManager: ObservableObject {
    private let logger = Logger(subsystem: "com.prakashjoshipax.voiceink", category: "AudioDeviceManager")
    @Published var availableDevices: [(id: AudioDeviceID, uid: String, name: String)] = []
    @Published var selectedDeviceID: AudioDeviceID?
    @Published var inputMode: AudioInputMode = .systemDefault
    @Published var prioritizedDevices: [PrioritizedDevice] = []
    private var fallbackDeviceID: AudioDeviceID?
    
    static let shared = AudioDeviceManager()
    
    init() {
        setupFallbackDevice()
        loadPrioritizedDevices()
        loadAvailableDevices { [weak self] in
            self?.initializeSelectedDevice()
        }
        
        // Load saved input mode
        if let savedMode = UserDefaults.standard.string(forKey: "audioInputMode"),
           let mode = AudioInputMode(rawValue: savedMode) {
            inputMode = mode
        }
        
        // Setup device change notifications
        setupDeviceChangeNotifications()
    }
    
    private func setupFallbackDevice() {
        let deviceID: AudioDeviceID? = getDeviceProperty(
            deviceID: AudioObjectID(kAudioObjectSystemObject),
            selector: kAudioHardwarePropertyDefaultInputDevice
        )
        
        if let deviceID = deviceID {
            fallbackDeviceID = deviceID
            if let name = getDeviceName(deviceID: deviceID) {
                logger.info("Fallback device set to: \(name) (ID: \(deviceID))")
            }
        } else {
            logger.error("Failed to get fallback device")
        }
    }
    
    private func initializeSelectedDevice() {
        if inputMode == .prioritized {
            selectHighestPriorityAvailableDevice()
            return
        }
        
        // Try to load saved device
        if let savedID = UserDefaults.standard.object(forKey: "selectedAudioDeviceID") as? AudioDeviceID {
            // Verify the saved device still exists and is valid
            if isDeviceAvailable(savedID) {
                selectedDeviceID = savedID
                logger.info("Loaded saved device ID: \(savedID)")
                if let name = getDeviceName(deviceID: savedID) {
                    logger.info("Using saved device: \(name)")
                }
            } else {
                logger.warning("Saved device ID \(savedID) is no longer available")
                fallbackToDefaultDevice()
            }
        } else {
            fallbackToDefaultDevice()
        }
    }
    
    private func isDeviceAvailable(_ deviceID: AudioDeviceID) -> Bool {
        return availableDevices.contains { $0.id == deviceID }
    }
    
    private func fallbackToDefaultDevice() {
        if let fallbackID = fallbackDeviceID {
            selectedDeviceID = fallbackID
            logger.info("Using fallback device ID: \(fallbackID)")
            if let name = getDeviceName(deviceID: fallbackID) {
                logger.info("Fallback to built-in microphone: \(name)")
            }
        } else {
            logger.error("No fallback device available")
        }
    }
    
    func loadAvailableDevices(completion: (() -> Void)? = nil) {
        logger.info("Loading available audio devices...")
        var propertySize: UInt32 = 0
        var address = AudioObjectPropertyAddress(
            mSelector: kAudioHardwarePropertyDevices,
            mScope: kAudioObjectPropertyScopeGlobal,
            mElement: kAudioObjectPropertyElementMain
        )
        
        var result = AudioObjectGetPropertyDataSize(
            AudioObjectID(kAudioObjectSystemObject),
            &address,
            0,
            nil,
            &propertySize
        )
        
        let deviceCount = Int(propertySize) / MemoryLayout<AudioDeviceID>.size
        logger.info("Found \(deviceCount) total audio devices")
        
        var deviceIDs = [AudioDeviceID](repeating: 0, count: deviceCount)
        
        result = AudioObjectGetPropertyData(
            AudioObjectID(kAudioObjectSystemObject),
            &address,
            0,
            nil,
            &propertySize,
            &deviceIDs
        )
        
        if result != noErr {
            logger.error("Error getting audio devices: \(result)")
            return
        }
        
        let devices = deviceIDs.compactMap { deviceID -> (id: AudioDeviceID, uid: String, name: String)? in
            guard let name = getDeviceName(deviceID: deviceID),
                  let uid = getDeviceUID(deviceID: deviceID),
                  isInputDevice(deviceID: deviceID) else {
                return nil
            }
            return (id: deviceID, uid: uid, name: name)
        }
        
        logger.info("Found \(devices.count) input devices")
        devices.forEach { device in
            logger.info("Available device: \(device.name) (ID: \(device.id))")
        }
        
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }
            self.availableDevices = devices.map { ($0.id, $0.uid, $0.name) }
            // Verify current selection is still valid
            if let currentID = self.selectedDeviceID, !devices.contains(where: { $0.id == currentID }) {
                self.logger.warning("Currently selected device is no longer available")
                self.fallbackToDefaultDevice()
            }
            completion?()
        }
    }
    
    func getDeviceName(deviceID: AudioDeviceID) -> String? {
        let name: CFString? = getDeviceProperty(deviceID: deviceID,
                                              selector: kAudioDevicePropertyDeviceNameCFString)
        return name as String?
    }
    
    private func isInputDevice(deviceID: AudioDeviceID) -> Bool {
        var address = AudioObjectPropertyAddress(
            mSelector: kAudioDevicePropertyStreamConfiguration,
            mScope: kAudioDevicePropertyScopeInput,
            mElement: kAudioObjectPropertyElementMain
        )
        
        var propertySize: UInt32 = 0
        var result = AudioObjectGetPropertyDataSize(
            deviceID,
            &address,
            0,
            nil,
            &propertySize
        )
        
        if result != noErr {
            logger.error("Error checking input capability for device \(deviceID): \(result)")
            return false
        }
        
        let bufferList = UnsafeMutablePointer<AudioBufferList>.allocate(capacity: Int(propertySize))
        defer { bufferList.deallocate() }
        
        result = AudioObjectGetPropertyData(
            deviceID,
            &address,
            0,
            nil,
            &propertySize,
            bufferList
        )
        
        if result != noErr {
            logger.error("Error getting stream configuration for device \(deviceID): \(result)")
            return false
        }
        
        let bufferCount = Int(bufferList.pointee.mNumberBuffers)
        return bufferCount > 0
    }
    
    func selectDevice(id: AudioDeviceID) {
        logger.info("Selecting device with ID: \(id)")
        if let name = getDeviceName(deviceID: id) {
            logger.info("Selected device name: \(name)")
        }
        
        if isDeviceAvailable(id) {
            DispatchQueue.main.async {
                self.selectedDeviceID = id
                UserDefaults.standard.set(id, forKey: "selectedAudioDeviceID")
                self.logger.info("Device selection saved")
                self.notifyDeviceChange()
            }
        } else {
            logger.error("Attempted to select unavailable device: \(id)")
            fallbackToDefaultDevice()
        }
    }
    
    func selectInputMode(_ mode: AudioInputMode) {
        inputMode = mode
        UserDefaults.standard.set(mode.rawValue, forKey: "audioInputMode")
        
        if mode == .systemDefault {
            selectedDeviceID = nil
            UserDefaults.standard.removeObject(forKey: "selectedAudioDeviceID")
        } else if selectedDeviceID == nil {
            if let firstDevice = availableDevices.first {
                selectDevice(id: firstDevice.id)
            }
        }
        
        notifyDeviceChange()
    }
    
    func getCurrentDevice() -> AudioDeviceID {
        switch inputMode {
        case .systemDefault:
            return fallbackDeviceID ?? 0
        case .custom:
            return selectedDeviceID ?? fallbackDeviceID ?? 0
        case .prioritized:
            let sortedDevices = prioritizedDevices.sorted { $0.priority < $1.priority }
            for device in sortedDevices {
                if let available = availableDevices.first(where: { $0.uid == device.id }) {
                    return available.id
                }
            }
            return fallbackDeviceID ?? 0
        }
    }
    
    private func loadPrioritizedDevices() {
        if let data = UserDefaults.standard.data(forKey: "prioritizedDevices"),
           let devices = try? JSONDecoder().decode([PrioritizedDevice].self, from: data) {
            prioritizedDevices = devices
            logger.info("Loaded \(devices.count) prioritized devices")
        }
    }
    
    func savePrioritizedDevices() {
        if let data = try? JSONEncoder().encode(prioritizedDevices) {
            UserDefaults.standard.set(data, forKey: "prioritizedDevices")
            logger.info("Saved \(self.prioritizedDevices.count) prioritized devices")
        }
    }
    
    func addPrioritizedDevice(uid: String, name: String) {
        guard !prioritizedDevices.contains(where: { $0.id == uid }) else { return }
        let nextPriority = (prioritizedDevices.map { $0.priority }.max() ?? -1) + 1
        let device = PrioritizedDevice(id: uid, name: name, priority: nextPriority)
        prioritizedDevices.append(device)
        savePrioritizedDevices()
    }
    
    func removePrioritizedDevice(id: String) {
        let wasSelected = selectedDeviceID == availableDevices.first(where: { $0.uid == id })?.id
        prioritizedDevices.removeAll { $0.id == id }
        
        // Reindex remaining devices to ensure continuous priority numbers
        let updatedDevices = prioritizedDevices.enumerated().map { index, device in
            PrioritizedDevice(id: device.id, name: device.name, priority: index)
        }
        
        prioritizedDevices = updatedDevices
        savePrioritizedDevices()
        
        // If we removed the currently selected device, select the next best option
        if wasSelected && inputMode == .prioritized {
            selectHighestPriorityAvailableDevice()
        }
    }
    
    func updatePriorities(devices: [PrioritizedDevice]) {
        prioritizedDevices = devices
        savePrioritizedDevices()
        
        if inputMode == .prioritized {
            selectHighestPriorityAvailableDevice()
        }
        
        notifyDeviceChange()
    }
    
    private func selectHighestPriorityAvailableDevice() {
        // Sort by priority (lowest number = highest priority)
        let sortedDevices = prioritizedDevices.sorted { $0.priority < $1.priority }
        
        // Try each device in priority order
        for device in sortedDevices {
            if let availableDevice = availableDevices.first(where: { $0.uid == device.id }) {
                selectedDeviceID = availableDevice.id
                logger.info("Selected prioritized device: \(device.name) (Priority: \(device.priority))")
                
                // Actually set the device as the current input device
                do {
                    try AudioDeviceConfiguration.setDefaultInputDevice(availableDevice.id)
                    UserDefaults.standard.set(availableDevice.id, forKey: "selectedAudioDeviceID")
                } catch {
                    logger.error("Failed to set prioritized device: \(error.localizedDescription)")
                    continue // Try next device if this one fails
                }
                return
            }
        }
        
        // If no prioritized device is available, fall back to default
        fallbackToDefaultDevice()
    }
    
    private func setupDeviceChangeNotifications() {
        var address = AudioObjectPropertyAddress(
            mSelector: kAudioHardwarePropertyDevices,
            mScope: kAudioObjectPropertyScopeGlobal,
            mElement: kAudioObjectPropertyElementMain
        )
        
        let systemObjectID = AudioObjectID(kAudioObjectSystemObject)
        
        // Add listener for device changes
        let status = AudioObjectAddPropertyListener(
            systemObjectID,
            &address,
            { (_, _, _, userData) -> OSStatus in
                let manager = Unmanaged<AudioDeviceManager>.fromOpaque(userData!).takeUnretainedValue()
                DispatchQueue.main.async {
                    manager.handleDeviceListChange()
                }
                return noErr
            },
            UnsafeMutableRawPointer(Unmanaged.passUnretained(self).toOpaque())
        )
        
        if status != noErr {
            logger.error("Failed to add device change listener: \(status)")
        } else {
            logger.info("Successfully added device change listener")
        }
    }
    
    private func handleDeviceListChange() {
        logger.info("Device list change detected")
        loadAvailableDevices { [weak self] in
            guard let self = self else { return }
            
            // If in prioritized mode, recheck the device selection
            if self.inputMode == .prioritized {
                self.selectHighestPriorityAvailableDevice()
            }
            // If in custom mode and selected device is no longer available, fallback
            else if self.inputMode == .custom,
                    let currentID = self.selectedDeviceID,
                    !self.isDeviceAvailable(currentID) {
                self.fallbackToDefaultDevice()
            }
            
            // Notify UI of changes
            NotificationCenter.default.post(name: NSNotification.Name("AudioDeviceChanged"), object: nil)
        }
    }
    
    private func getDeviceUID(deviceID: AudioDeviceID) -> String? {
        let uid: CFString? = getDeviceProperty(deviceID: deviceID,
                                             selector: kAudioDevicePropertyDeviceUID)
        return uid as String?
    }
    
    deinit {
        // Remove the listener when the manager is deallocated
        var address = AudioObjectPropertyAddress(
            mSelector: kAudioHardwarePropertyDevices,
            mScope: kAudioObjectPropertyScopeGlobal,
            mElement: kAudioObjectPropertyElementMain
        )
        
        AudioObjectRemovePropertyListener(
            AudioObjectID(kAudioObjectSystemObject),
            &address,
            { (_, _, _, userData) -> OSStatus in
                return noErr
            },
            UnsafeMutableRawPointer(Unmanaged.passUnretained(self).toOpaque())
        )
    }
    
    // MARK: - Helper Methods
    private func createPropertyAddress(selector: AudioObjectPropertySelector,
                                    scope: AudioObjectPropertyScope = kAudioObjectPropertyScopeGlobal,
                                    element: AudioObjectPropertyElement = kAudioObjectPropertyElementMain) -> AudioObjectPropertyAddress {
        return AudioObjectPropertyAddress(
            mSelector: selector,
            mScope: scope,
            mElement: element
        )
    }
    
    private func getDeviceProperty<T>(deviceID: AudioDeviceID,
                                    selector: AudioObjectPropertySelector,
                                    scope: AudioObjectPropertyScope = kAudioObjectPropertyScopeGlobal) -> T? {
        // Skip invalid device IDs
        guard deviceID != 0 else { return nil }
        
        var address = createPropertyAddress(selector: selector, scope: scope)
        var propertySize = UInt32(MemoryLayout<T>.size)
        var property: T? = nil
        
        let status = AudioObjectGetPropertyData(
            deviceID,
            &address,
            0,
            nil,
            &propertySize,
            &property
        )
        
        if status != noErr {
            logger.error("Failed to get device property \(selector) for device \(deviceID): \(status)")
            return nil
        }
        
        return property
    }
    
    private func notifyDeviceChange() {
        NotificationCenter.default.post(name: NSNotification.Name("AudioDeviceChanged"), object: nil)
    }
}

================
File: VoiceInk/Services/AudioProcessor.swift
================
import Foundation
import AVFoundation
import os

class AudioProcessor {
    private let logger = Logger(subsystem: "com.prakashjoshipax.voiceink", category: "AudioProcessor")
    
    struct AudioFormat {
        static let targetSampleRate: Double = 16000.0
        static let targetChannels: UInt32 = 1
        static let targetBitDepth: UInt32 = 16
    }
    
    enum AudioProcessingError: LocalizedError {
        case invalidAudioFile
        case conversionFailed
        case exportFailed
        case unsupportedFormat
        case sampleExtractionFailed
        
        var errorDescription: String? {
            switch self {
            case .invalidAudioFile:
                return "The audio file is invalid or corrupted"
            case .conversionFailed:
                return "Failed to convert the audio format"
            case .exportFailed:
                return "Failed to export the processed audio"
            case .unsupportedFormat:
                return "The audio format is not supported"
            case .sampleExtractionFailed:
                return "Failed to extract audio samples"
            }
        }
    }
    
    /// Process audio file and return samples ready for Whisper
    /// - Parameter url: URL of the input audio file
    /// - Returns: Array of normalized float samples
    func processAudioToSamples(_ url: URL) async throws -> [Float] {
        logger.notice("üéµ Processing audio file to samples: \(url.lastPathComponent)")
        
        // Create AVAudioFile from input
        guard let audioFile = try? AVAudioFile(forReading: url) else {
            logger.error("‚ùå Failed to create AVAudioFile from input")
            throw AudioProcessingError.invalidAudioFile
        }
        
        // Get format information
        let format = audioFile.processingFormat
        let sampleRate = format.sampleRate
        let channels = format.channelCount
        
        logger.notice("üìä Input format - Sample Rate: \(sampleRate), Channels: \(channels)")
        
        // Create output format (always 16kHz mono float)
        let outputFormat = AVAudioFormat(
            commonFormat: .pcmFormatFloat32,
            sampleRate: AudioFormat.targetSampleRate,
            channels: AudioFormat.targetChannels,
            interleaved: false
        )
        
        guard let outputFormat = outputFormat else {
            logger.error("‚ùå Failed to create output format")
            throw AudioProcessingError.unsupportedFormat
        }
        
        // Read input file into buffer
        let inputBuffer = AVAudioPCMBuffer(
            pcmFormat: format,
            frameCapacity: AVAudioFrameCount(audioFile.length)
        )
        
        guard let inputBuffer = inputBuffer else {
            logger.error("‚ùå Failed to create input buffer")
            throw AudioProcessingError.conversionFailed
        }
        
        try audioFile.read(into: inputBuffer)
        
        // If format matches our target, just convert to samples
        if sampleRate == AudioFormat.targetSampleRate && channels == AudioFormat.targetChannels {
            logger.notice("‚úÖ Audio format already matches requirements")
            return convertToWhisperFormat(inputBuffer)
        }
        
        // Create converter for format conversion
        guard let converter = AVAudioConverter(from: format, to: outputFormat) else {
            logger.error("‚ùå Failed to create audio converter")
            throw AudioProcessingError.conversionFailed
        }
        
        // Create output buffer
        let ratio = AudioFormat.targetSampleRate / sampleRate
        let outputBuffer = AVAudioPCMBuffer(
            pcmFormat: outputFormat,
            frameCapacity: AVAudioFrameCount(Double(inputBuffer.frameLength) * ratio)
        )
        
        guard let outputBuffer = outputBuffer else {
            logger.error("‚ùå Failed to create output buffer")
            throw AudioProcessingError.conversionFailed
        }
        
        // Perform conversion
        var error: NSError?
        let status = converter.convert(
            to: outputBuffer,
            error: &error,
            withInputFrom: { inNumPackets, outStatus in
                outStatus.pointee = .haveData
                return inputBuffer
            }
        )
        
        if let error = error {
            logger.error("‚ùå Conversion failed: \(error.localizedDescription)")
            throw AudioProcessingError.conversionFailed
        }
        
        if status == .error {
            logger.error("‚ùå Conversion failed with status: error")
            throw AudioProcessingError.conversionFailed
        }
        
        logger.notice("‚úÖ Successfully converted audio format")
        return convertToWhisperFormat(outputBuffer)
    }
    
    /// Convert audio buffer to Whisper-compatible samples
    private func convertToWhisperFormat(_ buffer: AVAudioPCMBuffer) -> [Float] {
        guard let channelData = buffer.floatChannelData else {
            logger.error("‚ùå No channel data available in buffer")
            return []
        }
        
        let channelCount = Int(buffer.format.channelCount)
        let frameLength = Int(buffer.frameLength)
        var samples = Array(repeating: Float(0), count: frameLength)
        
        logger.notice("üìä Converting buffer - Channels: \(channelCount), Frames: \(frameLength)")
        
        // If mono, just copy the samples
        if channelCount == 1 {
            samples = Array(UnsafeBufferPointer(start: channelData[0], count: frameLength))
            logger.notice("‚úÖ Copied mono samples directly")
        }
        // If stereo or more, average all channels
        else {
            logger.notice("üîÑ Converting \(channelCount) channels to mono")
            for frame in 0..<frameLength {
                var sum: Float = 0
                for channel in 0..<channelCount {
                    sum += channelData[channel][frame]
                }
                samples[frame] = sum / Float(channelCount)
            }
        }
        
        // Normalize samples to [-1, 1]
        let maxSample = samples.map(abs).max() ?? 1
        if maxSample > 0 {
            logger.notice("üìà Normalizing samples with max amplitude: \(maxSample)")
            samples = samples.map { $0 / maxSample }
        }
        
        // Log sample statistics
        if let min = samples.min(), let max = samples.max() {
            logger.notice("üìä Final sample range: [\(min), \(max)]")
        }
        
        logger.notice("‚úÖ Successfully converted \(samples.count) samples")
        return samples
    }
}

================
File: VoiceInk/Services/AudioTranscriptionManager.swift
================
import Foundation
import SwiftUI
import AVFoundation
import SwiftData
import os

@MainActor
class AudioTranscriptionManager: ObservableObject {
    static let shared = AudioTranscriptionManager()
    
    @Published var isProcessing = false
    @Published var processingPhase: ProcessingPhase = .idle
    @Published var currentTranscription: Transcription?
    @Published var messageLog: String = ""
    @Published var errorMessage: String?
    
    private var currentTask: Task<Void, Error>?
    private var whisperContext: WhisperContext?
    private let audioProcessor = AudioProcessor()
    private let logger = Logger(subsystem: "com.prakashjoshipax.voiceink", category: "AudioTranscriptionManager")
    
    enum ProcessingPhase {
        case idle
        case loading
        case processingAudio
        case transcribing
        case enhancing
        case completed
        
        var message: String {
            switch self {
            case .idle:
                return ""
            case .loading:
                return "Loading transcription model..."
            case .processingAudio:
                return "Processing audio file for transcription..."
            case .transcribing:
                return "Transcribing audio..."
            case .enhancing:
                return "Enhancing transcription with AI..."
            case .completed:
                return "Transcription completed!"
            }
        }
    }
    
    private init() {}
    
    func startProcessing(url: URL, modelContext: ModelContext, whisperState: WhisperState) {
        // Cancel any existing processing
        cancelProcessing()
        
        isProcessing = true
        processingPhase = .loading
        messageLog = ""
        errorMessage = nil
        
        currentTask = Task {
            do {
                guard let currentModel = whisperState.currentModel else {
                    throw TranscriptionError.noModelSelected
                }
                
                // Load Whisper model
                whisperContext = try await WhisperContext.createContext(path: currentModel.url.path)
                
                // Process audio file
                processingPhase = .processingAudio
                let samples = try await audioProcessor.processAudioToSamples(url)
                
                // Get audio duration
                let audioAsset = AVURLAsset(url: url)
                var duration: TimeInterval = 0
                
                if #available(macOS 13.0, *) {
                    let durationValue = try await audioAsset.load(.duration)
                    duration = CMTimeGetSeconds(durationValue)
                } else {
                    duration = CMTimeGetSeconds(audioAsset.duration)
                }
                
                // Create permanent copy of the audio file
                let recordingsDirectory = FileManager.default.urls(for: .applicationSupportDirectory, in: .userDomainMask)[0]
                    .appendingPathComponent("com.prakashjoshipax.VoiceInk")
                    .appendingPathComponent("Recordings")
                
                let fileName = "transcribed_\(UUID().uuidString).wav"
                let permanentURL = recordingsDirectory.appendingPathComponent(fileName)
                
                try FileManager.default.createDirectory(at: recordingsDirectory, withIntermediateDirectories: true)
                try FileManager.default.copyItem(at: url, to: permanentURL)
                
                // Transcribe
                processingPhase = .transcribing
                await whisperContext?.setPrompt(whisperState.whisperPrompt.transcriptionPrompt)
                try await whisperContext?.fullTranscribe(samples: samples)
                var text = await whisperContext?.getTranscription() ?? ""
                text = text.trimmingCharacters(in: .whitespacesAndNewlines)
                
                // Apply word replacements if enabled
                if UserDefaults.standard.bool(forKey: "IsWordReplacementEnabled") {
                    text = WordReplacementService.shared.applyReplacements(to: text)
                }
                
                // Handle enhancement if enabled
                if let enhancementService = whisperState.enhancementService,
                   enhancementService.isEnhancementEnabled,
                   enhancementService.isConfigured {
                    processingPhase = .enhancing
                    do {
                        let enhancedText = try await enhancementService.enhance(text)
                        let transcription = Transcription(
                            text: text,
                            duration: duration,
                            enhancedText: enhancedText,
                            audioFileURL: permanentURL.absoluteString
                        )
                        modelContext.insert(transcription)
                        try modelContext.save()
                        currentTranscription = transcription
                    } catch {
                        logger.error("Enhancement failed: \(error.localizedDescription)")
                        messageLog += "Enhancement failed: \(error.localizedDescription). Using original transcription.\n"
                        let transcription = Transcription(
                            text: text,
                            duration: duration,
                            audioFileURL: permanentURL.absoluteString
                        )
                        modelContext.insert(transcription)
                        try modelContext.save()
                        currentTranscription = transcription
                    }
                } else {
                    let transcription = Transcription(
                        text: text,
                        duration: duration,
                        audioFileURL: permanentURL.absoluteString
                    )
                    modelContext.insert(transcription)
                    try modelContext.save()
                    currentTranscription = transcription
                }
                
                processingPhase = .completed
                try? await Task.sleep(nanoseconds: 1_500_000_000)
                await finishProcessing()
                
            } catch {
                await handleError(error)
            }
        }
    }
    
    func cancelProcessing() {
        currentTask?.cancel()
        cleanupResources()
    }
    
    private func finishProcessing() {
        isProcessing = false
        processingPhase = .idle
        currentTask = nil
        cleanupResources()
    }
    
    private func handleError(_ error: Error) {
        logger.error("Transcription error: \(error.localizedDescription)")
        errorMessage = error.localizedDescription
        messageLog += "Error: \(error.localizedDescription)\n"
        isProcessing = false
        processingPhase = .idle
        currentTask = nil
        cleanupResources()
    }
    
    private func cleanupResources() {
        whisperContext = nil
    }
}

enum TranscriptionError: Error, LocalizedError {
    case noModelSelected
    case transcriptionCancelled
    
    var errorDescription: String? {
        switch self {
        case .noModelSelected:
            return "No transcription model selected"
        case .transcriptionCancelled:
            return "Transcription was cancelled"
        }
    }
}

================
File: VoiceInk/Services/AudioTranscriptionService.swift
================
import Foundation
import SwiftUI
import AVFoundation
import SwiftData
import os

@MainActor
class AudioTranscriptionService: ObservableObject {
    @Published var isTranscribing = false
    @Published var messageLog = ""
    @Published var currentError: TranscriptionError?
    
    private var whisperContext: WhisperContext?
    private let modelContext: ModelContext
    private let enhancementService: AIEnhancementService?
    private let whisperState: WhisperState
    private let logger = Logger(subsystem: "com.prakashjoshipax.voiceink", category: "AudioTranscriptionService")
    
    enum TranscriptionError: Error {
        case noAudioFile
        case transcriptionFailed
        case modelNotLoaded
        case invalidAudioFormat
    }
    
    init(modelContext: ModelContext, whisperState: WhisperState) {
        self.modelContext = modelContext
        self.whisperState = whisperState
        self.enhancementService = whisperState.enhancementService
    }
    
    func retranscribeAudio(from url: URL, using whisperModel: WhisperModel) async throws -> Transcription {
        guard FileManager.default.fileExists(atPath: url.path) else {
            throw TranscriptionError.noAudioFile
        }
        
        await MainActor.run {
            isTranscribing = true
            messageLog = "Loading model...\n"
        }
        
        // Load the whisper model if needed
        if whisperContext == nil {
            do {
                whisperContext = try await WhisperContext.createContext(path: whisperModel.url.path)
                messageLog += "Model loaded successfully.\n"
            } catch {
                logger.error("‚ùå Failed to load model: \(error.localizedDescription)")
                messageLog += "Failed to load model: \(error.localizedDescription)\n"
                isTranscribing = false
                throw TranscriptionError.modelNotLoaded
            }
        }
        
        guard let whisperContext = whisperContext else {
            isTranscribing = false
            throw TranscriptionError.modelNotLoaded
        }
        
        // Get audio duration
        let audioAsset = AVURLAsset(url: url)
        var duration: TimeInterval = 0
        
        if #available(macOS 13.0, *) {
            let durationValue = try await audioAsset.load(.duration)
            duration = CMTimeGetSeconds(durationValue)
        } else {
            duration = CMTimeGetSeconds(audioAsset.duration)
        }
        
        // Create a permanent copy of the audio file
        let recordingsDirectory = FileManager.default.urls(for: .applicationSupportDirectory, in: .userDomainMask)[0]
            .appendingPathComponent("com.prakashjoshipax.VoiceInk")
            .appendingPathComponent("Recordings")
        
        let fileName = "retranscribed_\(UUID().uuidString).wav"
        let permanentURL = recordingsDirectory.appendingPathComponent(fileName)
        
        do {
            try FileManager.default.copyItem(at: url, to: permanentURL)
        } catch {
            logger.error("‚ùå Failed to create permanent copy of audio: \(error.localizedDescription)")
            messageLog += "Failed to create permanent copy of audio: \(error.localizedDescription)\n"
            isTranscribing = false
            throw error
        }
        
        let permanentURLString = permanentURL.absoluteString
        
        // Transcribe the audio
        messageLog += "Transcribing audio...\n"
        
        do {
            // Read audio samples
            let samples = try readAudioSamples(permanentURL)
            
            // Process with Whisper - using the same prompt as WhisperState
            messageLog += "Setting prompt: \(whisperState.whisperPrompt.transcriptionPrompt)\n"
            await whisperContext.setPrompt(whisperState.whisperPrompt.transcriptionPrompt)
            
            try await whisperContext.fullTranscribe(samples: samples)
            var text = await whisperContext.getTranscription()
            text = text.trimmingCharacters(in: .whitespacesAndNewlines)
            logger.notice("‚úÖ Retranscription completed successfully, length: \(text.count) characters")
            
            // Apply word replacements if enabled
            if UserDefaults.standard.bool(forKey: "IsWordReplacementEnabled") {
                text = WordReplacementService.shared.applyReplacements(to: text)
                logger.notice("‚úÖ Word replacements applied")
            }
            
            // Apply AI enhancement if enabled - using the same enhancement service as WhisperState
            if let enhancementService = enhancementService,
               enhancementService.isEnhancementEnabled,
               enhancementService.isConfigured {
                do {
                    messageLog += "Enhancing transcription with AI...\n"
                    let enhancedText = try await enhancementService.enhance(text)
                    messageLog += "Enhancement completed.\n"
                    
                    let newTranscription = Transcription(
                        text: text,
                        duration: duration,
                        enhancedText: enhancedText,
                        audioFileURL: permanentURLString
                    )
                    modelContext.insert(newTranscription)
                    do {
                        try modelContext.save()
                    } catch {
                        logger.error("‚ùå Failed to save transcription: \(error.localizedDescription)")
                        messageLog += "Failed to save transcription: \(error.localizedDescription)\n"
                    }
                    
                    await MainActor.run {
                        isTranscribing = false
                        messageLog += "Done: \(enhancedText)\n"
                    }
                    
                    return newTranscription
                } catch {
                    messageLog += "Enhancement failed: \(error.localizedDescription). Using original transcription.\n"
                    let newTranscription = Transcription(
                        text: text,
                        duration: duration,
                        audioFileURL: permanentURLString
                    )
                    modelContext.insert(newTranscription)
                    do {
                        try modelContext.save()
                    } catch {
                        logger.error("‚ùå Failed to save transcription: \(error.localizedDescription)")
                        messageLog += "Failed to save transcription: \(error.localizedDescription)\n"
                    }
                    
                    await MainActor.run {
                        isTranscribing = false
                        messageLog += "Done: \(text)\n"
                    }
                    
                    return newTranscription
                }
            } else {
                let newTranscription = Transcription(
                    text: text,
                    duration: duration,
                    audioFileURL: permanentURLString
                )
                modelContext.insert(newTranscription)
                do {
                    try modelContext.save()
                } catch {
                    logger.error("‚ùå Failed to save transcription: \(error.localizedDescription)")
                    messageLog += "Failed to save transcription: \(error.localizedDescription)\n"
                }
                
                await MainActor.run {
                    isTranscribing = false
                    messageLog += "Done: \(text)\n"
                }
                
                return newTranscription
            }
        } catch {
            logger.error("‚ùå Transcription failed: \(error.localizedDescription)")
            messageLog += "Transcription failed: \(error.localizedDescription)\n"
            currentError = .transcriptionFailed
            isTranscribing = false
            throw error
        }
    }
    
    private func readAudioSamples(_ url: URL) throws -> [Float] {
        return try decodeWaveFile(url)
    }
    
    private func decodeWaveFile(_ url: URL) throws -> [Float] {
        let data = try Data(contentsOf: url)
        let floats = stride(from: 44, to: data.count, by: 2).map {
            return data[$0..<$0 + 2].withUnsafeBytes {
                let short = Int16(littleEndian: $0.load(as: Int16.self))
                return max(-1.0, min(Float(short) / 32767.0, 1.0))
            }
        }
        return floats
    }
}

================
File: VoiceInk/Services/BrowserURLService.swift
================
import Foundation
import AppKit
import os

enum BrowserType {
    case safari
    case arc
    case chrome
    case edge
    case firefox
    case brave
    case opera
    case vivaldi
    case orion
    case zen
    
    var scriptName: String {
        switch self {
        case .safari: return "safariURL"
        case .arc: return "arcURL"
        case .chrome: return "chromeURL"
        case .edge: return "edgeURL"
        case .firefox: return "firefoxURL"
        case .brave: return "braveURL"
        case .opera: return "operaURL"
        case .vivaldi: return "vivaldiURL"
        case .orion: return "orionURL"
        case .zen: return "zenURL"
        }
    }
    
    var bundleIdentifier: String {
        switch self {
        case .safari: return "com.apple.Safari"
        case .arc: return "company.thebrowser.Browser"
        case .chrome: return "com.google.Chrome"
        case .edge: return "com.microsoft.edgemac"
        case .firefox: return "org.mozilla.firefox"
        case .brave: return "com.brave.Browser"
        case .opera: return "com.operasoftware.Opera"
        case .vivaldi: return "com.vivaldi.Vivaldi"
        case .orion: return "com.kagi.kagimacOS"
        case .zen: return "app.zen-browser.zen"
        }
    }
    
    var displayName: String {
        switch self {
        case .safari: return "Safari"
        case .arc: return "Arc"
        case .chrome: return "Google Chrome"
        case .edge: return "Microsoft Edge"
        case .firefox: return "Firefox"
        case .brave: return "Brave"
        case .opera: return "Opera"
        case .vivaldi: return "Vivaldi"
        case .orion: return "Orion"
        case .zen: return "Zen Browser"
        }
    }
    
    static var allCases: [BrowserType] {
        [.safari, .arc, .chrome, .edge, .firefox, .brave, .opera, .vivaldi, .orion, .zen]
    }
    
    static var installedBrowsers: [BrowserType] {
        allCases.filter { browser in
            let workspace = NSWorkspace.shared
            return workspace.urlForApplication(withBundleIdentifier: browser.bundleIdentifier) != nil
        }
    }
}

enum BrowserURLError: Error {
    case scriptNotFound
    case executionFailed
    case browserNotRunning
    case noActiveWindow
    case noActiveTab
}

class BrowserURLService {
    static let shared = BrowserURLService()
    
    private let logger = Logger(
        subsystem: "com.prakashjoshipax.VoiceInk",
        category: "browser.applescript"
    )
    
    private init() {}
    
    func getCurrentURL(from browser: BrowserType) async throws -> String {
        guard let scriptURL = Bundle.main.url(forResource: browser.scriptName, withExtension: "scpt") else {
            logger.error("‚ùå AppleScript file not found: \(browser.scriptName).scpt")
            throw BrowserURLError.scriptNotFound
        }
        
        logger.debug("üîç Attempting to execute AppleScript for \(browser.displayName)")
        
        // Check if browser is running
        if !isRunning(browser) {
            logger.error("‚ùå Browser not running: \(browser.displayName)")
            throw BrowserURLError.browserNotRunning
        }
        
        let task = Process()
        task.launchPath = "/usr/bin/osascript"
        task.arguments = [scriptURL.path]
        
        let pipe = Pipe()
        task.standardOutput = pipe
        task.standardError = pipe
        
        do {
            logger.debug("‚ñ∂Ô∏è Executing AppleScript for \(browser.displayName)")
            try task.run()
            task.waitUntilExit()
            
            let data = pipe.fileHandleForReading.readDataToEndOfFile()
            if let output = String(data: data, encoding: .utf8)?.trimmingCharacters(in: .whitespacesAndNewlines) {
                if output.isEmpty {
                    logger.error("‚ùå Empty output from AppleScript for \(browser.displayName)")
                    throw BrowserURLError.noActiveTab
                }
                
                // Check if output contains error messages
                if output.lowercased().contains("error") {
                    logger.error("‚ùå AppleScript error for \(browser.displayName): \(output)")
                    throw BrowserURLError.executionFailed
                }
                
                logger.debug("‚úÖ Successfully retrieved URL from \(browser.displayName): \(output)")
                return output
            } else {
                logger.error("‚ùå Failed to decode output from AppleScript for \(browser.displayName)")
                throw BrowserURLError.executionFailed
            }
        } catch {
            logger.error("‚ùå AppleScript execution failed for \(browser.displayName): \(error.localizedDescription)")
            throw BrowserURLError.executionFailed
        }
    }
    
    func isRunning(_ browser: BrowserType) -> Bool {
        let workspace = NSWorkspace.shared
        let runningApps = workspace.runningApplications
        let isRunning = runningApps.contains { $0.bundleIdentifier == browser.bundleIdentifier }
        logger.debug("\(browser.displayName) running status: \(isRunning)")
        return isRunning
    }
}

================
File: VoiceInk/Services/OllamaService.swift
================
import Foundation
import SwiftUI

class OllamaService: ObservableObject {
    static let defaultBaseURL = "http://localhost:11434"
    
    // MARK: - Response Types
    struct OllamaModel: Codable, Identifiable {
        let name: String
        let modified_at: String
        let size: Int64
        let digest: String
        let details: ModelDetails
        
        var id: String { name }
        
        struct ModelDetails: Codable {
            let format: String
            let family: String
            let families: [String]
            let parameter_size: String
            let quantization_level: String
        }
    }

    struct OllamaModelsResponse: Codable {
        let models: [OllamaModel]
    }

    struct OllamaResponse: Codable {
        let response: String
    }
    
    // MARK: - Published Properties
    @Published var baseURL: String {
        didSet {
            UserDefaults.standard.set(baseURL, forKey: "ollamaBaseURL")
        }
    }
    
    @Published var selectedModel: String {
        didSet {
            UserDefaults.standard.set(selectedModel, forKey: "ollamaSelectedModel")
        }
    }
    
    @Published var availableModels: [OllamaModel] = []
    @Published var isConnected: Bool = false
    @Published var isLoadingModels: Bool = false
    
    private let defaultTemperature: Double = 0.3
    
    init() {
        self.baseURL = UserDefaults.standard.string(forKey: "ollamaBaseURL") ?? Self.defaultBaseURL
        self.selectedModel = UserDefaults.standard.string(forKey: "ollamaSelectedModel") ?? "llama2"
        
        // Initial connection check and model list fetch
        Task {
            await checkConnection()
            if isConnected {
                await refreshModels()
            }
        }
    }
    
    @MainActor
    func checkConnection() async {
        guard let url = URL(string: baseURL) else {
            isConnected = false
            return
        }
        
        do {
            let (_, response) = try await URLSession.shared.data(from: url)
            if let httpResponse = response as? HTTPURLResponse {
                isConnected = (200...299).contains(httpResponse.statusCode)
            } else {
                isConnected = false
            }
        } catch {
            isConnected = false
        }
    }
    
    @MainActor
    func refreshModels() async {
        isLoadingModels = true
        defer { isLoadingModels = false }
        
        do {
            let models = try await fetchAvailableModels()
            availableModels = models
            
            // If selected model is not in available models, select first available
            if !models.contains(where: { $0.name == selectedModel }) && !models.isEmpty {
                selectedModel = models[0].name
            }
        } catch {
            print("Error fetching models: \(error)")
            availableModels = []
        }
    }
    
    private func fetchAvailableModels() async throws -> [OllamaModel] {
        guard let url = URL(string: "\(baseURL)/api/tags") else {
            throw LocalAIError.invalidURL
        }
        
        let (data, _) = try await URLSession.shared.data(from: url)
        let response = try JSONDecoder().decode(OllamaModelsResponse.self, from: data)
        return response.models
    }
    
    func enhance(_ text: String, withSystemPrompt systemPrompt: String? = nil) async throws -> String {
        guard let url = URL(string: "\(baseURL)/api/generate") else {
            throw LocalAIError.invalidURL
        }
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        
        guard let systemPrompt = systemPrompt else {
            throw LocalAIError.invalidRequest
        }
        
        print("\nOllama Enhancement Debug:")
        print("Original Text: \(text)")
        print("System Prompt: \(systemPrompt)")
        
        let body: [String: Any] = [
            "model": selectedModel,
            "prompt": text,
            "system": systemPrompt,
            "temperature": defaultTemperature,
            "stream": false
        ]
        
        request.httpBody = try JSONSerialization.data(withJSONObject: body)
        
        let (data, response) = try await URLSession.shared.data(for: request)
        
        guard let httpResponse = response as? HTTPURLResponse else {
            throw LocalAIError.invalidResponse
        }
        
        switch httpResponse.statusCode {
        case 200:
            let response = try JSONDecoder().decode(OllamaResponse.self, from: data)
            print("Enhanced Text: \(response.response)\n")
            return response.response
        case 404:
            throw LocalAIError.modelNotFound
        case 500:
            throw LocalAIError.serverError
        default:
            throw LocalAIError.invalidResponse
        }
    }
}

// MARK: - Error Types
enum LocalAIError: Error, LocalizedError {
    case invalidURL
    case serviceUnavailable
    case invalidResponse
    case modelNotFound
    case serverError
    case invalidRequest
    
    var errorDescription: String? {
        switch self {
        case .invalidURL:
            return "Invalid Ollama server URL"
        case .serviceUnavailable:
            return "Ollama service is not available"
        case .invalidResponse:
            return "Invalid response from Ollama server"
        case .modelNotFound:
            return "Selected model not found"
        case .serverError:
            return "Ollama server error"
        case .invalidRequest:
            return "System prompt is required"
        }
    }
}

================
File: VoiceInk/Services/PolarService.swift
================
import Foundation
import IOKit

class PolarService {
    private let organizationId = "Org"
    private let apiToken = "Token"
    private let baseURL = "https://api.polar.sh"
    
    struct LicenseValidationResponse: Codable {
        let status: String
        let limit_activations: Int?
        let id: String?
        let activation: ActivationResponse?
    }
    
    struct ActivationResponse: Codable {
        let id: String
    }
    
    struct ActivationRequest: Codable {
        let key: String
        let organization_id: String
        let label: String
        let meta: [String: String]
    }
    
    struct ActivationResult: Codable {
        let id: String
        let license_key: LicenseKeyInfo
    }
    
    struct LicenseKeyInfo: Codable {
        let limit_activations: Int
        let status: String
    }
    
    // Generate a unique device identifier
    private func getDeviceIdentifier() -> String {
        // Use the macOS serial number or a generated UUID that persists
        if let serialNumber = getMacSerialNumber() {
            return serialNumber
        }
        
        // Fallback to a stored UUID if we can't get the serial number
        let defaults = UserDefaults.standard
        if let storedId = defaults.string(forKey: "VoiceInkDeviceIdentifier") {
            return storedId
        }
        
        // Create and store a new UUID if none exists
        let newId = UUID().uuidString
        defaults.set(newId, forKey: "VoiceInkDeviceIdentifier")
        return newId
    }
    
    // Try to get the Mac serial number
    private func getMacSerialNumber() -> String? {
        let platformExpert = IOServiceGetMatchingService(kIOMasterPortDefault, IOServiceMatching("IOPlatformExpertDevice"))
        if platformExpert == 0 { return nil }
        
        defer { IOObjectRelease(platformExpert) }
        
        if let serialNumber = IORegistryEntryCreateCFProperty(platformExpert, "IOPlatformSerialNumber" as CFString, kCFAllocatorDefault, 0) {
            return (serialNumber.takeRetainedValue() as? String)?.trimmingCharacters(in: .whitespacesAndNewlines)
        }
        
        return nil
    }
    
    // Check if a license key requires activation
    func checkLicenseRequiresActivation(_ key: String) async throws -> (isValid: Bool, requiresActivation: Bool, activationsLimit: Int?) {
        let url = URL(string: "\(baseURL)/v1/customer-portal/license-keys/validate")!
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.setValue("Bearer \(apiToken)", forHTTPHeaderField: "Authorization")
        
        let body: [String: Any] = [
            "key": key,
            "organization_id": organizationId
        ]
        
        request.httpBody = try JSONSerialization.data(withJSONObject: body)
        
        let (data, httpResponse) = try await URLSession.shared.data(for: request)
        
        if let httpResponse = httpResponse as? HTTPURLResponse {
            if !(200...299).contains(httpResponse.statusCode) {
                if let errorString = String(data: data, encoding: .utf8) {
                    print("Error Response: \(errorString)")
                }
                throw LicenseError.validationFailed
            }
        }
        
        let validationResponse = try JSONDecoder().decode(LicenseValidationResponse.self, from: data)
        let isValid = validationResponse.status == "granted"
        
        // If limit_activations is nil or 0, the license doesn't require activation
        let requiresActivation = (validationResponse.limit_activations ?? 0) > 0
        
        return (isValid: isValid, requiresActivation: requiresActivation, activationsLimit: validationResponse.limit_activations)
    }
    
    // Activate a license key on this device
    func activateLicenseKey(_ key: String) async throws -> (activationId: String, activationsLimit: Int) {
        let url = URL(string: "\(baseURL)/v1/customer-portal/license-keys/activate")!
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.setValue("Bearer \(apiToken)", forHTTPHeaderField: "Authorization")
        
        let deviceId = getDeviceIdentifier()
        let hostname = Host.current().localizedName ?? "Unknown Mac"
        
        let activationRequest = ActivationRequest(
            key: key,
            organization_id: organizationId,
            label: hostname,
            meta: ["device_id": deviceId]
        )
        
        request.httpBody = try JSONEncoder().encode(activationRequest)
        
        let (data, httpResponse) = try await URLSession.shared.data(for: request)
        
        if let httpResponse = httpResponse as? HTTPURLResponse {
            if !(200...299).contains(httpResponse.statusCode) {
                print("HTTP Status Code: \(httpResponse.statusCode)")
                if let errorString = String(data: data, encoding: .utf8) {
                    print("Error Response: \(errorString)")
                    
                    // Check for specific error messages
                    if errorString.contains("License key does not require activation") {
                        throw LicenseError.activationNotRequired
                    }
                }
                throw LicenseError.activationFailed
            }
        }
        
        let activationResult = try JSONDecoder().decode(ActivationResult.self, from: data)
        return (activationId: activationResult.id, activationsLimit: activationResult.license_key.limit_activations)
    }
    
    // Validate a license key with an activation ID
    func validateLicenseKeyWithActivation(_ key: String, activationId: String) async throws -> Bool {
        let url = URL(string: "\(baseURL)/v1/customer-portal/license-keys/validate")!
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.setValue("Bearer \(apiToken)", forHTTPHeaderField: "Authorization")
        
        let body: [String: Any] = [
            "key": key,
            "organization_id": organizationId,
            "activation_id": activationId
        ]
        
        request.httpBody = try JSONSerialization.data(withJSONObject: body)
        
        let (data, httpResponse) = try await URLSession.shared.data(for: request)
        
        if let httpResponse = httpResponse as? HTTPURLResponse {
            if !(200...299).contains(httpResponse.statusCode) {
                print("HTTP Status Code: \(httpResponse.statusCode)")
                if let errorString = String(data: data, encoding: .utf8) {
                    print("Error Response: \(errorString)")
                }
                throw LicenseError.validationFailed
            }
        }
        
        let validationResponse = try JSONDecoder().decode(LicenseValidationResponse.self, from: data)
        return validationResponse.status == "granted"
    }
}

enum LicenseError: Error, LocalizedError {
    case activationFailed
    case validationFailed
    case activationLimitReached
    case activationNotRequired
    
    var errorDescription: String? {
        switch self {
        case .activationFailed:
            return "Failed to activate license on this device."
        case .validationFailed:
            return "License validation failed."
        case .activationLimitReached:
            return "This license has reached its maximum number of activations."
        case .activationNotRequired:
            return "This license does not require activation."
        }
    }
}

================
File: VoiceInk/Services/ScreenCaptureService.swift
================
import Foundation
import AppKit
import Vision
import os

class ScreenCaptureService: ObservableObject {
    @Published var isCapturing = false
    @Published var lastCapturedText: String?
    
    private let logger = Logger(
        subsystem: "com.prakashjoshipax.VoiceInk",
        category: "aienhancement"
    )
    
    // Maximum number of retries for capture attempts
    private let maxCaptureRetries = 3
    // Delay between capture retries in seconds
    private let captureRetryDelay: TimeInterval = 0.5
    
    private func getActiveWindowInfo() -> (title: String, ownerName: String, windowID: CGWindowID)? {
        // Try multiple window list options to improve reliability
        let options: [CGWindowListOption] = [
            [.optionOnScreenOnly, .excludeDesktopElements],
            [.optionOnScreenOnly],
            []
        ]
        
        for option in options {
            let windowListInfo = CGWindowListCopyWindowInfo(option, kCGNullWindowID) as? [[String: Any]] ?? []
            
            // Find the frontmost window that isn't our own app
            if let frontWindow = windowListInfo.first(where: { info in
                let layer = info[kCGWindowLayer as String] as? Int32 ?? 0
                let ownerName = info[kCGWindowOwnerName as String] as? String ?? ""
                // Exclude our own app and system UI elements
                return layer == 0 && ownerName != "VoiceInk" && !ownerName.contains("Dock") && !ownerName.contains("Menu Bar")
            }) {
                guard let windowID = frontWindow[kCGWindowNumber as String] as? CGWindowID,
                      let ownerName = frontWindow[kCGWindowOwnerName as String] as? String,
                      let title = frontWindow[kCGWindowName as String] as? String else {
                    continue
                }
                
                return (title: title, ownerName: ownerName, windowID: windowID)
            }
        }
        
        // If we couldn't find a window with the normal approach, try a more aggressive approach
        logger.notice("Trying fallback window detection approach")
        let allWindows = CGWindowListCopyWindowInfo(.optionAll, kCGNullWindowID) as? [[String: Any]] ?? []
        
        // Find any visible window that isn't our own
        if let visibleWindow = allWindows.first(where: { info in
            let ownerName = info[kCGWindowOwnerName as String] as? String ?? ""
            let alpha = info[kCGWindowAlpha as String] as? Double ?? 0
            return ownerName != "VoiceInk" && !ownerName.contains("Dock") && alpha > 0
        }) {
            let windowID = visibleWindow[kCGWindowNumber as String] as? CGWindowID ?? 0
            let ownerName = visibleWindow[kCGWindowOwnerName as String] as? String ?? "Unknown App"
            let title = visibleWindow[kCGWindowName as String] as? String ?? "Unknown Window"
            
            logger.notice("Found fallback window: \(title, privacy: .public) (\(ownerName, privacy: .public))")
            return (title: title, ownerName: ownerName, windowID: windowID)
        }
        
        logger.notice("‚ùå No suitable window found for capture")
        return nil
    }
    
    func captureActiveWindow() -> NSImage? {
        guard let windowInfo = getActiveWindowInfo() else {
            logger.notice("‚ùå Failed to get window info for capture")
            return captureFullScreen() // Fallback to full screen capture
        }
        
        // Try to capture the specific window
        let cgImage = CGWindowListCreateImage(
            .null,
            .optionIncludingWindow,
            windowInfo.windowID,
            [.boundsIgnoreFraming, .bestResolution]
        )
        
        if let cgImage = cgImage {
            logger.notice("‚úÖ Successfully captured window")
            return NSImage(cgImage: cgImage, size: NSSize(width: cgImage.width, height: cgImage.height))
        } else {
            logger.notice("‚ö†Ô∏è Window-specific capture failed, trying fallback methods")
            return captureFullScreen() // Fallback to full screen
        }
    }
    
    private func captureFullScreen() -> NSImage? {
        logger.notice("üì∫ Attempting full screen capture as fallback")
        
        // Capture the entire screen
        if let screen = NSScreen.main {
            let rect = screen.frame
            let cgImage = CGWindowListCreateImage(
                rect,
                .optionOnScreenOnly,
                kCGNullWindowID,
                [.bestResolution]
            )
            
            if let cgImage = cgImage {
                logger.notice("‚úÖ Full screen capture successful")
                return NSImage(cgImage: cgImage, size: NSSize(width: cgImage.width, height: cgImage.height))
            }
        }
        
        logger.notice("‚ùå All capture methods failed")
        return nil
    }
    
    func extractText(from image: NSImage, completion: @escaping (String?) -> Void) {
        guard let cgImage = image.cgImage(forProposedRect: nil, context: nil, hints: nil) else {
            logger.notice("‚ùå Failed to convert NSImage to CGImage for text extraction")
            completion(nil)
            return
        }
        
        let requestHandler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        let request = VNRecognizeTextRequest { request, error in
            if let error = error {
                self.logger.notice("‚ùå Text recognition error: \(error.localizedDescription, privacy: .public)")
                completion(nil)
                return
            }
            
            guard let observations = request.results as? [VNRecognizedTextObservation] else {
                self.logger.notice("‚ùå No text observations found")
                completion(nil)
                return
            }
            
            let text = observations.compactMap { observation in
                observation.topCandidates(1).first?.string
            }.joined(separator: "\n")
            
            if text.isEmpty {
                self.logger.notice("‚ö†Ô∏è Text extraction returned empty result")
                completion(nil)
            } else {
                self.logger.notice("‚úÖ Text extraction successful, found \(text.count, privacy: .public) characters")
                completion(text)
            }
        }
        
        // Configure the recognition level
        request.recognitionLevel = .accurate
        request.usesLanguageCorrection = true
        
        do {
            try requestHandler.perform([request])
        } catch {
            logger.notice("‚ùå Failed to perform text recognition: \(error.localizedDescription, privacy: .public)")
            completion(nil)
        }
    }
    
    func captureAndExtractText() async -> String? {
        guard !isCapturing else { 
            logger.notice("‚ö†Ô∏è Screen capture already in progress, skipping")
            return nil 
        }
        
        isCapturing = true
        defer { 
            DispatchQueue.main.async {
                self.isCapturing = false
            }
        }
        
        logger.notice("üé¨ Starting screen capture")
        
        // Try multiple times to get a successful capture
        for attempt in 1...maxCaptureRetries {
            logger.notice("üîÑ Capture attempt \(attempt, privacy: .public) of \(self.maxCaptureRetries, privacy: .public)")
            
            // First get window info
            guard let windowInfo = getActiveWindowInfo() else {
                logger.notice("‚ùå Failed to get window info on attempt \(attempt, privacy: .public)")
                if attempt < maxCaptureRetries {
                    try? await Task.sleep(nanoseconds: UInt64(captureRetryDelay * 1_000_000_000))
                    continue
                }
                return nil
            }
            
            logger.notice("üéØ Found window: \(windowInfo.title, privacy: .public) (\(windowInfo.ownerName, privacy: .public))")
            
            // Start with window metadata
            var contextText = """
            Active Window: \(windowInfo.title)
            Application: \(windowInfo.ownerName)
            
            """
            
            // Then capture and process window content
            if let capturedImage = captureActiveWindow() {
                if let extractedText = await withCheckedContinuation({ continuation in
                    extractText(from: capturedImage) { text in
                        continuation.resume(returning: text)
                    }
                }) {
                    contextText += "Window Content:\n\(extractedText)"
                    // Log immediately after text extraction
                    logger.notice("‚úÖ Captured: \(contextText, privacy: .public)")
                    
                    // Ensure lastCapturedText is set on the main thread
                    await MainActor.run {
                        self.lastCapturedText = contextText
                    }
                    
                    return contextText
                } else {
                    logger.notice("‚ö†Ô∏è Failed to extract text from image on attempt \(attempt, privacy: .public)")
                }
            } else {
                logger.notice("‚ö†Ô∏è Failed to capture window image on attempt \(attempt, privacy: .public)")
            }
            
            if attempt < maxCaptureRetries {
                try? await Task.sleep(nanoseconds: UInt64(captureRetryDelay * 1_000_000_000))
            }
        }
        
        logger.notice("‚ùå All capture attempts failed")
        return nil
    }
}

================
File: VoiceInk/Services/UserDefaultsManager.swift
================
import Foundation

extension UserDefaults {
    enum Keys {
        static let aiProviderApiKey = "VoiceInkAIProviderKey"
        static let licenseKey = "VoiceInkLicense"
        static let trialStartDate = "VoiceInkTrialStartDate"
    }
    
    // MARK: - AI Provider API Key
    var aiProviderApiKey: String? {
        get { string(forKey: Keys.aiProviderApiKey) }
        set { setValue(newValue, forKey: Keys.aiProviderApiKey) }
    }
    
    // MARK: - License Key
    var licenseKey: String? {
        get { string(forKey: Keys.licenseKey) }
        set { setValue(newValue, forKey: Keys.licenseKey) }
    }
    
    // MARK: - Trial Start Date
    var trialStartDate: Date? {
        get { object(forKey: Keys.trialStartDate) as? Date }
        set { setValue(newValue, forKey: Keys.trialStartDate) }
    }
}

================
File: VoiceInk/Services/WordReplacementService.swift
================
import Foundation

class WordReplacementService {
    static let shared = WordReplacementService()
    
    private init() {}
    
    func applyReplacements(to text: String) -> String {
        guard let replacements = UserDefaults.standard.dictionary(forKey: "wordReplacements") as? [String: String],
              !replacements.isEmpty else {
            return text // No replacements to apply
        }
        
        var modifiedText = text
        
        // Apply each replacement (case-insensitive, whole word)
        for (original, replacement) in replacements {
            // Create a regular expression that matches the word boundaries
            let pattern = "\\b\(NSRegularExpression.escapedPattern(for: original))\\b"
            if let regex = try? NSRegularExpression(pattern: pattern, options: .caseInsensitive) {
                let range = NSRange(modifiedText.startIndex..., in: modifiedText)
                modifiedText = regex.stringByReplacingMatches(
                    in: modifiedText,
                    options: [],
                    range: range,
                    withTemplate: replacement
                )
            }
        }
        
        return modifiedText
    }
}

================
File: VoiceInk/ViewModels/LicenseViewModel.swift
================
import Foundation
import AppKit

@MainActor
class LicenseViewModel: ObservableObject {
    enum LicenseState: Equatable {
        case trial(daysRemaining: Int)
        case trialExpired
        case licensed
    }
    
    @Published private(set) var licenseState: LicenseState = .trial(daysRemaining: 7)  // Default to trial
    @Published var licenseKey: String = ""
    @Published var isValidating = false
    @Published var validationMessage: String?
    @Published private(set) var activationsLimit: Int = 0
    
    private let trialPeriodDays = 7
    private let polarService = PolarService()
    private let userDefaults = UserDefaults.standard
    
    init() {
        checkLicenseState()
    }
    
    func startTrial() {
        // Only set trial start date if it hasn't been set before
        if userDefaults.trialStartDate == nil {
            userDefaults.trialStartDate = Date()
            licenseState = .trial(daysRemaining: trialPeriodDays)
            NotificationCenter.default.post(name: .licenseStatusChanged, object: nil)
        }
    }
    
    private func checkLicenseState() {
        // Check for existing license key
        if let licenseKey = userDefaults.licenseKey {
            self.licenseKey = licenseKey
            
            // Check if this license requires activation
            if userDefaults.bool(forKey: "VoiceInkLicenseRequiresActivation") {
                // If we have an activation ID, we need to validate it
                if let activationId = userDefaults.activationId {
                    Task {
                        do {
                            let isValid = try await polarService.validateLicenseKeyWithActivation(licenseKey, activationId: activationId)
                            if isValid {
                                licenseState = .licensed
                            } else {
                                // If validation fails, we'll need to reactivate
                                userDefaults.activationId = nil
                                licenseState = .trialExpired
                            }
                        } catch {
                            // If there's an error, we'll need to reactivate
                            userDefaults.activationId = nil
                            licenseState = .trialExpired
                        }
                    }
                } else {
                    // We have a license key but no activation ID, so we need to activate
                    licenseState = .licensed
                }
            } else {
                // This license doesn't require activation (unlimited devices)
                licenseState = .licensed
            }
            return
        }
        
        // Check if this is first launch
        let hasLaunchedBefore = userDefaults.bool(forKey: "VoiceInkHasLaunchedBefore")
        if !hasLaunchedBefore {
            // First launch - start trial automatically
            userDefaults.set(true, forKey: "VoiceInkHasLaunchedBefore")
            startTrial()
            return
        }
        
        // Only check trial if not licensed and not first launch
        if let trialStartDate = userDefaults.trialStartDate {
            let daysSinceTrialStart = Calendar.current.dateComponents([.day], from: trialStartDate, to: Date()).day ?? 0
            
            if daysSinceTrialStart >= trialPeriodDays {
                licenseState = .trialExpired
            } else {
                licenseState = .trial(daysRemaining: trialPeriodDays - daysSinceTrialStart)
            }
        } else {
            // No trial has been started yet - start it now
            startTrial()
        }
    }
    
    var canUseApp: Bool {
        switch licenseState {
        case .licensed, .trial:
            return true
        case .trialExpired:
            return false
        }
    }
    
    func openPurchaseLink() {
        if let url = URL(string: "https://tryvoiceink.com/buy") {
            NSWorkspace.shared.open(url)
        }
    }
    
    func validateLicense() async {
        guard !licenseKey.isEmpty else {
            validationMessage = "Please enter a license key"
            return
        }
        
        isValidating = true
        
        do {
            // First, check if the license is valid and if it requires activation
            let licenseCheck = try await polarService.checkLicenseRequiresActivation(licenseKey)
            
            if !licenseCheck.isValid {
                validationMessage = "Invalid license key"
                isValidating = false
                return
            }
            
            // Store the license key
            userDefaults.licenseKey = licenseKey
            
            // Handle based on whether activation is required
            if licenseCheck.requiresActivation {
                // If we already have an activation ID, validate with it
                if let activationId = userDefaults.activationId {
                    let isValid = try await polarService.validateLicenseKeyWithActivation(licenseKey, activationId: activationId)
                    if isValid {
                        // Existing activation is valid
                        licenseState = .licensed
                        validationMessage = "License activated successfully!"
                        NotificationCenter.default.post(name: .licenseStatusChanged, object: nil)
                        isValidating = false
                        return
                    }
                }
                
                // Need to create a new activation
                let (activationId, limit) = try await polarService.activateLicenseKey(licenseKey)
                
                // Store activation details
                userDefaults.activationId = activationId
                userDefaults.set(true, forKey: "VoiceInkLicenseRequiresActivation")
                self.activationsLimit = limit
                
            } else {
                // This license doesn't require activation (unlimited devices)
                userDefaults.activationId = nil
                userDefaults.set(false, forKey: "VoiceInkLicenseRequiresActivation")
                self.activationsLimit = licenseCheck.activationsLimit ?? 0
            }
            
            // Update the license state
            licenseState = .licensed
            validationMessage = "License activated successfully!"
            NotificationCenter.default.post(name: .licenseStatusChanged, object: nil)
            
        } catch LicenseError.activationLimitReached {
            validationMessage = "This license has reached its maximum number of activations."
        } catch LicenseError.activationNotRequired {
            // This is actually a success case for unlimited licenses
            userDefaults.licenseKey = licenseKey
            userDefaults.activationId = nil
            userDefaults.set(false, forKey: "VoiceInkLicenseRequiresActivation")
            self.activationsLimit = 0
            
            licenseState = .licensed
            validationMessage = "License activated successfully!"
            NotificationCenter.default.post(name: .licenseStatusChanged, object: nil)
        } catch {
            validationMessage = "Error validating license: \(error.localizedDescription)"
        }
        
        isValidating = false
    }
    
    func removeLicense() {
        // Remove both license key and trial data
        userDefaults.licenseKey = nil
        userDefaults.activationId = nil
        userDefaults.set(false, forKey: "VoiceInkLicenseRequiresActivation")
        userDefaults.trialStartDate = nil
        userDefaults.set(false, forKey: "VoiceInkHasLaunchedBefore")  // Allow trial to restart
        
        licenseState = .trial(daysRemaining: trialPeriodDays)  // Reset to trial state
        licenseKey = ""
        validationMessage = nil
        NotificationCenter.default.post(name: .licenseStatusChanged, object: nil)
        checkLicenseState()
    }
}

extension Notification.Name {
    static let licenseStatusChanged = Notification.Name("licenseStatusChanged")
}

// Add UserDefaults extensions for storing activation ID
extension UserDefaults {
    var activationId: String? {
        get { string(forKey: "VoiceInkActivationId") }
        set { set(newValue, forKey: "VoiceInkActivationId") }
    }
}

================
File: VoiceInk/Views/Components/ProBadge.swift
================
import SwiftUI

struct ProBadge: View {
    var body: some View {
        Text("PRO")
            .font(.system(size: 10, weight: .semibold))
            .foregroundColor(.white)
            .padding(.horizontal, 6)
            .padding(.vertical, 2)
            .background(
                RoundedRectangle(cornerRadius: 4)
                    .fill(Color.blue.opacity(0.8))
            )
    }
}

#Preview {
    ProBadge()
}

================
File: VoiceInk/Views/Components/TrialMessageView.swift
================
import SwiftUI

struct TrialMessageView: View {
    let message: String
    let type: MessageType
    
    enum MessageType {
        case warning
        case expired
        case info
    }
    
    var body: some View {
        HStack(spacing: 12) {
            Image(systemName: icon)
                .font(.system(size: 20))
                .foregroundColor(iconColor)
            
            VStack(alignment: .leading, spacing: 4) {
                Text(title)
                    .font(.headline)
                Text(message)
                    .font(.subheadline)
                    .foregroundColor(.secondary)
            }
            
            Spacer()
            
            if type == .expired || type == .warning {
                Button(action: {
                    if let url = URL(string: "https://tryvoiceink.com/buy") {
                        NSWorkspace.shared.open(url)
                    }
                }) {
                    Text(type == .expired ? "Upgrade Now" : "Upgrade")
                        .font(.headline)
                }
                .buttonStyle(.borderedProminent)
            }
        }
        .padding()
        .background(backgroundColor)
        .cornerRadius(12)
    }
    
    private var icon: String {
        switch type {
        case .warning: return "exclamationmark.triangle.fill"
        case .expired: return "xmark.circle.fill"
        case .info: return "info.circle.fill"
        }
    }
    
    private var iconColor: Color {
        switch type {
        case .warning: return .orange
        case .expired: return .red
        case .info: return .blue
        }
    }
    
    private var title: String {
        switch type {
        case .warning: return "Trial Ending Soon"
        case .expired: return "Trial Expired"
        case .info: return "Trial Active"
        }
    }
    
    private var backgroundColor: Color {
        switch type {
        case .warning: return Color.orange.opacity(0.1)
        case .expired: return Color.red.opacity(0.1)
        case .info: return Color.blue.opacity(0.1)
        }
    }
}

================
File: VoiceInk/Views/Components/VideoCTAView.swift
================
import SwiftUI

struct VideoCTAView: View {
    let url: String
    let subtitle: String
    
    var body: some View {
        Link(destination: URL(string: url)!) {
            HStack(spacing: 12) {
                Image(systemName: "play.circle.fill")
                    .symbolRenderingMode(.hierarchical)
                    .font(.system(size: 24))
                    .foregroundStyle(Color.blue)
                
                VStack(alignment: .leading, spacing: 2) {
                    Text("Watch how it works")
                        .font(.system(size: 15, weight: .semibold))
                        .foregroundColor(.primary)
                    
                    Text(subtitle)
                        .font(.system(size: 13))
                        .foregroundColor(.secondary)
                }
                
                Spacer()
                
                Image(systemName: "chevron.right")
                    .font(.system(size: 14, weight: .medium))
                    .foregroundColor(.secondary)
            }
            .padding(16)
            .background(
                RoundedRectangle(cornerRadius: 12)
                    .fill(Color(.windowBackgroundColor).opacity(0.9))
            )
            .overlay(
                RoundedRectangle(cornerRadius: 12)
                    .stroke(Color.secondary.opacity(0.1), lineWidth: 1)
            )
        }
        .buttonStyle(.plain)
    }
}

================
File: VoiceInk/Views/Dictionary/DictionarySettingsView.swift
================
import SwiftUI

struct DictionarySettingsView: View {
    @State private var selectedSection: DictionarySection = .spellings
    let whisperPrompt: WhisperPrompt
    
    enum DictionarySection: String, CaseIterable {
        case spellings = "Correct Spellings"
        case replacements = "Word Replacements"
        
        var description: String {
            switch self {
            case .spellings:
                return "Train VoiceInk to recognize industry terms, names, and technical words"
            case .replacements:
                return "Automatically replace specific words/phrases with custom formatted text "
            }
        }
        
        var icon: String {
            switch self {
            case .spellings:
                return "character.book.closed.fill"
            case .replacements:
                return "arrow.2.squarepath"
            }
        }
    }
    
    var body: some View {
        ScrollView {
            VStack(spacing: 0) {
                heroSection
                mainContent
            }
        }
        .frame(minWidth: 600, minHeight: 500)
        .background(Color(NSColor.controlBackgroundColor))
    }
    
    private var heroSection: some View {
        VStack(spacing: 24) {
            Image(systemName: "brain.filled.head.profile")
                .font(.system(size: 40))
                .foregroundStyle(.blue)
                .padding(20)
                .background(Circle()
                    .fill(Color(.windowBackgroundColor).opacity(0.9))
                    .shadow(color: .black.opacity(0.1), radius: 10, y: 5))
            
            VStack(spacing: 8) {
                Text("Dictionary Settings")
                    .font(.system(size: 28, weight: .bold))
                Text("Enhance VoiceInk's transcription accuracy by teaching it your vocabulary")
                    .font(.system(size: 15))
                    .foregroundStyle(.secondary)
                    .multilineTextAlignment(.center)
                    .frame(maxWidth: 400)
            }
        }
        .padding(.vertical, 40)
        .frame(maxWidth: .infinity)
    }
    
    private var mainContent: some View {
        VStack(spacing: 40) {
            sectionSelector
            
            selectedSectionContent
        }
        .padding(.horizontal, 32)
        .padding(.vertical, 40)
    }
    
    private var sectionSelector: some View {
        VStack(alignment: .leading, spacing: 20) {
            Text("Select Section")
                .font(.title2)
                .fontWeight(.semibold)
            
            HStack(spacing: 20) {
                ForEach(DictionarySection.allCases, id: \.self) { section in
                    SectionCard(
                        section: section,
                        isSelected: selectedSection == section,
                        action: { selectedSection = section }
                    )
                }
            }
        }
    }
    
    private var selectedSectionContent: some View {
        VStack(alignment: .leading, spacing: 20) {
            switch selectedSection {
            case .spellings:
                DictionaryView(whisperPrompt: whisperPrompt)
                    .background(Color(.windowBackgroundColor).opacity(0.4))
                    .cornerRadius(10)
            case .replacements:
                WordReplacementView()
                    .background(Color(.windowBackgroundColor).opacity(0.4))
                    .cornerRadius(10)
            }
        }
    }
}

struct SectionCard: View {
    let section: DictionarySettingsView.DictionarySection
    let isSelected: Bool
    let action: () -> Void
    
    var body: some View {
        Button(action: action) {
            VStack(alignment: .leading, spacing: 12) {
                Image(systemName: section.icon)
                    .font(.system(size: 28))
                    .symbolRenderingMode(.hierarchical)
                    .foregroundStyle(isSelected ? .blue : .secondary)
                
                VStack(alignment: .leading, spacing: 4) {
                    Text(section.rawValue)
                        .font(.headline)
                    
                    Text(section.description)
                        .font(.subheadline)
                        .foregroundStyle(.secondary)
                        .fixedSize(horizontal: false, vertical: true)
                }
            }
            .frame(maxWidth: .infinity, alignment: .leading)
            .padding()
            .background(
                RoundedRectangle(cornerRadius: 16)
                    .fill(Color(.windowBackgroundColor).opacity(0.4))
                    .shadow(color: isSelected ? .blue.opacity(0.2) : .clear, radius: 8, y: 4)
                    .overlay(
                        RoundedRectangle(cornerRadius: 16)
                            .stroke(isSelected ? .blue.opacity(0.5) : .clear, lineWidth: 2)
                    )
            )
        }
        .buttonStyle(.plain)
    }
}

================
File: VoiceInk/Views/Dictionary/DictionaryView.swift
================
import SwiftUI

struct DictionaryItem: Identifiable, Hashable, Codable {
    let id: UUID
    var word: String
    var dateAdded: Date
    var isEnabled: Bool
    
    init(id: UUID = UUID(), word: String, dateAdded: Date = Date(), isEnabled: Bool = true) {
        self.id = id
        self.word = word
        self.dateAdded = dateAdded
        self.isEnabled = isEnabled
    }
}

class DictionaryManager: ObservableObject {
    @Published var items: [DictionaryItem] = []
    private let saveKey = "CustomDictionaryItems"
    private let whisperPrompt: WhisperPrompt
    
    init(whisperPrompt: WhisperPrompt) {
        self.whisperPrompt = whisperPrompt
        loadItems()
    }
    
    private func loadItems() {
        guard let data = UserDefaults.standard.data(forKey: saveKey) else { return }
        
        if let savedItems = try? JSONDecoder().decode([DictionaryItem].self, from: data) {
            items = savedItems.sorted(by: { $0.dateAdded > $1.dateAdded })
            updatePrompt()
        }
    }
    
    private func saveItems() {
        if let encoded = try? JSONEncoder().encode(items) {
            UserDefaults.standard.set(encoded, forKey: saveKey)
            updatePrompt()
        }
    }
    
    private func updatePrompt() {
        Task { @MainActor in
            await whisperPrompt.saveDictionaryItems(items)
        }
    }
    
    func addWord(_ word: String) {
        let normalizedWord = word.trimmingCharacters(in: .whitespacesAndNewlines)
        guard !items.contains(where: { $0.word.lowercased() == normalizedWord.lowercased() }) else {
            return
        }
        
        let newItem = DictionaryItem(word: normalizedWord)
        items.insert(newItem, at: 0)
        saveItems()
    }
    
    func removeWord(_ word: String) {
        items.removeAll(where: { $0.word == word })
        saveItems()
    }
    
    func toggleWordState(id: UUID) {
        if let index = items.firstIndex(where: { $0.id == id }) {
            items[index].isEnabled.toggle()
            saveItems()
        }
    }
    
    var allWords: [String] {
        items.filter { $0.isEnabled }.map { $0.word }
    }
}

struct DictionaryView: View {
    @StateObject private var dictionaryManager: DictionaryManager
    @ObservedObject var whisperPrompt: WhisperPrompt
    @State private var newWord = ""
    @State private var showAlert = false
    @State private var alertMessage = ""
    
    init(whisperPrompt: WhisperPrompt) {
        self.whisperPrompt = whisperPrompt
        _dictionaryManager = StateObject(wrappedValue: DictionaryManager(whisperPrompt: whisperPrompt))
    }
    
    var body: some View {
        VStack(alignment: .leading, spacing: 20) {
            // Information Section
            GroupBox {
                Label {
                    Text("Add words to help VoiceInk recognize them properly(154 chars max, ~25 words). Works independently of AI enhancement.")
                        .font(.system(size: 12))
                        .foregroundColor(.secondary)
                        .fixedSize(horizontal: false, vertical: true)
                } icon: {
                    Image(systemName: "info.circle.fill")
                        .foregroundColor(.blue)
                }
            }
            
            // Input Section
            HStack(spacing: 8) {
                TextField("Add word to dictionary", text: $newWord)
                    .textFieldStyle(.roundedBorder)
                    .font(.system(size: 13))
                    .onSubmit { addWord() }
                
                Button(action: addWord) {
                    Image(systemName: "plus.circle.fill")
                        .symbolRenderingMode(.hierarchical)
                        .foregroundStyle(.blue)
                        .font(.system(size: 16, weight: .semibold))
                }
                .buttonStyle(.borderless)
                .disabled(newWord.isEmpty)
                .help("Add word")
            }
            
            // Words List
            if !dictionaryManager.items.isEmpty {
                VStack(alignment: .leading, spacing: 12) {
                    Text("Dictionary Items (\(dictionaryManager.items.count))")
                        .font(.system(size: 12, weight: .medium))
                        .foregroundColor(.secondary)
                    
                    Text("Toggle words on/off to optimize recognition. Disable unnecessary words to improve local AI model performance.")
                        .font(.system(size: 11))
                        .foregroundColor(.secondary)
                        .padding(.bottom, 4)
                    
                    ScrollView {
                        let columns = [
                            GridItem(.adaptive(minimum: 240, maximum: .infinity), spacing: 12)
                        ]
                        
                        LazyVGrid(columns: columns, alignment: .leading, spacing: 12) {
                            ForEach(dictionaryManager.items) { item in
                                DictionaryItemView(item: item) {
                                    dictionaryManager.removeWord(item.word)
                                } onToggle: {
                                    dictionaryManager.toggleWordState(id: item.id)
                                }
                            }
                        }
                        .padding(.vertical, 4)
                    }
                    .frame(maxHeight: 200)
                }
                .padding(.top, 4)
            }
        }
        .padding()
        .alert("Dictionary", isPresented: $showAlert) {
            Button("OK", role: .cancel) {}
        } message: {
            Text(alertMessage)
        }
    }
    
    private func addWord() {
        let word = newWord.trimmingCharacters(in: .whitespacesAndNewlines)
        guard !word.isEmpty else { return }
        
        if dictionaryManager.items.contains(where: { $0.word.lowercased() == word.lowercased() }) {
            alertMessage = "'\(word)' is already in the dictionary"
            showAlert = true
            return
        }
        
        dictionaryManager.addWord(word)
        newWord = ""
    }
}

struct DictionaryItemView: View {
    let item: DictionaryItem
    let onDelete: () -> Void
    let onToggle: () -> Void
    @State private var isHovered = false
    
    var body: some View {
        HStack(spacing: 6) {
            Text(item.word)
                .font(.system(size: 13))
                .lineLimit(1)
                .foregroundColor(item.isEnabled ? .primary : .secondary)
            
            Spacer(minLength: 8)
            
            HStack(spacing: 4) {
                Button(action: onToggle) {
                    Image(systemName: item.isEnabled ? "checkmark.circle.fill" : "circle")
                        .symbolRenderingMode(.hierarchical)
                        .foregroundStyle(item.isEnabled ? .green : .secondary)
                        .contentTransition(.symbolEffect(.replace))
                }
                .buttonStyle(.borderless)
                .help(item.isEnabled ? "Disable word" : "Enable word")
                
                Button(action: onDelete) {
                    Image(systemName: "xmark.circle.fill")
                        .symbolRenderingMode(.hierarchical)
                        .foregroundStyle(isHovered ? .red : .secondary)
                        .contentTransition(.symbolEffect(.replace))
                }
                .buttonStyle(.borderless)
                .help("Remove word")
            }
            .onHover { hover in
                withAnimation(.easeInOut(duration: 0.2)) {
                    isHovered = hover
                }
            }
        }
        .padding(.horizontal, 8)
        .padding(.vertical, 6)
        .background {
            RoundedRectangle(cornerRadius: 6)
                .fill(Color(.windowBackgroundColor).opacity(0.4))
        }
        .overlay {
            RoundedRectangle(cornerRadius: 6)
                .stroke(Color.secondary.opacity(item.isEnabled ? 0.2 : 0.1), lineWidth: 1)
        }
        .opacity(item.isEnabled ? 1 : 0.7)
        .shadow(color: Color.black.opacity(item.isEnabled ? 0.05 : 0), radius: 2, y: 1)
    }
}

================
File: VoiceInk/Views/Dictionary/WordReplacementView.swift
================
import SwiftUI

class WordReplacementManager: ObservableObject {
    @Published var replacements: [String: String] {
        didSet {
            UserDefaults.standard.set(replacements, forKey: "wordReplacements")
        }
    }
    
    @Published var isEnabled: Bool {
        didSet {
            UserDefaults.standard.set(isEnabled, forKey: "IsWordReplacementEnabled")
        }
    }
    
    init() {
        self.replacements = UserDefaults.standard.dictionary(forKey: "wordReplacements") as? [String: String] ?? [:]
        self.isEnabled = UserDefaults.standard.bool(forKey: "IsWordReplacementEnabled")
    }
    
    func addReplacement(original: String, replacement: String) {
        replacements[original] = replacement
    }
    
    func removeReplacement(original: String) {
        replacements.removeValue(forKey: original)
    }
}

struct WordReplacementView: View {
    @StateObject private var manager = WordReplacementManager()
    @State private var showAddReplacementModal = false
    @State private var showAlert = false
    @State private var alertMessage = ""
    
    var body: some View {
        VStack(alignment: .leading, spacing: 20) {
            // Info Section with Toggle
            GroupBox {
                HStack {
                    Label {
                        Text("Define word replacements to automatically replace specific words or phrases")
                            .font(.system(size: 12))
                            .foregroundColor(.secondary)
                            .fixedSize(horizontal: false, vertical: true)
                            .frame(alignment: .leading)
                    } icon: {
                        Image(systemName: "info.circle.fill")
                            .foregroundColor(.blue)
                    }
                    
                    Spacer()
                    
                    Toggle("Enable", isOn: $manager.isEnabled)
                        .toggleStyle(.switch)
                        .labelsHidden()
                        .help("Enable automatic word replacement after transcription")
                }
            }
            
            VStack(spacing: 0) {
                // Header with action button
                HStack {
                    Text("Word Replacements")
                        .font(.headline)
                    
                    Spacer()
                    
                    Button(action: { showAddReplacementModal = true }) {
                        Image(systemName: "plus")
                    }
                    .buttonStyle(.borderless)
                    .help("Add new replacement")
                }
                .padding(.horizontal)
                .padding(.vertical, 8)
                .background(Color(.controlBackgroundColor))
                
                Divider()
                
                // Content
                if manager.replacements.isEmpty {
                    EmptyStateView(showAddModal: $showAddReplacementModal)
                } else {
                    ScrollView {
                        LazyVStack(spacing: 0) {
                            ForEach(Array(manager.replacements.keys.sorted()), id: \.self) { original in
                                ReplacementRow(
                                    original: original,
                                    replacement: manager.replacements[original] ?? "",
                                    onDelete: { manager.removeReplacement(original: original) }
                                )
                                
                                if original != manager.replacements.keys.sorted().last {
                                    Divider()
                                        .padding(.leading, 32)
                                }
                            }
                        }
                        .background(Color(.controlBackgroundColor))
                    }
                }
            }
        }
        .padding()
        .sheet(isPresented: $showAddReplacementModal) {
            AddReplacementSheet(manager: manager)
        }
    }
}

struct EmptyStateView: View {
    @Binding var showAddModal: Bool
    
    var body: some View {
        VStack(spacing: 12) {
            Image(systemName: "text.word.spacing")
                .font(.system(size: 32))
                .foregroundColor(.secondary)
            
            Text("No Replacements")
                .font(.headline)
            
            Text("Add word replacements to automatically replace text during AI enhancement.")
                .font(.subheadline)
                .foregroundColor(.secondary)
                .multilineTextAlignment(.center)
                .frame(maxWidth: 250)
            
            Button("Add Replacement") {
                showAddModal = true
            }
            .buttonStyle(.borderedProminent)
            .controlSize(.regular)
            .padding(.top, 8)
        }
        .padding()
        .frame(maxWidth: .infinity, maxHeight: .infinity)
    }
}

struct AddReplacementSheet: View {
    @ObservedObject var manager: WordReplacementManager
    @Environment(\.dismiss) private var dismiss
    @State private var originalWord = ""
    @State private var replacementWord = ""
    
    var body: some View {
        VStack(spacing: 0) {
            // Header
            HStack {
                Button("Cancel", role: .cancel) {
                    dismiss()
                }
                .buttonStyle(.borderless)
                .keyboardShortcut(.escape, modifiers: [])
                
                Spacer()
                
                Text("Add Word Replacement")
                    .font(.headline)
                
                Spacer()
                
                Button("Add") {
                    addReplacement()
                }
                .buttonStyle(.borderedProminent)
                .controlSize(.small)
                .disabled(originalWord.isEmpty || replacementWord.isEmpty)
                .keyboardShortcut(.return, modifiers: [])
            }
            .padding(.horizontal)
            .padding(.vertical, 12)
            .background(Color(.windowBackgroundColor).opacity(0.4))
            
            Divider()
            
            ScrollView {
                VStack(spacing: 20) {
                    // Description
                    Text("Define a word or phrase to be automatically replaced during AI enhancement.")
                        .font(.subheadline)
                        .foregroundColor(.secondary)
                        .frame(maxWidth: .infinity, alignment: .leading)
                        .padding(.horizontal)
                        .padding(.top, 8)
                    
                    // Form Content
                    VStack(spacing: 16) {
                        // Original Text Section
                        VStack(alignment: .leading, spacing: 6) {
                            HStack {
                                Text("Original Text")
                                    .font(.headline)
                                    .foregroundColor(.primary)
                                
                                Text("Required")
                                    .font(.caption)
                                    .foregroundColor(.secondary)
                            }
                            
                            TextField("Enter word or phrase to replace", text: $originalWord)
                                .textFieldStyle(.roundedBorder)
                                .font(.body)
                        }
                        .padding(.horizontal)
                        
                        // Replacement Text Section
                        VStack(alignment: .leading, spacing: 6) {
                            HStack {
                                Text("Replacement Text")
                                    .font(.headline)
                                    .foregroundColor(.primary)
                                
                                Text("Required")
                                    .font(.caption)
                                    .foregroundColor(.secondary)
                            }
                            
                            TextEditor(text: $replacementWord)
                                .font(.body)
                                .frame(height: 100)
                                .padding(8)
                                .background(Color(.textBackgroundColor))
                                .cornerRadius(6)
                                .overlay(
                                    RoundedRectangle(cornerRadius: 6)
                                        .stroke(Color(.separatorColor), lineWidth: 1)
                                )
                        }
                        .padding(.horizontal)
                    }
                    
                    // Example Section
                    VStack(alignment: .leading, spacing: 8) {
                        Text("Example")
                            .font(.subheadline)
                            .foregroundColor(.secondary)
                        
                        HStack(spacing: 12) {
                            VStack(alignment: .leading, spacing: 4) {
                                Text("Original:")
                                    .font(.caption)
                                    .foregroundColor(.secondary)
                                Text("my website link")
                                    .font(.callout)
                            }
                            
                            Image(systemName: "arrow.right")
                                .font(.caption)
                                .foregroundColor(.secondary)
                            
                            VStack(alignment: .leading, spacing: 4) {
                                Text("Replacement:")
                                    .font(.caption)
                                    .foregroundColor(.secondary)
                                Text("https://tryvoiceink.com")
                                    .font(.callout)
                            }
                        }
                        .padding(12)
                        .background(Color(.textBackgroundColor))
                        .cornerRadius(8)
                    }
                    .padding(.horizontal)
                    .padding(.top, 8)
                }
                .padding(.vertical)
            }
        }
        .frame(width: 460, height: 480)
    }
    
    private func addReplacement() {
        let trimmedOriginal = originalWord.trimmingCharacters(in: .whitespacesAndNewlines)
        let trimmedReplacement = replacementWord.trimmingCharacters(in: .whitespacesAndNewlines)
        
        guard !trimmedOriginal.isEmpty && !trimmedReplacement.isEmpty else { return }
        
        manager.addReplacement(original: trimmedOriginal, replacement: trimmedReplacement)
        dismiss()
    }
}

struct ReplacementRow: View {
    let original: String
    let replacement: String
    let onDelete: () -> Void
    
    var body: some View {
        HStack(spacing: 16) {
            // Original Text Container
            HStack {
                Text(original)
                    .font(.body)
                    .lineLimit(2)
                    .frame(maxWidth: .infinity, alignment: .leading)
                    .padding(.horizontal, 12)
                    .padding(.vertical, 8)
                    .background(Color(.textBackgroundColor))
                    .cornerRadius(6)
            }
            .frame(maxWidth: .infinity)
            
            // Arrow
            Image(systemName: "arrow.right")
                .foregroundColor(.secondary)
                .font(.system(size: 12))
            
            // Replacement Text Container
            HStack {
                Text(replacement)
                    .font(.body)
                    .lineLimit(2)
                    .frame(maxWidth: .infinity, alignment: .leading)
                    .padding(.horizontal, 12)
                    .padding(.vertical, 8)
                    .background(Color(.textBackgroundColor))
                    .cornerRadius(6)
            }
            .frame(maxWidth: .infinity)
            
            // Delete Button
            Button(action: onDelete) {
                Image(systemName: "xmark.circle.fill")
                    .symbolRenderingMode(.hierarchical)
                    .foregroundStyle(.red)
                    .font(.system(size: 16))
            }
            .buttonStyle(.borderless)
            .help("Remove replacement")
        }
        .padding(.horizontal)
        .padding(.vertical, 8)
        .contentShape(Rectangle())
        .background(Color(.controlBackgroundColor))
    }
}

================
File: VoiceInk/Views/Metrics/AppIconView.swift
================
import SwiftUI

struct AppIconView: View {
    var size: CGFloat
    var cornerRadius: CGFloat
    
    var body: some View {
        Group {
            if let appIcon = NSImage(named: NSImage.applicationIconName) {
                Image(nsImage: appIcon)
                    .resizable()
                    .aspectRatio(contentMode: .fit)
                    .frame(width: size, height: size)
                    .clipShape(RoundedRectangle(cornerRadius: cornerRadius))
                    .overlay(
                        RoundedRectangle(cornerRadius: cornerRadius)
                            .stroke(.linearGradient(
                                colors: [
                                    Color.white.opacity(0.5),
                                    Color.white.opacity(0.1)
                                ],
                                startPoint: .topLeading,
                                endPoint: .bottomTrailing
                            ), lineWidth: 1)
                    )
                    .shadow(color: Color.black.opacity(0.1), radius: 10, y: 5)
            }
        }
    }
}

================
File: VoiceInk/Views/Metrics/MetricCard.swift
================
import SwiftUI

struct MetricCard: View {
    let title: String
    let value: String
    let icon: String
    let color: Color
    
    var body: some View {
        VStack(alignment: .leading, spacing: 16) {
            HStack(spacing: 12) {
                // Icon
                Image(systemName: icon)
                    .font(.system(size: 24))
                    .foregroundColor(color)
                    .frame(width: 32, height: 32)
                    .background(
                        Circle()
                            .fill(color.opacity(0.1))
                    )
                
                VStack(alignment: .leading, spacing: 8) {
                    Text(title)
                        .font(.subheadline)
                        .foregroundColor(.secondary)
                    Text(value)
                        .font(.system(size: 24, weight: .bold, design: .rounded))
                        .foregroundColor(.primary)
                }
            }
        }
        .frame(maxWidth: .infinity, alignment: .leading)
        .padding()
        .background(Color(.controlBackgroundColor))
        .cornerRadius(10)
        .shadow(radius: 2)
    }
}

================
File: VoiceInk/Views/Metrics/MetricsContent.swift
================
import SwiftUI
import Charts

struct MetricsContent: View {
    let transcriptions: [Transcription]
    
    var body: some View {
        if transcriptions.isEmpty {
            emptyStateView
        } else {
            ScrollView {
                VStack(spacing: 20) {
                    TimeEfficiencyView(totalRecordedTime: totalRecordedTime, estimatedTypingTime: estimatedTypingTime)
                    
                    metricsGrid
                    
                    voiceInkTrendChart
                }
                .padding()
            }
        }
    }
    
    private var emptyStateView: some View {
        VStack(spacing: 20) {
            Image(systemName: "waveform")
                .font(.system(size: 50))
                .foregroundColor(.secondary)
            Text("No Transcriptions Yet")
                .font(.title2)
                .fontWeight(.semibold)
            Text("Start recording to see your metrics")
                .foregroundColor(.secondary)
        }
        .frame(maxWidth: .infinity, maxHeight: .infinity)
        .background(Color(.windowBackgroundColor))
    }
    
    private var metricsGrid: some View {
        LazyVGrid(columns: [GridItem(.flexible()), GridItem(.flexible())], spacing: 20) {
            MetricCard(
                title: "Words Captured",
                value: "\(totalWordsTranscribed)",
                icon: "text.word.spacing",
                color: .blue
            )
            MetricCard(
                title: "Voice-to-Text Sessions",
                value: "\(transcriptions.count)",
                icon: "mic.circle.fill",
                color: .green
            )
            MetricCard(
                title: "Average Words/Minute",
                value: String(format: "%.1f", averageWordsPerMinute),
                icon: "speedometer",
                color: .orange
            )
            MetricCard(
                title: "Words/Session",
                value: String(format: "%.1f", averageWordsPerSession),
                icon: "chart.bar.fill",
                color: .purple
            )
        }
    }
    
    private var voiceInkTrendChart: some View {
        VStack(alignment: .leading, spacing: 10) {
            Text("30-Day VoiceInk Trend")
                .font(.headline)
            
            Chart {
                ForEach(dailyTranscriptionCounts, id: \.date) { item in
                    LineMark(
                        x: .value("Date", item.date),
                        y: .value("Sessions", item.count)
                    )
                    .interpolationMethod(.catmullRom)
                    
                    AreaMark(
                        x: .value("Date", item.date),
                        y: .value("Sessions", item.count)
                    )
                    .foregroundStyle(LinearGradient(colors: [.blue.opacity(0.3), .blue.opacity(0.1)], startPoint: .top, endPoint: .bottom))
                    .interpolationMethod(.catmullRom)
                }
            }
            .chartXAxis {
                AxisMarks(values: .stride(by: .day, count: 7)) { _ in
                    AxisGridLine()
                    AxisTick()
                    AxisValueLabel(format: .dateTime.day().month(), centered: true)
                }
            }
            .chartYAxis {
                AxisMarks { value in
                    AxisGridLine()
                    AxisTick()
                    AxisValueLabel()
                }
            }
            .frame(height: 250)
        }
        .padding()
        .background(Color(.controlBackgroundColor))
        .cornerRadius(10)
        .shadow(radius: 2)
    }
    
    // Computed properties for metrics
    private var totalWordsTranscribed: Int {
        transcriptions.reduce(0) { $0 + $1.text.split(separator: " ").count }
    }
    
    private var totalRecordedTime: TimeInterval {
        transcriptions.reduce(0) { $0 + $1.duration }
    }
    
    private var estimatedTypingTime: TimeInterval {
        let averageTypingSpeed: Double = 40 // words per minute
        let totalWords = Double(totalWordsTranscribed)
        let estimatedTypingTimeInMinutes = totalWords / averageTypingSpeed
        return estimatedTypingTimeInMinutes * 60
    }
    
    private var dailyTranscriptionCounts: [(date: Date, count: Int)] {
        let calendar = Calendar.current
        let now = Date()
        let thirtyDaysAgo = calendar.date(byAdding: .day, value: -29, to: now)!
        
        let dailyData = (0..<30).compactMap { dayOffset -> (date: Date, count: Int)? in
            guard let date = calendar.date(byAdding: .day, value: -dayOffset, to: now) else { return nil }
            let startOfDay = calendar.startOfDay(for: date)
            let endOfDay = calendar.date(byAdding: .day, value: 1, to: startOfDay)!
            let count = transcriptions.filter { $0.timestamp >= startOfDay && $0.timestamp < endOfDay }.count
            return (date: startOfDay, count: count)
        }
        
        return dailyData.reversed()
    }
    
    // Add computed properties for new metrics
    private var averageWordsPerMinute: Double {
        guard totalRecordedTime > 0 else { return 0 }
        return Double(totalWordsTranscribed) / (totalRecordedTime / 60.0)
    }
    
    private var averageWordsPerSession: Double {
        guard !transcriptions.isEmpty else { return 0 }
        return Double(totalWordsTranscribed) / Double(transcriptions.count)
    }
}

================
File: VoiceInk/Views/Metrics/MetricsSetupView.swift
================
import SwiftUI
import KeyboardShortcuts

struct MetricsSetupView: View {
    @EnvironmentObject private var whisperState: WhisperState
    @State private var isAccessibilityEnabled = AXIsProcessTrusted()
    @State private var isScreenRecordingEnabled = CGPreflightScreenCaptureAccess()
    
    var body: some View {
        GeometryReader { geometry in
            ScrollView {
                VStack(spacing: geometry.size.height * 0.05) {
                    // Header
                    VStack(spacing: geometry.size.height * 0.02) {
                        AppIconView(size: min(90, geometry.size.width * 0.15), cornerRadius: 22)
                        
                        VStack(spacing: geometry.size.height * 0.01) {
                            Text("Welcome to VoiceInk")
                                .font(.system(size: min(32, geometry.size.width * 0.05), weight: .bold, design: .rounded))
                                .multilineTextAlignment(.center)
                            
                            Text("Complete the setup to get started")
                                .font(.system(size: min(16, geometry.size.width * 0.025)))
                                .foregroundColor(.secondary)
                                .multilineTextAlignment(.center)
                        }
                    }
                    .padding(.top, geometry.size.height * 0.03)
                    
                    // Setup Steps
                    VStack(spacing: geometry.size.height * 0.02) {
                        ForEach(0..<4) { index in
                            setupStep(for: index, geometry: geometry)
                        }
                    }
                    .padding(.horizontal, geometry.size.width * 0.03)
                    
                    Spacer(minLength: geometry.size.height * 0.02)
                    
                    // Action Button
                    actionButton
                        .frame(maxWidth: min(600, geometry.size.width * 0.8))
                    
                    // Help Text
                    helpText
                        .padding(.bottom, geometry.size.height * 0.03)
                }
                .padding(.horizontal, geometry.size.width * 0.05)
                .frame(minHeight: geometry.size.height)
                .background {
                    Color(.controlBackgroundColor)
                }
            }
        }
        .frame(minWidth: 500, minHeight: 400)
    }
    
    private func setupStep(for index: Int, geometry: GeometryProxy) -> some View {
        let isCompleted: Bool
        let icon: String
        let title: String
        let description: String
        
        switch index {
        case 0:
            isCompleted = KeyboardShortcuts.getShortcut(for: .toggleMiniRecorder) != nil
            icon = "command"
            title = "Set Keyboard Shortcut"
            description = "Set up a keyboard shortcut to use VoiceInk anywhere"
        case 1:
            isCompleted = isAccessibilityEnabled
            icon = "hand.raised"
            title = "Enable Accessibility"
            description = "Allow VoiceInk to paste transcribed text directly at your cursor position"
        case 2:
            isCompleted = isScreenRecordingEnabled
            icon = "video"
            title = "Enable Screen Recording"
            description = "Allow VoiceInk to understand context from your screen for transcript  Enhancement"
        default:
            isCompleted = whisperState.currentModel != nil
            icon = "arrow.down"
            title = "Download Model"
            description = "Choose and download an AI model"
        }
        
        return HStack(spacing: geometry.size.width * 0.03) {
            // Status Icon
            ZStack {
                Circle()
                    .fill(isCompleted ?
                          Color(nsColor: .controlAccentColor).opacity(0.15) :
                          Color(nsColor: .systemRed).opacity(0.15))
                    .frame(width: min(44, geometry.size.width * 0.08), height: min(44, geometry.size.width * 0.08))
                
                Image(systemName: "\(icon).circle")
                    .font(.system(size: min(24, geometry.size.width * 0.04), weight: .medium))
                    .foregroundColor(isCompleted ? Color(nsColor: .controlAccentColor) : Color(nsColor: .systemRed))
                    .symbolRenderingMode(.hierarchical)
            }
            
            // Text
            VStack(alignment: .leading, spacing: 4) {
                Text(title)
                    .font(.system(size: min(16, geometry.size.width * 0.025), weight: .semibold))
                Text(description)
                    .font(.system(size: min(14, geometry.size.width * 0.022)))
                    .foregroundColor(.secondary)
            }
            
            Spacer()
            
            // Status indicator
            if isCompleted {
                Image(systemName: "checkmark.seal.fill")
                    .font(.system(size: min(26, geometry.size.width * 0.045), weight: .semibold))
                    .foregroundColor(Color.green.opacity(0.95))
                    .symbolRenderingMode(.hierarchical)
            } else {
                Circle()
                    .stroke(Color(nsColor: .systemRed), lineWidth: 2)
                    .frame(width: min(24, geometry.size.width * 0.04), height: min(24, geometry.size.width * 0.04))
            }
        }
        .padding(.horizontal, geometry.size.width * 0.03)
        .padding(.vertical, geometry.size.height * 0.02)
        .background(
            RoundedRectangle(cornerRadius: 16)
                .fill(Color(.windowBackgroundColor))
                .shadow(
                    color: Color.black.opacity(0.05),
                    radius: 8,
                    x: 0,
                    y: 4
                )
        )
    }
    
    private var actionButton: some View {
        Button(action: {
            if isShortcutAndAccessibilityGranted {
                openModelManagement()
            } else {
                // Handle different permission requests based on which one is missing
                if KeyboardShortcuts.getShortcut(for: .toggleMiniRecorder) == nil {
                    openSettings()
                } else if !AXIsProcessTrusted() {
                    if let url = URL(string: "x-apple.systempreferences:com.apple.preference.security?Privacy_Accessibility") {
                        NSWorkspace.shared.open(url)
                    }
                } else if !CGPreflightScreenCaptureAccess() {
                    CGRequestScreenCaptureAccess()
                    // After requesting, open system preferences as fallback
                    if let url = URL(string: "x-apple.systempreferences:com.apple.preference.security?Privacy_ScreenCapture") {
                        NSWorkspace.shared.open(url)
                    }
                }
            }
        }) {
            HStack(spacing: 8) {
                Text(isShortcutAndAccessibilityGranted ? "Download Model" : getActionButtonTitle())
                Image(systemName: "arrow.right")
                    .font(.system(size: 14, weight: .semibold))
            }
            .font(.headline)
            .frame(maxWidth: .infinity)
            .frame(height: 50)
            .background(
                LinearGradient(
                    colors: [
                        Color(nsColor: .controlAccentColor),
                        Color(nsColor: .controlAccentColor).opacity(0.8)
                    ],
                    startPoint: .leading,
                    endPoint: .trailing
                )
            )
            .foregroundColor(.white)
            .clipShape(RoundedRectangle(cornerRadius: 14))
        }
        .buttonStyle(.plain)
        .shadow(
            color: Color(nsColor: .controlAccentColor).opacity(0.3),
            radius: 10,
            y: 5
        )
    }
    
    private func getActionButtonTitle() -> String {
        if KeyboardShortcuts.getShortcut(for: .toggleMiniRecorder) == nil {
            return "Configure Shortcut"
        } else if !AXIsProcessTrusted() {
            return "Enable Accessibility"
        } else if !CGPreflightScreenCaptureAccess() {
            return "Enable Screen Recording"
        }
        return "Open Settings"
    }
    
    private var helpText: some View {
        Text("Need help? Check the Help menu for support options")
            .font(.system(size: 13))
            .foregroundColor(.secondary)
    }
    
    private var isShortcutAndAccessibilityGranted: Bool {
        KeyboardShortcuts.getShortcut(for: .toggleMiniRecorder) != nil && 
        AXIsProcessTrusted() && 
        CGPreflightScreenCaptureAccess()
    }
    
    private func openSettings() {
        NotificationCenter.default.post(
            name: .navigateToDestination,
            object: nil,
            userInfo: ["destination": "Settings"]
        )
    }
    
    private func openModelManagement() {
        NotificationCenter.default.post(
            name: .navigateToDestination,
            object: nil,
            userInfo: ["destination": "AI Models"]
        )
    }
}

================
File: VoiceInk/Views/Metrics/TimeEfficiencyView.swift
================
import SwiftUI

struct TimeEfficiencyView: View {
    // MARK: - Properties
    
    private let totalRecordedTime: TimeInterval
    private let estimatedTypingTime: TimeInterval
    
    // Computed properties for efficiency metrics
    private var timeSaved: TimeInterval {
        estimatedTypingTime - totalRecordedTime
    }
    
    private var efficiencyMultiplier: Double {
        guard totalRecordedTime > 0 else { return 0 }
        let multiplier = estimatedTypingTime / totalRecordedTime
        return round(multiplier * 10) / 10  // Round to 1 decimal place
    }
    
    private var efficiencyMultiplierFormatted: String {
        String(format: "%.1fx", efficiencyMultiplier)
    }
    
    // MARK: - Initializer
    
    init(totalRecordedTime: TimeInterval, estimatedTypingTime: TimeInterval) {
        self.totalRecordedTime = totalRecordedTime
        self.estimatedTypingTime = estimatedTypingTime
    }
    
    // MARK: - Body
    
    var body: some View {
        VStack(spacing: 0) {
            mainContent
        }
    }
    
    // MARK: - Main Content View
    
    private var mainContent: some View {
        VStack(spacing: 24) {
            headerSection
            timeComparisonSection
            bottomSection
        }
        .padding(.vertical, 24)
        .background(Color(.controlBackgroundColor))
        .cornerRadius(10)
        .shadow(radius: 2)
    }
    
    // MARK: - Subviews
    
    private var headerSection: some View {
        VStack(alignment: .center, spacing: 8) {
            HStack(spacing: 8) {
                Text("You are")
                    .font(.system(size: 32, weight: .bold))
                
                Text("\(efficiencyMultiplierFormatted) Faster")
                    .font(.system(size: 32, weight: .bold))
                    .foregroundStyle(efficiencyGradient)
                
                Text("with VoiceInk")
                    .font(.system(size: 32, weight: .bold))
            }
            .lineLimit(1)
            .minimumScaleFactor(0.5)
        }
        .padding(.horizontal, 24)
    }
    
    private var timeComparisonSection: some View {
        HStack(spacing: 16) {
            TimeBlockView(
                duration: totalRecordedTime,
                label: "SPEAKING TIME",
                icon: "mic.circle.fill",
                color: .green
            )
            
            TimeBlockView(
                duration: estimatedTypingTime,
                label: "TYPING TIME",
                icon: "keyboard.fill",
                color: .orange
            )
        }
        .padding(.horizontal, 24)
    }
    
    private var bottomSection: some View {
        HStack {
            timeSavedView
            Spacer()
            discordCommunityLink
        }
        .padding(.horizontal, 24)
    }
    
    private var timeSavedView: some View {
        VStack(alignment: .leading, spacing: 8) {
            Text("TIME SAVED")
                .font(.system(size: 13, weight: .heavy))
                .tracking(4)
                .foregroundColor(.secondary)
            
            Text(formatDuration(timeSaved))
                .font(.system(size: 32, weight: .black, design: .rounded))
                .foregroundStyle(accentGradient)
        }
    }
    
    private var discordCommunityLink: some View {
        Link(destination: URL(string: "https://discord.gg/xryDy57nYD")!) {
            VStack(alignment: .leading, spacing: 10) {
                HStack(spacing: 12) {
                    Image(systemName: "ellipsis.message.fill")
                        .foregroundStyle(accentGradient)
                        .font(.system(size: 36))

                    VStack(alignment: .leading, spacing: 4) {
                        Text("Need Support?")
                            .font(.headline)
                            .fontWeight(.bold)
                        
                        Text("Got Feature Ideas? We're Listening!")
                            .font(.subheadline)
                            .foregroundColor(.secondary)
                    }
                }
                
                HStack {
                    Text("JOIN DISCORD")
                        .font(.system(size: 14, weight: .bold))
                        .foregroundColor(.white)
                        .padding(.horizontal, 16)
                        .padding(.vertical, 8)
                        .background(Color.blue)
                        .cornerRadius(6)
                    
                    Image(systemName: "chevron.right")
                        .foregroundColor(Color.blue.opacity(0.7))
                }
            }
            .padding(14)
            .background(
                RoundedRectangle(cornerRadius: 8)
                    .fill(Color(nsColor: .controlBackgroundColor))
            )
            .overlay(
                RoundedRectangle(cornerRadius: 8)
                    .stroke(Color.blue.opacity(0.2), lineWidth: 1)
            )
        }
    }
    
    private var efficiencyGradient: LinearGradient {
        LinearGradient(
            colors: [
                Color.green,
                Color.green.opacity(0.7)
            ],
            startPoint: .leading,
            endPoint: .trailing
        )
    }
    
    private var accentGradient: LinearGradient {
        LinearGradient(
            colors: [
                Color(nsColor: .controlAccentColor),
                Color(nsColor: .controlAccentColor).opacity(0.8)
            ],
            startPoint: .leading,
            endPoint: .trailing
        )
    }
    
    // MARK: - Utility Methods
    
    private func formatDuration(_ duration: TimeInterval) -> String {
        let formatter = DateComponentsFormatter()
        formatter.allowedUnits = [.hour, .minute, .second]
        formatter.unitsStyle = .abbreviated
        return formatter.string(from: duration) ?? ""
    }
}

// MARK: - Helper Struct

struct TimeBlockView: View {
    let duration: TimeInterval
    let label: String
    let icon: String
    let color: Color
    
    private func formatDuration(_ duration: TimeInterval) -> String {
        let formatter = DateComponentsFormatter()
        formatter.allowedUnits = [.hour, .minute, .second]
        formatter.unitsStyle = .abbreviated
        return formatter.string(from: duration) ?? ""
    }
    
    var body: some View {
        HStack(spacing: 16) {
            Image(systemName: icon)
                .font(.system(size: 24, weight: .semibold))
                .foregroundColor(color)
            
            VStack(alignment: .leading, spacing: 4) {
                Text(formatDuration(duration))
                    .font(.system(size: 24, weight: .bold, design: .rounded))
                
                Text(label)
                    .font(.system(size: 12, weight: .heavy))
                    .tracking(2)
                    .foregroundColor(.secondary)
            }
            
            Spacer()
        }
        .padding(.horizontal, 24)
        .padding(.vertical, 16)
        .background(
            RoundedRectangle(cornerRadius: 16)
                .fill(color.opacity(0.1))
        )
    }
}

================
File: VoiceInk/Views/Onboarding/OnboardingModelDownloadView.swift
================
import SwiftUI

struct OnboardingModelDownloadView: View {
    @Binding var hasCompletedOnboarding: Bool
    @EnvironmentObject private var whisperState: WhisperState
    @State private var scale: CGFloat = 0.8
    @State private var opacity: CGFloat = 0
    @State private var isDownloading = false
    @State private var isModelSet = false
    @State private var showTutorial = false
    
    private let turboModel = PredefinedModels.models.first { $0.name == "ggml-large-v3-turbo-q5_0" }!
    
    var body: some View {
        ZStack {
            GeometryReader { geometry in
                // Reusable background
                OnboardingBackgroundView()
                
                VStack(spacing: 40) {
                    // Model icon and title
                    VStack(spacing: 30) {
                        // Model icon
                        ZStack {
                            Circle()
                                .fill(Color.accentColor.opacity(0.1))
                                .frame(width: 100, height: 100)
                            
                            if isModelSet {
                                Image(systemName: "checkmark.seal.fill")
                                    .font(.system(size: 50))
                                    .foregroundColor(.accentColor)
                                    .transition(.scale.combined(with: .opacity))
                            } else {
                                Image(systemName: "brain")
                                    .font(.system(size: 40))
                                    .foregroundColor(.accentColor)
                            }
                        }
                        .scaleEffect(scale)
                        .opacity(opacity)
                        
                        // Title and description
                        VStack(spacing: 12) {
                            Text("Download AI Model")
                                .font(.title2)
                                .fontWeight(.bold)
                                .foregroundColor(.white)
                            
                            Text("We'll download the optimized model to get you started.")
                                .font(.body)
                                .foregroundColor(.white.opacity(0.7))
                                .multilineTextAlignment(.center)
                                .padding(.horizontal)
                        }
                        .scaleEffect(scale)
                        .opacity(opacity)
                    }
                    
                    // Model card - Centered and compact
                    VStack(alignment: .leading, spacing: 16) {
                        // Model name and details
                        VStack(alignment: .center, spacing: 8) {
                            Text(turboModel.displayName)
                                .font(.headline)
                                .foregroundColor(.white)
                            Text("\(turboModel.size) ‚Ä¢ \(turboModel.language)")
                                .font(.caption)
                                .foregroundColor(.white.opacity(0.7))
                        }
                        .frame(maxWidth: .infinity)
                        
                        Divider()
                            .background(Color.white.opacity(0.1))
                        
                        // Performance indicators in a more compact layout
                        HStack(spacing: 20) {
                            performanceIndicator(label: "Speed", value: turboModel.speed)
                            performanceIndicator(label: "Accuracy", value: turboModel.accuracy)
                            ramUsageLabel(gb: turboModel.ramUsage)
                        }
                        .frame(maxWidth: .infinity, alignment: .center)
                        
                        // Download progress
                        if isDownloading {
                            VStack(spacing: 8) {
                                ProgressView(value: whisperState.downloadProgress[turboModel.name] ?? 0)
                                    .progressViewStyle(.linear)
                                    .tint(.white)
                                Text("\(Int((whisperState.downloadProgress[turboModel.name] ?? 0) * 100))%")
                                    .font(.caption)
                                    .foregroundColor(.white.opacity(0.7))
                            }
                            .transition(.opacity)
                        }
                    }
                    .padding(24)
                    .frame(width: min(geometry.size.width * 0.6, 400))
                    .background(Color.black.opacity(0.3))
                    .cornerRadius(16)
                    .overlay(
                        RoundedRectangle(cornerRadius: 16)
                            .stroke(Color.white.opacity(0.1), lineWidth: 1)
                    )
                    .scaleEffect(scale)
                    .opacity(opacity)
                    
                    // Action buttons
                    VStack(spacing: 16) {
                        Button(action: handleAction) {
                            Text(getButtonTitle())
                                .font(.headline)
                                .foregroundColor(.white)
                                .frame(width: 200, height: 50)
                                .background(Color.accentColor)
                                .cornerRadius(25)
                        }
                        .buttonStyle(ScaleButtonStyle())
                        .disabled(isDownloading)
                        
                        if !isModelSet {
                            SkipButton(text: "Skip for now") {
                                withAnimation {
                                    showTutorial = true
                                }
                            }
                        }
                    }
                    .opacity(opacity)
                }
                .padding()
                .frame(maxWidth: .infinity, maxHeight: .infinity)
                .frame(width: min(geometry.size.width * 0.8, 600))
                .position(x: geometry.size.width / 2, y: geometry.size.height / 2)
            }
            
            if showTutorial {
                OnboardingTutorialView(hasCompletedOnboarding: $hasCompletedOnboarding)
                    .transition(.move(edge: .trailing).combined(with: .opacity))
            }
        }
        .onAppear {
            animateIn()
            checkModelStatus()
        }
    }
    
    private func animateIn() {
        withAnimation(.spring(response: 0.6, dampingFraction: 0.7)) {
            scale = 1
            opacity = 1
        }
    }
    
    private func checkModelStatus() {
        if let model = whisperState.availableModels.first(where: { $0.name == turboModel.name }) {
            isModelSet = whisperState.currentModel?.name == model.name
        }
    }
    
    private func handleAction() {
        if isModelSet {
            withAnimation {
                showTutorial = true
            }
        } else if let model = whisperState.availableModels.first(where: { $0.name == turboModel.name }) {
            Task {
                await whisperState.setDefaultModel(model)
                withAnimation {
                    isModelSet = true
                }
            }
        } else {
            withAnimation {
                isDownloading = true
            }
            Task {
                await whisperState.downloadModel(turboModel)
                if let model = whisperState.availableModels.first(where: { $0.name == turboModel.name }) {
                    await whisperState.setDefaultModel(model)
                    withAnimation {
                        isModelSet = true
                        isDownloading = false
                    }
                }
            }
        }
    }
    
    private func getButtonTitle() -> String {
        if isModelSet {
            return "Continue"
        } else if isDownloading {
            return "Downloading..."
        } else if whisperState.availableModels.contains(where: { $0.name == turboModel.name }) {
            return "Set as Default"
        } else {
            return "Download Model"
        }
    }
    
    private func performanceIndicator(label: String, value: Double) -> some View {
        VStack(alignment: .leading, spacing: 4) {
            Text(label)
                .font(.caption)
                .foregroundColor(.white.opacity(0.7))
            
            HStack(spacing: 4) {
                ForEach(0..<5) { index in
                    Circle()
                        .fill(Double(index) / 5.0 <= value ? Color.accentColor : Color.white.opacity(0.2))
                        .frame(width: 6, height: 6)
                }
            }
        }
    }
    
    private func ramUsageLabel(gb: Double) -> some View {
        VStack(alignment: .leading, spacing: 4) {
            Text("RAM")
                .font(.caption)
                .foregroundColor(.white.opacity(0.7))
            
            Text(String(format: "%.1f GB", gb))
                .font(.system(size: 12, weight: .bold))
                .foregroundColor(.white)
        }
    }
}

================
File: VoiceInk/Views/Onboarding/OnboardingPermissionsView.swift
================
import SwiftUI
import AVFoundation
import AppKit
import KeyboardShortcuts

struct OnboardingPermission: Identifiable {
    let id = UUID()
    let title: String
    let description: String
    let icon: String
    let type: PermissionType
    
    enum PermissionType {
        case microphone
        case accessibility
        case screenRecording
        case keyboardShortcut
        
        var systemName: String {
            switch self {
            case .microphone: return "mic"
            case .accessibility: return "accessibility"
            case .screenRecording: return "rectangle.inset.filled.and.person.filled"
            case .keyboardShortcut: return "keyboard"
            }
        }
    }
}

struct OnboardingPermissionsView: View {
    @Binding var hasCompletedOnboarding: Bool
    @EnvironmentObject private var hotkeyManager: HotkeyManager
    @State private var currentPermissionIndex = 0
    @State private var permissionStates: [Bool] = [false, false, false, false]
    @State private var showAnimation = false
    @State private var scale: CGFloat = 0.8
    @State private var opacity: CGFloat = 0
    @State private var showModelDownload = false
    
    private let permissions: [OnboardingPermission] = [
        OnboardingPermission(
            title: "Microphone Access",
            description: "Enable your microphone to start speaking and converting your voice to text instantly.",
            icon: "waveform",
            type: .microphone
        ),
        OnboardingPermission(
            title: "Accessibility Access",
            description: "Allow VoiceInk to help you type anywhere in your Mac.",
            icon: "accessibility",
            type: .accessibility
        ),
        OnboardingPermission(
            title: "Screen Recording",
            description: "This helps to improve the accuracy of transcription.",
            icon: "rectangle.inset.filled.and.person.filled",
            type: .screenRecording
        ),
        OnboardingPermission(
            title: "Keyboard Shortcut",
            description: "Set up a keyboard shortcut to quickly access VoiceInk from anywhere.",
            icon: "keyboard",
            type: .keyboardShortcut
        )
    ]
    
    var body: some View {
        ZStack {
            GeometryReader { geometry in
                ZStack {
                    // Reusable background
                    OnboardingBackgroundView()
                    
                    VStack(spacing: 40) {
                        // Progress indicator
                        HStack(spacing: 8) {
                            ForEach(0..<permissions.count, id: \.self) { index in
                                Circle()
                                    .fill(index <= currentPermissionIndex ? Color.accentColor : Color.white.opacity(0.1))
                                    .frame(width: 8, height: 8)
                                    .scaleEffect(index == currentPermissionIndex ? 1.2 : 1.0)
                                    .animation(.spring(response: 0.3, dampingFraction: 0.7), value: currentPermissionIndex)
                            }
                        }
                        .padding(.top, 40)
                        
                        // Current permission card
                        VStack(spacing: 30) {
                            // Permission icon
                            ZStack {
                                Circle()
                                    .fill(Color.accentColor.opacity(0.1))
                                    .frame(width: 100, height: 100)
                                
                                if permissionStates[currentPermissionIndex] {
                                    Image(systemName: "checkmark.seal.fill")
                                        .font(.system(size: 50))
                                        .foregroundColor(.accentColor)
                                        .transition(.scale.combined(with: .opacity))
                                } else {
                                    Image(systemName: permissions[currentPermissionIndex].icon)
                                        .font(.system(size: 40))
                                        .foregroundColor(.accentColor)
                                }
                            }
                            .scaleEffect(scale)
                            .opacity(opacity)
                            
                            // Permission text
                            VStack(spacing: 12) {
                                Text(permissions[currentPermissionIndex].title)
                                    .font(.title2)
                                    .fontWeight(.bold)
                                    .foregroundColor(.white)
                                
                                Text(permissions[currentPermissionIndex].description)
                                    .font(.body)
                                    .foregroundColor(.white.opacity(0.7))
                                    .multilineTextAlignment(.center)
                                    .padding(.horizontal)
                            }
                            .scaleEffect(scale)
                            .opacity(opacity)
                            
                            // Keyboard shortcut recorder (only shown for keyboard shortcut step)
                            if permissions[currentPermissionIndex].type == .keyboardShortcut {
                                VStack(spacing: 16) {
                                    if hotkeyManager.isShortcutConfigured {
                                        if let shortcut = KeyboardShortcuts.getShortcut(for: .toggleMiniRecorder) {
                                            KeyboardShortcutView(shortcut: shortcut)
                                                .scaleEffect(1.2)
                                        }
                                    }
                                    
                                    VStack(spacing: 16) {
                                        KeyboardShortcuts.Recorder("Set Shortcut:", name: .toggleMiniRecorder) { newShortcut in
                                            if newShortcut != nil {
                                                permissionStates[currentPermissionIndex] = true
                                            } else {
                                                permissionStates[currentPermissionIndex] = false
                                            }
                                            hotkeyManager.updateShortcutStatus()
                                        }
                                        .controlSize(.large)
                                        
                                        SkipButton(text: "Skip for now") {
                                            moveToNext()
                                        }
                                    }
                                }
                                .scaleEffect(scale)
                                .opacity(opacity)
                            }
                        }
                        .frame(maxWidth: 400)
                        .padding(.vertical, 40)
                        
                        // Action buttons
                        VStack(spacing: 16) {
                            Button(action: requestPermission) {
                                Text(getButtonTitle())
                                    .font(.headline)
                                    .foregroundColor(.white)
                                    .frame(width: 200, height: 50)
                                    .background(Color.accentColor)
                                    .cornerRadius(25)
                            }
                            .buttonStyle(ScaleButtonStyle())
                            
                            if !permissionStates[currentPermissionIndex] && permissions[currentPermissionIndex].type != .keyboardShortcut {
                                SkipButton(text: "Skip for now") {
                                    moveToNext()
                                }
                            }
                        }
                        .opacity(opacity)
                    }
                    .padding()
                }
            }
            
            if showModelDownload {
                OnboardingModelDownloadView(hasCompletedOnboarding: $hasCompletedOnboarding)
                    .transition(.move(edge: .trailing).combined(with: .opacity))
            }
        }
        .onAppear {
            checkExistingPermissions()
            animateIn()
        }
    }
    
    private func animateIn() {
        withAnimation(.spring(response: 0.6, dampingFraction: 0.7)) {
            scale = 1
            opacity = 1
        }
    }
    
    private func resetAnimation() {
        scale = 0.8
        opacity = 0
        animateIn()
    }
    
    private func checkExistingPermissions() {
        // Check microphone permission
        permissionStates[0] = AVCaptureDevice.authorizationStatus(for: .audio) == .authorized
        
        // Check accessibility permission
        permissionStates[1] = AXIsProcessTrusted()
        
        // Check screen recording permission
        permissionStates[2] = CGPreflightScreenCaptureAccess()
        
        // Check keyboard shortcut
        permissionStates[3] = hotkeyManager.isShortcutConfigured
    }
    
    private func requestPermission() {
        if permissionStates[currentPermissionIndex] {
            moveToNext()
            return
        }
        
        switch permissions[currentPermissionIndex].type {
        case .microphone:
            AVCaptureDevice.requestAccess(for: .audio) { granted in
                DispatchQueue.main.async {
                    permissionStates[currentPermissionIndex] = granted
                    if granted {
                        withAnimation {
                            showAnimation = true
                        }
                    }
                }
            }
            
        case .accessibility:
            let options: NSDictionary = [kAXTrustedCheckOptionPrompt.takeUnretainedValue() as String: true]
            AXIsProcessTrustedWithOptions(options)
            
            // Start checking for permission status
            Timer.scheduledTimer(withTimeInterval: 0.5, repeats: true) { timer in
                if AXIsProcessTrusted() {
                    timer.invalidate()
                    permissionStates[currentPermissionIndex] = true
                    withAnimation {
                        showAnimation = true
                    }
                }
            }
            
        case .screenRecording:
            // Launch system preferences for screen recording
            let prefpaneURL = URL(string: "x-apple.systempreferences:com.apple.preference.security?Privacy_ScreenCapture")!
            NSWorkspace.shared.open(prefpaneURL)
            
            // Start checking for permission status
            Timer.scheduledTimer(withTimeInterval: 0.5, repeats: true) { timer in
                if CGPreflightScreenCaptureAccess() {
                    timer.invalidate()
                    permissionStates[currentPermissionIndex] = true
                    withAnimation {
                        showAnimation = true
                    }
                }
            }
            
        case .keyboardShortcut:
            // The keyboard shortcut is handled by the KeyboardShortcuts.Recorder
            break
        }
    }
    
    private func moveToNext() {
        if currentPermissionIndex < permissions.count - 1 {
            withAnimation {
                currentPermissionIndex += 1
                resetAnimation()
            }
        } else {
            withAnimation {
                showModelDownload = true
            }
        }
    }
    
    private func getButtonTitle() -> String {
        if permissions[currentPermissionIndex].type == .keyboardShortcut {
            return permissionStates[currentPermissionIndex] ? "Continue" : "Set Shortcut"
        }
        return permissionStates[currentPermissionIndex] ? "Continue" : "Enable Access"
    }
}

================
File: VoiceInk/Views/Onboarding/OnboardingTutorialView.swift
================
import SwiftUI
import KeyboardShortcuts

struct OnboardingTutorialView: View {
    @Binding var hasCompletedOnboarding: Bool
    @EnvironmentObject private var hotkeyManager: HotkeyManager
    @EnvironmentObject private var whisperState: WhisperState
    @State private var scale: CGFloat = 0.8
    @State private var opacity: CGFloat = 0
    @State private var transcribedText: String = ""
    @State private var isTextFieldFocused: Bool = false
    @State private var showingShortcutHint: Bool = true
    @FocusState private var isFocused: Bool
    
    var body: some View {
        GeometryReader { geometry in
            ZStack {
                // Reusable background
                OnboardingBackgroundView()
                
                HStack(spacing: 0) {
                    // Left side - Tutorial instructions
                    VStack(alignment: .leading, spacing: 40) {
                        // Title and description
                        VStack(alignment: .leading, spacing: 16) {
                            Text("Try It Out!")
                                .font(.system(size: 44, weight: .bold, design: .rounded))
                                .foregroundColor(.white)
                            
                            Text("Let's test your VoiceInk setup.")
                                .font(.system(size: 24, weight: .medium, design: .rounded))
                                .foregroundColor(.white.opacity(0.7))
                                .lineSpacing(4)
                        }
                        
                        // Keyboard shortcut display
                        VStack(alignment: .leading, spacing: 20) {
                            Text("Your Shortcut")
                                .font(.system(size: 28, weight: .semibold, design: .rounded))
                                .foregroundColor(.white)
                            
                            if let shortcut = KeyboardShortcuts.getShortcut(for: .toggleMiniRecorder) {
                                KeyboardShortcutView(shortcut: shortcut)
                                    .scaleEffect(1.2)
                            }
                        }
                        
                        // Instructions
                        VStack(alignment: .leading, spacing: 24) {
                            ForEach(1...4, id: \.self) { step in
                                instructionStep(number: step, text: getInstructionText(for: step))
                            }
                        }
                        
                        Spacer()
                        
                        // Continue button
                        Button(action: {
                            hasCompletedOnboarding = true
                        }) {
                            Text("Complete Setup")
                                .font(.system(size: 18, weight: .semibold, design: .rounded))
                                .foregroundColor(.white)
                                .frame(width: 200, height: 50)
                                .background(Color.accentColor)
                                .cornerRadius(25)
                        }
                        .buttonStyle(ScaleButtonStyle())
                        .opacity(transcribedText.isEmpty ? 0.5 : 1)
                        .disabled(transcribedText.isEmpty)
                        
                        SkipButton(text: "Skip for now") {
                            hasCompletedOnboarding = true
                        }
                    }
                    .padding(60)
                    .frame(width: geometry.size.width * 0.5)
                    
                    // Right side - Interactive area
                    VStack {
                        // Magical text editor area
                        ZStack {
                            // Glowing background
                            RoundedRectangle(cornerRadius: 20)
                                .fill(Color.black.opacity(0.4))
                                .overlay(
                                    RoundedRectangle(cornerRadius: 20)
                                        .stroke(Color.white.opacity(0.1), lineWidth: 1)
                                )
                                .overlay(
                                    // Subtle gradient overlay
                                    LinearGradient(
                                        colors: [
                                            Color.accentColor.opacity(0.05),
                                            Color.black.opacity(0.1)
                                        ],
                                        startPoint: .topLeading,
                                        endPoint: .bottomTrailing
                                    )
                                )
                                .shadow(color: Color.accentColor.opacity(0.1), radius: 15, x: 0, y: 0)
                            
                            // Text editor with custom styling
                            TextEditor(text: $transcribedText)
                                .font(.system(size: 32, weight: .bold, design: .rounded))
                                .focused($isFocused)
                                .scrollContentBackground(.hidden)
                                .background(Color.clear)
                                .foregroundColor(.white)
                                .padding(20)
                            
                            // Placeholder text with magical appearance
                            if transcribedText.isEmpty {
                                VStack(spacing: 16) {
                                    Image(systemName: "wand.and.stars")
                                        .font(.system(size: 36))
                                        .foregroundColor(.white.opacity(0.3))
                                    
                                    Text("Click here and start speaking...")
                                        .font(.system(size: 28, weight: .semibold, design: .rounded))
                                        .foregroundColor(.white.opacity(0.5))
                                        .multilineTextAlignment(.center)
                                }
                                .padding()
                                .allowsHitTesting(false)
                            }
                            
                            // Subtle animated border
                            RoundedRectangle(cornerRadius: 20)
                                .strokeBorder(
                                    LinearGradient(
                                        colors: [
                                            Color.accentColor.opacity(isFocused ? 0.4 : 0.1),
                                            Color.accentColor.opacity(isFocused ? 0.2 : 0.05)
                                        ],
                                        startPoint: .topLeading,
                                        endPoint: .bottomTrailing
                                    ),
                                    lineWidth: 1
                                )
                                .animation(.easeInOut(duration: 0.3), value: isFocused)
                        }
                        .frame(maxWidth: .infinity, maxHeight: .infinity)
                    }
                    .padding(60)
                    .frame(width: geometry.size.width * 0.5)
                }
            }
        }
        .onAppear {
            animateIn()
            isFocused = true
        }
    }
    
    private func getInstructionText(for step: Int) -> String {
        switch step {
        case 1: return "Click the text area on the right"
        case 2: return "Press your keyboard shortcut"
        case 3: return "Speak something"
        case 4: return "Press your keyboard shortcut again"
        default: return ""
        }
    }
    
    private func instructionStep(number: Int, text: String) -> some View {
        HStack(spacing: 20) {
            Text("\(number)")
                .font(.system(size: 20, weight: .bold, design: .rounded))
                .foregroundColor(.white)
                .frame(width: 40, height: 40)
                .background(Circle().fill(Color.accentColor.opacity(0.2)))
                .overlay(
                    Circle()
                        .stroke(Color.accentColor.opacity(0.3), lineWidth: 1)
                )
            
            Text(text)
                .font(.system(size: 18, weight: .medium, design: .rounded))
                .foregroundColor(.white.opacity(0.9))
                .lineSpacing(4)
        }
    }
    
    private func animateIn() {
        withAnimation(.spring(response: 0.6, dampingFraction: 0.7)) {
            scale = 1
            opacity = 1
        }
    }
}

================
File: VoiceInk/Views/Onboarding/OnboardingView.swift
================
import SwiftUI

struct OnboardingView: View {
    @Binding var hasCompletedOnboarding: Bool
    @State private var textOpacity: CGFloat = 0
    @State private var showSecondaryElements = false
    @State private var showPermissions = false
    
    // Animation timing
    private let animationDelay = 0.2
    private let textAnimationDuration = 0.6
    
    var body: some View {
        ZStack {
            GeometryReader { geometry in
                ZStack {
                    // Reusable background
                    OnboardingBackgroundView()
                    
                    // Content container
                    ScrollView(.vertical, showsIndicators: false) {
                        VStack(spacing: 0) {
                            // Content Area
                            VStack(spacing: 60) {
                                Spacer()
                                    .frame(height: 40)
                                
                                // Title and subtitle
                                VStack(spacing: 16) {
                                    Text("Welcome to the Future of Typing")
                                        .font(.system(size: min(geometry.size.width * 0.055, 42), weight: .bold, design: .rounded))
                                        .foregroundColor(.white)
                                        .opacity(textOpacity)
                                        .multilineTextAlignment(.center)
                                        .padding(.horizontal)
                                    
                                    Text("A New Way to Type")
                                        .font(.system(size: min(geometry.size.width * 0.032, 24), weight: .medium, design: .rounded))
                                        .foregroundColor(.white.opacity(0.7))
                                        .opacity(textOpacity)
                                        .multilineTextAlignment(.center)
                                }
                                
                                if showSecondaryElements {
                                    // Typewriter roles animation
                                    TypewriterRoles()
                                        .frame(height: 160)
                                        .transition(.scale.combined(with: .opacity))
                                        .padding(.horizontal, 40)
                                }
                            }
                            .padding(.top, geometry.size.height * 0.15)
                            
                            Spacer(minLength: geometry.size.height * 0.2)
                            
                            // Bottom navigation
                            if showSecondaryElements {
                                VStack(spacing: 20) {
                                    Button(action: {
                                        withAnimation(.spring(response: 0.5, dampingFraction: 0.7)) {
                                            showPermissions = true
                                        }
                                    }) {
                                        Text("Get Started")
                                            .font(.system(size: 18, weight: .semibold))
                                            .foregroundColor(.black)
                                            .frame(width: min(geometry.size.width * 0.3, 200), height: 50)
                                            .background(Color.white)
                                            .cornerRadius(25)
                                    }
                                    .buttonStyle(ScaleButtonStyle())
                                    
                                    SkipButton(text: "Skip Tour") {
                                        hasCompletedOnboarding = true
                                    }
                                }
                                .padding(.bottom, 35)
                                .transition(.move(edge: .bottom).combined(with: .opacity))
                            }
                        }
                    }
                }
            }
            
            if showPermissions {
                OnboardingPermissionsView(hasCompletedOnboarding: $hasCompletedOnboarding)
                    .transition(.move(edge: .trailing).combined(with: .opacity))
            }
        }
        .onAppear {
            startAnimations()
        }
    }
    
    private func startAnimations() {
        // Text fade in
        withAnimation(.easeOut(duration: textAnimationDuration).delay(animationDelay)) {
            textOpacity = 1
        }
        
        // Show secondary elements
        DispatchQueue.main.asyncAfter(deadline: .now() + animationDelay * 3) {
            withAnimation(.spring(response: 0.5, dampingFraction: 0.8)) {
                showSecondaryElements = true
            }
        }
    }
}

// MARK: - Supporting Views
struct TypewriterRoles: View {
    private let roles = [
        "Your Writing Assistant",
        "Your Vibe-Coding Assistant",
        "Works Everywhere on Mac with a click",
        "100% offline & private",
       
    ]
    
    @State private var displayedText = ""
    @State private var currentIndex = 0
    @State private var showCursor = true
    @State private var isTyping = false
    @State private var isDeleting = false
    
    // Animation timing
    private let typingSpeed = 0.05  // Time between each character
    private let deleteSpeed = 0.03   // Faster deletion
    private let pauseDuration = 1.0  // How long to show completed text
    private let cursorBlinkSpeed = 0.6
    
    var body: some View {
        VStack {
            HStack(spacing: 0) {
                Text(displayedText)
                    .font(.system(size: 42, weight: .bold, design: .rounded))
                    .foregroundStyle(
                        LinearGradient(
                            colors: [
                                Color.accentColor,
                                Color.accentColor.opacity(0.8),
                                Color.white.opacity(0.9)
                            ],
                            startPoint: .topLeading,
                            endPoint: .bottomTrailing
                        )
                    )
                
                // Blinking cursor
                Text("|")
                    .font(.system(size: 42, weight: .bold, design: .rounded))
                    .foregroundStyle(
                        LinearGradient(
                            colors: [
                                Color.accentColor,
                                Color.accentColor.opacity(0.8)
                            ],
                            startPoint: .top,
                            endPoint: .bottom
                        )
                    )
                    .opacity(showCursor ? 1 : 0)
                    .animation(.easeInOut(duration: cursorBlinkSpeed).repeatForever(), value: showCursor)
            }
            .multilineTextAlignment(.center)
            .shadow(color: Color.accentColor.opacity(0.5), radius: 15, x: 0, y: 0)
            .padding(.horizontal)
        }
        .frame(maxWidth: .infinity)
        .onAppear {
            startTypingAnimation()
            // Start cursor blinking
            withAnimation(.easeInOut(duration: cursorBlinkSpeed).repeatForever()) {
                showCursor.toggle()
            }
        }
    }
    
    private func startTypingAnimation() {
        guard currentIndex < roles.count else { return }
        let targetText = roles[currentIndex]
        isTyping = true
        
        // Type out the text
        var charIndex = 0
        func typeNextCharacter() {
            guard charIndex < targetText.count else {
                // Typing complete, pause then delete
                isTyping = false
                DispatchQueue.main.asyncAfter(deadline: .now() + pauseDuration) {
                    startDeletingAnimation()
                }
                return
            }
            
            let nextChar = String(targetText[targetText.index(targetText.startIndex, offsetBy: charIndex)])
            displayedText += nextChar
            charIndex += 1
            
            // Schedule next character
            DispatchQueue.main.asyncAfter(deadline: .now() + typingSpeed) {
                typeNextCharacter()
            }
        }
        
        typeNextCharacter()
    }
    
    private func startDeletingAnimation() {
        isDeleting = true
        
        func deleteNextCharacter() {
            guard !displayedText.isEmpty else {
                isDeleting = false
                currentIndex = (currentIndex + 1) % roles.count
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.3) {
                    startTypingAnimation()
                }
                return
            }
            
            displayedText.removeLast()
            
            // Schedule next deletion
            DispatchQueue.main.asyncAfter(deadline: .now() + deleteSpeed) {
                deleteNextCharacter()
            }
        }
        
        deleteNextCharacter()
    }
}

struct SkipButton: View {
    let text: String
    let action: () -> Void
    
    var body: some View {
        Text(text)
            .font(.system(size: 13, weight: .regular))
            .foregroundColor(.white.opacity(0.2))
            .onTapGesture(perform: action)
    }
}

struct OnboardingBackgroundView: View {
    @State private var glowOpacity: CGFloat = 0
    @State private var glowScale: CGFloat = 0.8
    @State private var particlesActive = false
    
    var body: some View {
        GeometryReader { geometry in
            ZStack {
                // Base background with black gradient
                Color.black
                    .overlay(
                        LinearGradient(
                            colors: [
                                Color.black,
                                Color.black.opacity(0.8),
                                Color.black.opacity(0.6)
                            ],
                            startPoint: .top,
                            endPoint: .bottom
                        )
                    )
                
                // Animated glow effect
                Circle()
                    .fill(Color.accentColor)
                    .frame(width: min(geometry.size.width, geometry.size.height) * 0.4)
                    .blur(radius: 100)
                    .opacity(glowOpacity)
                    .scaleEffect(glowScale)
                    .position(
                        x: geometry.size.width * 0.5,
                        y: geometry.size.height * 0.3
                    )
                
                // Enhanced particles with reduced opacity
                ParticlesView(isActive: $particlesActive)
                    .opacity(0.2)
                    .drawingGroup()
            }
        }
        .onAppear {
            startAnimations()
        }
    }
    
    private func startAnimations() {
        // Glow animation
        withAnimation(.easeInOut(duration: 2.0).repeatForever(autoreverses: true)) {
            glowOpacity = 0.3
            glowScale = 1.2
        }
        
        // Start particles
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.2) {
            particlesActive = true
        }
    }
}

// MARK: - Particles
struct ParticlesView: View {
    @Binding var isActive: Bool
    let particleCount = 60 // Increased particle count
    
    var body: some View {
        TimelineView(.animation) { timeline in
            Canvas { context, size in
                let timeOffset = timeline.date.timeIntervalSinceReferenceDate
                
                for i in 0..<particleCount {
                    let position = particlePosition(index: i, time: timeOffset, size: size)
                    let opacity = particleOpacity(index: i, time: timeOffset)
                    let scale = particleScale(index: i, time: timeOffset)
                    
                    context.opacity = opacity
                    context.fill(
                        Circle().path(in: CGRect(
                            x: position.x - scale/2,
                            y: position.y - scale/2,
                            width: scale,
                            height: scale
                        )),
                        with: .color(.white)
                    )
                }
            }
        }
        .opacity(isActive ? 1 : 0)
    }
    
    private func particlePosition(index: Int, time: TimeInterval, size: CGSize) -> CGPoint {
        let relativeIndex = Double(index) / Double(particleCount)
        let speed = 0.3 // Slower, more graceful movement
        let radius = min(size.width, size.height) * 0.45
        
        let angle = time * speed + relativeIndex * .pi * 4
        let x = sin(angle) * radius + size.width * 0.5
        let y = cos(angle * 0.5) * radius + size.height * 0.5
        
        return CGPoint(x: x, y: y)
    }
    
    private func particleOpacity(index: Int, time: TimeInterval) -> Double {
        let relativeIndex = Double(index) / Double(particleCount)
        return (sin(time + relativeIndex * .pi * 2) + 1) * 0.3 // Reduced opacity for subtlety
    }
    
    private func particleScale(index: Int, time: TimeInterval) -> CGFloat {
        let relativeIndex = Double(index) / Double(particleCount)
        let baseScale: CGFloat = 3
        return baseScale + sin(time * 2 + relativeIndex * .pi) * 2
    }
}

// MARK: - Button Style
struct ScaleButtonStyle: ButtonStyle {
    func makeBody(configuration: Configuration) -> some View {
        configuration.label
            .scaleEffect(configuration.isPressed ? 0.97 : 1)
            .animation(.spring(response: 0.3, dampingFraction: 0.7), value: configuration.isPressed)
    }
}

// MARK: - Preview
#Preview {
    OnboardingView(hasCompletedOnboarding: .constant(false))
}

================
File: VoiceInk/Views/Settings/AudioCleanupManager.swift
================
import Foundation
import SwiftData
import OSLog

/// A utility class that manages automatic cleanup of audio files while preserving transcript data
class AudioCleanupManager {
    static let shared = AudioCleanupManager()
    
    private let logger = Logger(subsystem: "com.prakashjoshipax.voiceink", category: "AudioCleanupManager")
    private var cleanupTimer: Timer?
    
    // Default cleanup settings
    private let defaultRetentionDays = 7
    private let cleanupCheckInterval: TimeInterval = 86400 // Check once per day (in seconds)
    
    private init() {
        logger.info("AudioCleanupManager initialized")
    }
    
    /// Start the automatic cleanup process
    func startAutomaticCleanup(modelContext: ModelContext) {
        logger.info("Starting automatic audio cleanup")
        
        // Cancel any existing timer
        cleanupTimer?.invalidate()
        
        // Perform initial cleanup
        Task {
            await performCleanup(modelContext: modelContext)
        }
        
        // Schedule regular cleanup
        cleanupTimer = Timer.scheduledTimer(withTimeInterval: cleanupCheckInterval, repeats: true) { [weak self] _ in
            Task { [weak self] in
                await self?.performCleanup(modelContext: modelContext)
            }
        }
        
        logger.info("Automatic cleanup scheduled")
    }
    
    /// Stop the automatic cleanup process
    func stopAutomaticCleanup() {
        logger.info("Stopping automatic audio cleanup")
        cleanupTimer?.invalidate()
        cleanupTimer = nil
    }
    
    /// Get information about the files that would be cleaned up
    func getCleanupInfo(modelContext: ModelContext) async -> (fileCount: Int, totalSize: Int64, transcriptions: [Transcription]) {
        logger.info("Analyzing potential audio cleanup")
        
        // Get retention period from UserDefaults
        let retentionDays = UserDefaults.standard.integer(forKey: "AudioRetentionPeriod")
        let effectiveRetentionDays = retentionDays > 0 ? retentionDays : defaultRetentionDays
        
        // Calculate the cutoff date
        let calendar = Calendar.current
        guard let cutoffDate = calendar.date(byAdding: .day, value: -effectiveRetentionDays, to: Date()) else {
            logger.error("Failed to calculate cutoff date")
            return (0, 0, [])
        }
        
        do {
            // Execute SwiftData operations on the main thread
            return try await MainActor.run {
                // Create a predicate to find transcriptions with audio files older than the cutoff date
                let descriptor = FetchDescriptor<Transcription>(
                    predicate: #Predicate<Transcription> { transcription in
                        transcription.timestamp < cutoffDate && 
                        transcription.audioFileURL != nil
                    }
                )
                
                let transcriptions = try modelContext.fetch(descriptor)
                
                // Calculate stats (can be done on any thread)
                var fileCount = 0
                var totalSize: Int64 = 0
                var eligibleTranscriptions: [Transcription] = []
                
                for transcription in transcriptions {
                    if let urlString = transcription.audioFileURL,
                       let url = URL(string: urlString),
                       FileManager.default.fileExists(atPath: url.path) {
                        do {
                            // Get file attributes to determine size
                            let attributes = try FileManager.default.attributesOfItem(atPath: url.path)
                            if let fileSize = attributes[.size] as? Int64 {
                                totalSize += fileSize
                                fileCount += 1
                                eligibleTranscriptions.append(transcription)
                            }
                        } catch {
                            self.logger.error("Failed to get attributes for \(url.lastPathComponent): \(error.localizedDescription)")
                        }
                    }
                }
                
                self.logger.info("Found \(fileCount) files eligible for cleanup, totaling \(self.formatFileSize(totalSize))")
                return (fileCount, totalSize, eligibleTranscriptions)
            }
        } catch {
            logger.error("Error analyzing files for cleanup: \(error.localizedDescription)")
            return (0, 0, [])
        }
    }
    
    /// Perform the cleanup operation
    private func performCleanup(modelContext: ModelContext) async {
        logger.info("Performing audio cleanup")
        
        // Get retention period from UserDefaults
        let retentionDays = UserDefaults.standard.integer(forKey: "AudioRetentionPeriod")
        let effectiveRetentionDays = retentionDays > 0 ? retentionDays : defaultRetentionDays
        
        // Check if automatic cleanup is enabled
        let isCleanupEnabled = UserDefaults.standard.bool(forKey: "IsAudioCleanupEnabled")
        guard isCleanupEnabled else {
            logger.info("Audio cleanup is disabled, skipping")
            return
        }
        
        logger.info("Audio retention period: \(effectiveRetentionDays) days")
        
        // Calculate the cutoff date
        let calendar = Calendar.current
        guard let cutoffDate = calendar.date(byAdding: .day, value: -effectiveRetentionDays, to: Date()) else {
            logger.error("Failed to calculate cutoff date")
            return
        }
        
        logger.info("Cutoff date for audio cleanup: \(cutoffDate)")
        
        do {
            // Execute SwiftData operations on the main thread
            try await MainActor.run {
                // Create a predicate to find transcriptions with audio files older than the cutoff date
                let descriptor = FetchDescriptor<Transcription>(
                    predicate: #Predicate<Transcription> { transcription in
                        transcription.timestamp < cutoffDate && 
                        transcription.audioFileURL != nil
                    }
                )
                
                let transcriptions = try modelContext.fetch(descriptor)
                self.logger.info("Found \(transcriptions.count) transcriptions with audio files to clean up")
                
                var deletedCount = 0
                var errorCount = 0
                
                for transcription in transcriptions {
                    if let urlString = transcription.audioFileURL,
                       let url = URL(string: urlString),
                       FileManager.default.fileExists(atPath: url.path) {
                        do {
                            // Delete the audio file
                            try FileManager.default.removeItem(at: url)
                            
                            // Update the transcription to remove the audio file reference
                            transcription.audioFileURL = nil
                            
                            deletedCount += 1
                            self.logger.debug("Deleted audio file: \(url.lastPathComponent)")
                        } catch {
                            errorCount += 1
                            self.logger.error("Failed to delete audio file \(url.lastPathComponent): \(error.localizedDescription)")
                        }
                    }
                }
                
                if deletedCount > 0 || errorCount > 0 {
                    try modelContext.save()
                    self.logger.info("Cleanup complete. Deleted \(deletedCount) files. Failed: \(errorCount)")
                }
            }
        } catch {
            logger.error("Error during audio cleanup: \(error.localizedDescription)")
        }
    }
    
    /// Run cleanup manually - can be called from settings
    func runManualCleanup(modelContext: ModelContext) async {
        await performCleanup(modelContext: modelContext)
    }
    
    /// Run cleanup on the specified transcriptions
    func runCleanupForTranscriptions(modelContext: ModelContext, transcriptions: [Transcription]) async -> (deletedCount: Int, errorCount: Int) {
        logger.info("Running cleanup for \(transcriptions.count) specific transcriptions")
        
        do {
            // Execute SwiftData operations on the main thread
            return try await MainActor.run {
                var deletedCount = 0
                var errorCount = 0
                
                for transcription in transcriptions {
                    if let urlString = transcription.audioFileURL,
                       let url = URL(string: urlString),
                       FileManager.default.fileExists(atPath: url.path) {
                        do {
                            // Delete the audio file
                            try FileManager.default.removeItem(at: url)
                            
                            // Update the transcription to remove the audio file reference
                            transcription.audioFileURL = nil
                            
                            deletedCount += 1
                            self.logger.debug("Deleted audio file: \(url.lastPathComponent)")
                        } catch {
                            errorCount += 1
                            self.logger.error("Failed to delete audio file \(url.lastPathComponent): \(error.localizedDescription)")
                        }
                    }
                }
                
                if deletedCount > 0 || errorCount > 0 {
                    do {
                        try modelContext.save()
                        self.logger.info("Cleanup complete. Deleted \(deletedCount) files. Failed: \(errorCount)")
                    } catch {
                        self.logger.error("Error saving model context after cleanup: \(error.localizedDescription)")
                    }
                }
                
                return (deletedCount, errorCount)
            }
        } catch {
            logger.error("Error during targeted cleanup: \(error.localizedDescription)")
            return (0, 0)
        }
    }
    
    /// Format file size in human-readable form
    func formatFileSize(_ size: Int64) -> String {
        let byteCountFormatter = ByteCountFormatter()
        byteCountFormatter.allowedUnits = [.useKB, .useMB, .useGB]
        byteCountFormatter.countStyle = .file
        return byteCountFormatter.string(fromByteCount: size)
    }
}

================
File: VoiceInk/Views/Settings/AudioCleanupSettingsView.swift
================
import SwiftUI
import SwiftData

/// A view component for configuring audio cleanup settings
struct AudioCleanupSettingsView: View {
    @EnvironmentObject private var whisperState: WhisperState
    
    // Audio cleanup settings
    @AppStorage("IsAudioCleanupEnabled") private var isAudioCleanupEnabled = true
    @AppStorage("AudioRetentionPeriod") private var audioRetentionPeriod = 7
    @State private var isPerformingCleanup = false
    @State private var isShowingConfirmation = false
    @State private var cleanupInfo: (fileCount: Int, totalSize: Int64, transcriptions: [Transcription]) = (0, 0, [])
    @State private var showResultAlert = false
    @State private var cleanupResult: (deletedCount: Int, errorCount: Int) = (0, 0)
    
    var body: some View {
        VStack(alignment: .leading, spacing: 12) {
            Text("VoiceInk can automatically delete audio files from transcription history while preserving the text transcripts.")
                .font(.system(size: 13))
                .foregroundColor(.secondary)
                .fixedSize(horizontal: false, vertical: true)
            
            Toggle("Enable automatic audio cleanup", isOn: $isAudioCleanupEnabled)
                .toggleStyle(.switch)
                .padding(.vertical, 4)
            
            if isAudioCleanupEnabled {
                VStack(alignment: .leading, spacing: 8) {
                    Text("Retention Period")
                        .font(.system(size: 14, weight: .medium))
                    
                    Picker("Keep audio files for", selection: $audioRetentionPeriod) {
                        Text("1 day").tag(1)
                        Text("3 days").tag(3)
                        Text("7 days").tag(7)
                        Text("14 days").tag(14)
                        Text("30 days").tag(30)
                    }
                    .pickerStyle(.menu)
                    
                    Text("Audio files older than the selected period will be automatically deleted, while keeping the text transcripts intact.")
                        .font(.system(size: 13))
                        .foregroundColor(.secondary)
                        .fixedSize(horizontal: false, vertical: true)
                        .padding(.top, 2)
                }
                .padding(.vertical, 4)
                
                Button(action: {
                    // Start by analyzing what would be cleaned up
                    Task {
                        // Update UI state
                        await MainActor.run {
                            isPerformingCleanup = true
                        }
                        
                        // Get cleanup info
                        let info = await AudioCleanupManager.shared.getCleanupInfo(modelContext: whisperState.modelContext)
                        
                        // Update UI with results
                        await MainActor.run {
                            cleanupInfo = info
                            isPerformingCleanup = false
                            isShowingConfirmation = true
                        }
                    }
                }) {
                    HStack {
                        if isPerformingCleanup {
                            ProgressView()
                                .controlSize(.small)
                                .padding(.trailing, 4)
                        } else {
                            Image(systemName: "arrow.clockwise")
                        }
                        Text(isPerformingCleanup ? "Analyzing..." : "Run Cleanup Now")
                    }
                }
                .buttonStyle(.bordered)
                .controlSize(.large)
                .disabled(isPerformingCleanup)
                .alert("Audio Cleanup", isPresented: $isShowingConfirmation) {
                    Button("Cancel", role: .cancel) { }
                    
                    if cleanupInfo.fileCount > 0 {
                        Button("Delete \(cleanupInfo.fileCount) Files", role: .destructive) {
                            Task {
                                // Update UI state
                                await MainActor.run {
                                    isPerformingCleanup = true
                                }
                                
                                // Perform cleanup
                                let result = await AudioCleanupManager.shared.runCleanupForTranscriptions(
                                    modelContext: whisperState.modelContext, 
                                    transcriptions: cleanupInfo.transcriptions
                                )
                                
                                // Update UI with results
                                await MainActor.run {
                                    cleanupResult = result
                                    isPerformingCleanup = false
                                    showResultAlert = true
                                }
                            }
                        }
                    }
                } message: {
                    VStack(alignment: .leading, spacing: 8) {
                        if cleanupInfo.fileCount > 0 {
                            Text("This will delete \(cleanupInfo.fileCount) audio files older than \(audioRetentionPeriod) day\(audioRetentionPeriod > 1 ? "s" : "").")
                            Text("Total size to be freed: \(AudioCleanupManager.shared.formatFileSize(cleanupInfo.totalSize))")
                            Text("The text transcripts will be preserved.")
                        } else {
                            Text("No audio files found that are older than \(audioRetentionPeriod) day\(audioRetentionPeriod > 1 ? "s" : "").")
                        }
                    }
                }
                .alert("Cleanup Complete", isPresented: $showResultAlert) {
                    Button("OK", role: .cancel) { }
                } message: {
                    if cleanupResult.errorCount > 0 {
                        Text("Successfully deleted \(cleanupResult.deletedCount) audio files. Failed to delete \(cleanupResult.errorCount) files.")
                    } else {
                        Text("Successfully deleted \(cleanupResult.deletedCount) audio files.")
                    }
                }
            }
        }
    }
}

================
File: VoiceInk/Views/Settings/AudioInputSettingsView.swift
================
import SwiftUI

struct AudioInputSettingsView: View {
    @ObservedObject var audioDeviceManager = AudioDeviceManager.shared
    @Environment(\.colorScheme) private var colorScheme
    
    var body: some View {
        ScrollView {
            VStack(spacing: 0) {
                heroSection
                mainContent
            }
        }
        .background(Color(NSColor.controlBackgroundColor))
    }
    
    private var mainContent: some View {
        VStack(spacing: 40) {
            inputModeSection
            
            if audioDeviceManager.inputMode == .custom {
                customDeviceSection
            } else if audioDeviceManager.inputMode == .prioritized {
                prioritizedDevicesSection
            }
        }
        .padding(.horizontal, 32)
        .padding(.vertical, 40)
    }
    
    private var heroSection: some View {
        VStack(spacing: 24) {
            Image(systemName: "waveform")
                .font(.system(size: 40))
                .foregroundStyle(.blue)
                .padding(20)
                .background(Circle()
                    .fill(Color(.windowBackgroundColor).opacity(0.4))
                    .shadow(color: .black.opacity(0.1), radius: 10, y: 5))
            
            VStack(spacing: 8) {
                Text("Audio Input")
                    .font(.system(size: 28, weight: .bold))
                Text("Configure your microphone preferences")
                    .font(.system(size: 15))
                    .foregroundStyle(.secondary)
            }
        }
        .padding(.vertical, 40)
        .frame(maxWidth: .infinity)
    }
    
    private var inputModeSection: some View {
        VStack(alignment: .leading, spacing: 20) {
            Text("Input Mode")
                .font(.title2)
                .fontWeight(.semibold)
            
            HStack(spacing: 20) {
                ForEach(AudioInputMode.allCases, id: \.self) { mode in
                    InputModeCard(
                        mode: mode,
                        isSelected: audioDeviceManager.inputMode == mode,
                        action: { audioDeviceManager.selectInputMode(mode) }
                    )
                }
            }
        }
    }
    
    private var customDeviceSection: some View {
        VStack(alignment: .leading, spacing: 20) {
            HStack {
                Text("Available Devices")
                    .font(.title2)
                    .fontWeight(.semibold)
                
                Spacer()
                
                Button(action: { audioDeviceManager.loadAvailableDevices() }) {
                    Label("Refresh", systemImage: "arrow.clockwise")
                }
                .buttonStyle(.borderless)
            }
            
            VStack(spacing: 12) {
                ForEach(audioDeviceManager.availableDevices, id: \.id) { device in
                    DeviceSelectionCard(
                        name: device.name,
                        isSelected: audioDeviceManager.selectedDeviceID == device.id,
                        isActive: audioDeviceManager.getCurrentDevice() == device.id
                    ) {
                        audioDeviceManager.selectDevice(id: device.id)
                    }
                }
            }
        }
    }
    
    private var prioritizedDevicesSection: some View {
        VStack(alignment: .leading, spacing: 20) {
            if audioDeviceManager.availableDevices.isEmpty {
                emptyDevicesState
            } else {
                prioritizedDevicesContent
                Divider().padding(.vertical, 8)
                availableDevicesContent
            }
        }
    }
    
    private var prioritizedDevicesContent: some View {
        VStack(alignment: .leading, spacing: 12) {
            VStack(alignment: .leading, spacing: 4) {
                Text("Prioritized Devices")
                    .font(.title2)
                    .fontWeight(.semibold)
                Text("Devices will be used in order of priority. If a device is unavailable, the next one will be tried. If no prioritized device is available, the system default microphone will be used.")
                    .font(.subheadline)
                    .foregroundStyle(.secondary)
                    .fixedSize(horizontal: false, vertical: true)
            }
            
            if audioDeviceManager.prioritizedDevices.isEmpty {
                Text("No prioritized devices")
                    .foregroundStyle(.secondary)
                    .padding(.vertical, 8)
            } else {
                prioritizedDevicesList
            }
        }
    }
    
    private var availableDevicesContent: some View {
        VStack(alignment: .leading, spacing: 12) {
            Text("Available Devices")
                .font(.title2)
                .fontWeight(.semibold)
            
            availableDevicesList
        }
    }
    
    private var emptyDevicesState: some View {
        VStack(spacing: 16) {
            Image(systemName: "mic.slash.circle.fill")
                .font(.system(size: 48))
                .symbolRenderingMode(.hierarchical)
                .foregroundStyle(.secondary)
            
            VStack(spacing: 8) {
                Text("No Audio Devices")
                    .font(.headline)
                Text("Connect an audio input device to get started")
                    .font(.subheadline)
                    .foregroundStyle(.secondary)
            }
        }
        .frame(maxWidth: .infinity)
        .padding(40)
        .background(
            RoundedRectangle(cornerRadius: 16)
                .fill(Color(.windowBackgroundColor).opacity(0.4))
        )
    }
    
    private var prioritizedDevicesList: some View {
        VStack(spacing: 12) {
            ForEach(audioDeviceManager.prioritizedDevices.sorted(by: { $0.priority < $1.priority })) { device in
                devicePriorityCard(for: device)
            }
        }
    }
    
    private func devicePriorityCard(for prioritizedDevice: PrioritizedDevice) -> some View {
        let device = audioDeviceManager.availableDevices.first(where: { $0.uid == prioritizedDevice.id })
        return DevicePriorityCard(
            name: prioritizedDevice.name,
            priority: prioritizedDevice.priority,
            isActive: device.map { audioDeviceManager.getCurrentDevice() == $0.id } ?? false,
            isPrioritized: true,
            isAvailable: device != nil,
            canMoveUp: prioritizedDevice.priority > 0,
            canMoveDown: prioritizedDevice.priority < audioDeviceManager.prioritizedDevices.count - 1,
            onTogglePriority: { audioDeviceManager.removePrioritizedDevice(id: prioritizedDevice.id) },
            onMoveUp: { moveDeviceUp(prioritizedDevice) },
            onMoveDown: { moveDeviceDown(prioritizedDevice) }
        )
    }
    
    private var availableDevicesList: some View {
        let unprioritizedDevices = audioDeviceManager.availableDevices.filter { device in
            !audioDeviceManager.prioritizedDevices.contains { $0.id == device.uid }
        }
        
        return Group {
            if unprioritizedDevices.isEmpty {
                Text("No additional devices available")
                    .foregroundStyle(.secondary)
                    .padding(.vertical, 8)
            } else {
                ForEach(unprioritizedDevices, id: \.id) { device in
                    DevicePriorityCard(
                        name: device.name,
                        priority: nil,
                        isActive: audioDeviceManager.getCurrentDevice() == device.id,
                        isPrioritized: false,
                        isAvailable: true,
                        canMoveUp: false,
                        canMoveDown: false,
                        onTogglePriority: { audioDeviceManager.addPrioritizedDevice(uid: device.uid, name: device.name) },
                        onMoveUp: {},
                        onMoveDown: {}
                    )
                }
            }
        }
    }
    
    private func moveDeviceUp(_ device: PrioritizedDevice) {
        guard device.priority > 0,
              let currentIndex = audioDeviceManager.prioritizedDevices.firstIndex(where: { $0.id == device.id })
        else { return }
        
        var devices = audioDeviceManager.prioritizedDevices
        devices.swapAt(currentIndex, currentIndex - 1)
        updatePriorities(devices)
    }
    
    private func moveDeviceDown(_ device: PrioritizedDevice) {
        guard device.priority < audioDeviceManager.prioritizedDevices.count - 1,
              let currentIndex = audioDeviceManager.prioritizedDevices.firstIndex(where: { $0.id == device.id })
        else { return }
        
        var devices = audioDeviceManager.prioritizedDevices
        devices.swapAt(currentIndex, currentIndex + 1)
        updatePriorities(devices)
    }
    
    private func updatePriorities(_ devices: [PrioritizedDevice]) {
        let updatedDevices = devices.enumerated().map { index, device in
            PrioritizedDevice(id: device.id, name: device.name, priority: index)
        }
        audioDeviceManager.updatePriorities(devices: updatedDevices)
    }
}

struct InputModeCard: View {
    let mode: AudioInputMode
    let isSelected: Bool
    let action: () -> Void
    
    private var icon: String {
        switch mode {
        case .systemDefault: return "macbook.and.iphone"
        case .custom: return "mic.circle.fill"
        case .prioritized: return "list.number"
        }
    }
    
    private var description: String {
        switch mode {
        case .systemDefault: return "Use system's default input device"
        case .custom: return "Select a specific input device"
        case .prioritized: return "Set up device priority order"
        }
    }
    
    var body: some View {
        Button(action: action) {
            VStack(alignment: .leading, spacing: 12) {
                Image(systemName: icon)
                    .font(.system(size: 28))
                    .symbolRenderingMode(.hierarchical)
                    .foregroundStyle(isSelected ? .blue : .secondary)
                
                VStack(alignment: .leading, spacing: 4) {
                    Text(mode.rawValue)
                        .font(.headline)
                    
                    Text(description)
                        .font(.subheadline)
                        .foregroundStyle(.secondary)
                        .fixedSize(horizontal: false, vertical: true)
                }
            }
            .frame(maxWidth: .infinity, alignment: .leading)
            .padding()
            .background(
                RoundedRectangle(cornerRadius: 16)
                    .fill(Color(.windowBackgroundColor).opacity(0.4))
                    .shadow(color: isSelected ? .blue.opacity(0.2) : .clear, radius: 8, y: 4)
                    .overlay(
                        RoundedRectangle(cornerRadius: 16)
                            .stroke(isSelected ? .blue.opacity(0.5) : .clear, lineWidth: 2)
                    )
            )
        }
        .buttonStyle(.plain)
    }
}

struct DeviceSelectionCard: View {
    let name: String
    let isSelected: Bool
    let isActive: Bool
    let action: () -> Void
    
    var body: some View {
        Button(action: action) {
            HStack {
                Image(systemName: isSelected ? "checkmark.circle.fill" : "circle")
                    .symbolRenderingMode(.hierarchical)
                    .foregroundStyle(isSelected ? .blue : .secondary)
                    .font(.system(size: 18))
                
                Text(name)
                    .foregroundStyle(.primary)
                
                Spacer()
                
                if isActive {
                    Label("Active", systemImage: "wave.3.right")
                        .font(.caption)
                        .foregroundStyle(.green)
                        .padding(.horizontal, 10)
                        .padding(.vertical, 4)
                        .background(
                            Capsule()
                                .fill(.green.opacity(0.1))
                        )
                }
            }
            .padding()
            .background(
                RoundedRectangle(cornerRadius: 12)
                    .fill(Color(.windowBackgroundColor).opacity(0.4))
            )
        }
        .buttonStyle(.plain)
    }
}

struct DevicePriorityCard: View {
    let name: String
    let priority: Int?
    let isActive: Bool
    let isPrioritized: Bool
    let isAvailable: Bool
    let canMoveUp: Bool
    let canMoveDown: Bool
    let onTogglePriority: () -> Void
    let onMoveUp: () -> Void
    let onMoveDown: () -> Void
    
    var body: some View {
        HStack {
            // Priority number or dash
            if let priority = priority {
                Text("\(priority + 1)")
                    .font(.system(size: 18, weight: .medium))
                    .foregroundStyle(.secondary)
                    .frame(width: 24)
            } else {
                Text("-")
                    .font(.system(size: 18, weight: .medium))
                    .foregroundStyle(.secondary)
                    .frame(width: 24)
            }
            
            // Device name
            Text(name)
                .foregroundStyle(isAvailable ? .primary : .secondary)
            
            Spacer()
            
            // Status and Controls
            HStack(spacing: 12) {
                // Active status
                if isActive {
                    Label("Active", systemImage: "wave.3.right")
                        .font(.caption)
                        .foregroundStyle(.green)
                        .padding(.horizontal, 10)
                        .padding(.vertical, 4)
                        .background(
                            Capsule()
                                .fill(.green.opacity(0.1))
                        )
                } else if !isAvailable && isPrioritized {
                    Label("Unavailable", systemImage: "exclamationmark.triangle")
                        .font(.caption)
                        .foregroundStyle(.secondary)
                        .padding(.horizontal, 10)
                        .padding(.vertical, 4)
                        .background(
                            Capsule()
                                .fill(Color(.windowBackgroundColor).opacity(0.4))
                        )
                }
                
                // Priority controls (only show if prioritized)
                if isPrioritized {
                    HStack(spacing: 2) {
                        Button(action: onMoveUp) {
                            Image(systemName: "chevron.up")
                                .foregroundStyle(canMoveUp ? .blue : .secondary.opacity(0.5))
                        }
                        .disabled(!canMoveUp)
                        
                        Button(action: onMoveDown) {
                            Image(systemName: "chevron.down")
                                .foregroundStyle(canMoveDown ? .blue : .secondary.opacity(0.5))
                        }
                        .disabled(!canMoveDown)
                    }
                }
                
                // Toggle priority button
                Button(action: onTogglePriority) {
                    Image(systemName: isPrioritized ? "minus.circle.fill" : "plus.circle.fill")
                        .symbolRenderingMode(.hierarchical)
                        .foregroundStyle(isPrioritized ? .red : .blue)
                }
            }
            .buttonStyle(.plain)
        }
        .padding()
        .background(
            RoundedRectangle(cornerRadius: 16)
                .fill(Color(.windowBackgroundColor).opacity(0.4))
                .opacity(isAvailable ? 1 : 0.8)
        )
    }
}

================
File: VoiceInk/Views/Settings/SettingsView.swift
================
import SwiftUI
import Cocoa
import KeyboardShortcuts
import LaunchAtLogin
import AVFoundation
// Additional imports for Settings components

struct SettingsView: View {
    @EnvironmentObject private var updaterViewModel: UpdaterViewModel
    @EnvironmentObject private var menuBarManager: MenuBarManager
    @EnvironmentObject private var hotkeyManager: HotkeyManager
    @EnvironmentObject private var whisperState: WhisperState
    @StateObject private var deviceManager = AudioDeviceManager.shared
    @AppStorage("hasCompletedOnboarding") private var hasCompletedOnboarding = true
    @State private var showResetOnboardingAlert = false
    @State private var currentShortcut = KeyboardShortcuts.getShortcut(for: .toggleMiniRecorder)
    
    var body: some View {
        ScrollView {
            VStack(spacing: 24) {
                // Keyboard Shortcuts Section first
                SettingsSection(
                    icon: currentShortcut != nil ? "keyboard" : "keyboard.badge.exclamationmark",
                    title: "Keyboard Shortcuts",
                    subtitle: currentShortcut != nil ? "Shortcut configured" : "Shortcut required",
                    showWarning: currentShortcut == nil
                ) {
                    VStack(alignment: .leading, spacing: 8) {
                        if currentShortcut == nil {
                            Text("‚ö†Ô∏è Please set a keyboard shortcut to use VoiceInk")
                                .foregroundColor(.orange)
                                .font(.subheadline)
                        }
                        
                        HStack(alignment: .center, spacing: 16) {
                            if let shortcut = currentShortcut {
                                KeyboardShortcutView(shortcut: shortcut)
                            } else {
                                Text("Not Set")
                                    .foregroundColor(.secondary)
                                    .italic()
                            }
                            
                            Button(action: {
                                KeyboardShortcuts.reset(.toggleMiniRecorder)
                                currentShortcut = nil
                            }) {
                                Image(systemName: "arrow.counterclockwise")
                                    .foregroundColor(.secondary)
                            }
                            .buttonStyle(.borderless)
                            .help("Reset Shortcut")
                        }
                        
                        KeyboardShortcuts.Recorder("Change Shortcut:", name: .toggleMiniRecorder) { newShortcut in
                            currentShortcut = newShortcut
                            hotkeyManager.updateShortcutStatus()
                        }
                        .controlSize(.large)
                        
                        Divider()
                            .padding(.vertical, 4)
                        
                        VStack(alignment: .leading, spacing: 6) {
                            Toggle("Enable Push-to-Talk", isOn: $hotkeyManager.isPushToTalkEnabled)
                                .toggleStyle(.switch)
                            
                            if hotkeyManager.isPushToTalkEnabled {
                                if currentShortcut == nil {
                                    HStack(spacing: 6) {
                                        Image(systemName: "exclamationmark.triangle.fill")
                                            .foregroundColor(.orange)
                                        Text("Please set a keyboard shortcut first to use Push-to-Talk")
                                            .settingsDescription()
                                            .foregroundColor(.orange)
                                    }
                                    .padding(.vertical, 4)
                                } else {
                                    VStack(alignment: .leading, spacing: 12) {
                                        Text("Choose Push-to-Talk Key")
                                            .font(.system(size: 13, weight: .medium))
                                            .foregroundColor(.secondary)
                                        
                                        PushToTalkKeySelector(selectedKey: $hotkeyManager.pushToTalkKey)
                                            .padding(.vertical, 4)
                                        
                                    
                                        
                                        VideoCTAView(
                                            url: "https://dub.sh/shortcut",
                                            subtitle: "Pro tip for Push-to-Talk setup"
                                        )
                                    }
                                    .padding(.top, 4)
                                }
                            }
                        }
                    }
                }
                
                // Startup Section
                SettingsSection(
                    icon: "power",
                    title: "Startup",
                    subtitle: "Launch options"
                ) {
                    VStack(alignment: .leading, spacing: 8) {
                        Text("Choose whether VoiceInk should start automatically when you log in.")
                            .settingsDescription()
                        
                        LaunchAtLogin.Toggle()
                            .toggleStyle(.switch)
                    }
                }
                
                // Updates Section
                SettingsSection(
                    icon: "arrow.triangle.2.circlepath",
                    title: "Updates",
                    subtitle: "Keep VoiceInk up to date"
                ) {
                    VStack(alignment: .leading, spacing: 8) {
                        Text("VoiceInk automatically checks for updates on launch and every other day.")
                            .settingsDescription()
                        
                        Button("Check for Updates Now") {
                            updaterViewModel.checkForUpdates()
                        }
                        .buttonStyle(.bordered)
                        .controlSize(.large)
                        .disabled(!updaterViewModel.canCheckForUpdates)
                    }
                }
                
                // App Appearance Section
                SettingsSection(
                    icon: "dock.rectangle",
                    title: "App Appearance",
                    subtitle: "Dock and Menu Bar options"
                ) {
                    VStack(alignment: .leading, spacing: 8) {
                        Text("Choose how VoiceInk appears in your system.")
                            .settingsDescription()
                        
                        Toggle("Hide Dock Icon (Menu Bar Only)", isOn: $menuBarManager.isMenuBarOnly)
                            .toggleStyle(.switch)
                    }
                }
                
                // Paste Method Section
                SettingsSection(
                    icon: "doc.on.clipboard",
                    title: "Paste Method",
                    subtitle: "Choose how text is pasted"
                ) {
                    VStack(alignment: .leading, spacing: 8) {
                        Text("Select the method used to paste text. Use AppleScript if you have a non-standard keyboard layout.")
                            .settingsDescription()
                        
                        Toggle("Use AppleScript Paste Method", isOn: Binding(
                            get: { UserDefaults.standard.bool(forKey: "UseAppleScriptPaste") },
                            set: { UserDefaults.standard.set($0, forKey: "UseAppleScriptPaste") }
                        ))
                        .toggleStyle(.switch)
                    }
                }
                
                // Recorder Preference Section
                SettingsSection(
                    icon: "rectangle.on.rectangle",
                    title: "Recorder Style",
                    subtitle: "Choose your preferred recorder interface"
                ) {
                    VStack(alignment: .leading, spacing: 8) {
                        Text("Select how you want the recorder to appear on your screen.")
                            .settingsDescription()
                        
                        Picker("Recorder Style", selection: $whisperState.recorderType) {
                            Text("Notch Recorder").tag("notch")
                            Text("Mini Recorder").tag("mini")
                        }
                        .pickerStyle(.radioGroup)
                        .padding(.vertical, 4)
                    }
                }
                
                // Audio Cleanup Section
                SettingsSection(
                    icon: "trash.circle",
                    title: "Audio Cleanup",
                    subtitle: "Manage recording storage"
                ) {
                    AudioCleanupSettingsView()
                }
                
                // Reset Onboarding Section
                SettingsSection(
                    icon: "arrow.counterclockwise",
                    title: "Reset Onboarding",
                    subtitle: "View the introduction again"
                ) {
                    VStack(alignment: .leading, spacing: 8) {
                        Text("Reset the onboarding process to view the app introduction again.")
                            .settingsDescription()
                        
                        Button("Reset Onboarding") {
                            showResetOnboardingAlert = true
                        }
                        .buttonStyle(.bordered)
                        .controlSize(.large)
                    }
                }
            }
            .padding(.horizontal, 20)
            .padding(.vertical, 6)
        }
        .alert("Reset Onboarding", isPresented: $showResetOnboardingAlert) {
            Button("Cancel", role: .cancel) { }
            Button("Reset", role: .destructive) {
                hasCompletedOnboarding = false
            }
        } message: {
            Text("Are you sure you want to reset the onboarding? You'll see the introduction screens again the next time you launch the app.")
        }
    }
    
    private func getPushToTalkDescription() -> String {
        switch hotkeyManager.pushToTalkKey {
        case .rightOption:
            return "Using Right Option (‚å•) key to quickly start recording. Release to stop."
        case .fn:
            return "Using Function (Fn) key to quickly start recording. Release to stop."
        case .rightCommand:
            return "Using Right Command (‚åò) key to quickly start recording. Release to stop."
        case .rightShift:
            return "Using Right Shift (‚áß) key to quickly start recording. Release to stop."
        }
    }
}

struct SettingsSection<Content: View>: View {
    let icon: String
    let title: String
    let subtitle: String
    let content: Content
    var showWarning: Bool = false
    
    init(icon: String, title: String, subtitle: String, showWarning: Bool = false, @ViewBuilder content: () -> Content) {
        self.icon = icon
        self.title = title
        self.subtitle = subtitle
        self.showWarning = showWarning
        self.content = content()
    }
    
    var body: some View {
        VStack(alignment: .leading, spacing: 12) {
            HStack(spacing: 12) {
                Image(systemName: icon)
                    .font(.system(size: 20))
                    .foregroundColor(showWarning ? .red : .accentColor)
                    .frame(width: 24, height: 24)
                
                VStack(alignment: .leading, spacing: 2) {
                    Text(title)
                        .font(.headline)
                    Text(subtitle)
                        .font(.subheadline)
                        .foregroundColor(showWarning ? .red : .secondary)
                }
                
                if showWarning {
                    Spacer()
                    Image(systemName: "exclamationmark.triangle.fill")
                        .foregroundColor(.red)
                        .help("Permission required for VoiceInk to function properly")
                }
            }
            
            Divider()
                .padding(.vertical, 4)
            
            content
        }
        .padding(16)
        .frame(maxWidth: .infinity, alignment: .leading)
        .background(
            RoundedRectangle(cornerRadius: 12)
                .fill(Color(NSColor.windowBackgroundColor))
                .overlay(
                    RoundedRectangle(cornerRadius: 12)
                        .fill(Color(NSColor.controlBackgroundColor).opacity(0.5))
                )
        )
        .overlay(
            RoundedRectangle(cornerRadius: 12)
                .stroke(showWarning ? Color.red.opacity(0.5) : Color.clear, lineWidth: 1)
        )
    }
}

// Add this extension for consistent description text styling
extension Text {
    func settingsDescription() -> some View {
        self
            .font(.system(size: 13))
            .foregroundColor(.secondary)
            .fixedSize(horizontal: false, vertical: true)
    }
}

struct PushToTalkKeySelector: View {
    @Binding var selectedKey: HotkeyManager.PushToTalkKey
    
    var body: some View {
        HStack(spacing: 12) {
            ForEach(HotkeyManager.PushToTalkKey.allCases, id: \.self) { key in
                Button(action: {
                    withAnimation(.spring(response: 0.2, dampingFraction: 0.6)) {
                        selectedKey = key
                    }
                }) {
                    SelectableKeyCapView(
                        text: getKeySymbol(for: key),
                        subtext: getKeyText(for: key),
                        isSelected: selectedKey == key
                    )
                }
                .buttonStyle(.plain)
            }
        }
    }
    
    private func getKeySymbol(for key: HotkeyManager.PushToTalkKey) -> String {
        switch key {
        case .rightOption: return "‚å•"
        case .fn: return "Fn"
        case .rightCommand: return "‚åò"
        case .rightShift: return "‚áß"
        }
    }
    
    private func getKeyText(for key: HotkeyManager.PushToTalkKey) -> String {
        switch key {
        case .rightOption: return "Right Option"
        case .fn: return "Function"
        case .rightCommand: return "Right Command"
        case .rightShift: return "Right Shift"
        }
    }
}

struct SelectableKeyCapView: View {
    let text: String
    let subtext: String
    let isSelected: Bool
    
    @Environment(\.colorScheme) private var colorScheme
    
    private var keyColor: Color {
        if isSelected {
            return colorScheme == .dark ? Color.accentColor.opacity(0.3) : Color.accentColor.opacity(0.2)
        }
        return colorScheme == .dark ? Color(white: 0.2) : .white
    }
    
    var body: some View {
        VStack(spacing: 4) {
            Text(text)
                .font(.system(size: 20, weight: .semibold, design: .rounded))
                .foregroundColor(colorScheme == .dark ? .white : .black)
                .frame(width: 44, height: 44)
                .background(
                    ZStack {
                        RoundedRectangle(cornerRadius: 8)
                            .fill(keyColor)
                        
                        // Highlight overlay
                        if isSelected {
                            RoundedRectangle(cornerRadius: 8)
                                .strokeBorder(Color.accentColor, lineWidth: 2)
                        }
                        
                        // Key surface highlight
                        RoundedRectangle(cornerRadius: 8)
                            .fill(
                                LinearGradient(
                                    gradient: Gradient(colors: [
                                        Color.white.opacity(colorScheme == .dark ? 0.1 : 0.4),
                                        Color.white.opacity(0)
                                    ]),
                                    startPoint: .top,
                                    endPoint: .bottom
                                )
                            )
                    }
                )
                .shadow(
                    color: Color.black.opacity(colorScheme == .dark ? 0.5 : 0.2),
                    radius: 2,
                    x: 0,
                    y: 1
                )
            
            Text(subtext)
                .font(.system(size: 11))
                .foregroundColor(.secondary)
        }
    }
}

================
File: VoiceInk/Views/AboutView.swift
================
import SwiftUI
import AppKit

struct AboutView: View {
    @Environment(\.colorScheme) private var colorScheme
    let appVersion = Bundle.main.infoDictionary?["CFBundleShortVersionString"] as? String ?? "Unknown"
    
    var body: some View {
        GeometryReader { geometry in
            ScrollView {
                VStack {
                    Spacer()
                    CardView {
                        VStack(spacing: 30) {
                            appLogo
                            appDescription
                            featuresSection
                            contactInfo
                        }
                        .padding()
                    }
                    .frame(width: min(geometry.size.width * 0.9, 600))
                    .frame(minHeight: min(geometry.size.height * 0.9, 800))
                    Spacer()
                }
                .frame(minWidth: geometry.size.width, minHeight: geometry.size.height)
            }
            .padding()  // Add padding here
        }
    }
    
    private var appLogo: some View {
        Group {
            if let image = NSImage(named: "AppIcon") {
                Image(nsImage: image)
                    .resizable()
                    .aspectRatio(contentMode: .fit)
                    .frame(width: 128, height: 128)
                    .cornerRadius(16)
                    .shadow(radius: 5)
            } else {
                Image(systemName: "questionmark.app.dashed")
                    .resizable()
                    .aspectRatio(contentMode: .fit)
                    .frame(width: 128, height: 128)
                    .foregroundColor(.secondary)
            }
        }
        .accessibilityLabel("VoiceInk App Icon")
    }
    
    private var appDescription: some View {
        VStack(spacing: 10) {
            Text("VoiceInk")
                .font(.system(size: 36, weight: .bold, design: .rounded))
                .foregroundColor(.primary)
            
            Text("Version \(appVersion)")
                .font(.subheadline)
                .foregroundColor(.secondary)
            
            Text("VoiceInk is a powerful voice-to-text application that leverages local whisper AI models to provide accurate and efficient transcription in real-time.")
                .font(.body)
                .multilineTextAlignment(.center)
                .padding()
                .frame(maxWidth: 600)
        }
    }
    
    private var featuresSection: some View {
        VStack(alignment: .leading, spacing: 15) {
            Text("Key Features")
                .font(.headline)
                .padding(.bottom, 5)
            
            FeatureRow(icon: "waveform", text: "Real-time transcription")
            FeatureRow(icon: "globe", text: "Support for multiple languages")
            FeatureRow(icon: "keyboard", text: "Global hotkey for quick access")
            FeatureRow(icon: "chart.bar", text: "VoiceInk insights and metrics")
            FeatureRow(icon: "lock.shield", text: "Privacy-focused with local processing")
        }
        .padding()
        .background(RoundedRectangle(cornerRadius: 10).fill(Color(.controlBackgroundColor)))
        .shadow(color: Color.black.opacity(0.1), radius: 5, x: 0, y: 2)
    }
    
    private var contactInfo: some View {
        VStack(spacing: 15) {
            Text("Contact Us")
                .font(.headline)
            
            Button(action: {
                if let url = URL(string: "mailto:prakashjoshipax@gmail.com?subject=VoiceInk%20Help%20%26%20Support") {
                    NSWorkspace.shared.open(url)
                }
            }) {
                Text("prakashjoshipax@gmail.com")
                    .underline()
                    .foregroundColor(.blue)
            }
            .buttonStyle(PlainButtonStyle())
            
            Text("¬© 2025 VoiceInk. All rights reserved.")
                .font(.caption)
                .foregroundColor(.secondary)
        }
        .padding()
        .background(RoundedRectangle(cornerRadius: 10).fill(Color(.controlBackgroundColor)))
        .shadow(color: Color.black.opacity(0.1), radius: 5, x: 0, y: 2)
    }
}

struct FeatureRow: View {
    let icon: String
    let text: String
    
    var body: some View {
        HStack(spacing: 15) {
            Image(systemName: icon)
                .foregroundColor(.blue)
                .frame(width: 24, height: 24)
            Text(text)
                .font(.body)
        }
    }
}

struct CardView<Content: View>: View {
    let content: Content
    
    init(@ViewBuilder content: () -> Content) {
        self.content = content()
    }
    
    var body: some View {
        content
            .background(Color(.controlBackgroundColor))
            .cornerRadius(20)
            .shadow(color: Color.black.opacity(0.2), radius: 10, x: 0, y: 5)
    }
}

struct AboutView_Previews: PreviewProvider {
    static var previews: some View {
        AboutView()
    }
}

================
File: VoiceInk/Views/APIKeyManagementView.swift
================
import SwiftUI

struct APIKeyManagementView: View {
    @EnvironmentObject private var aiService: AIService
    @State private var apiKey: String = ""
    @State private var showAlert = false
    @State private var alertMessage = ""
    @State private var isVerifying = false
    @State private var ollamaBaseURL: String = UserDefaults.standard.string(forKey: "ollamaBaseURL") ?? "http://localhost:11434"
    @State private var ollamaModels: [OllamaService.OllamaModel] = []
    @State private var selectedOllamaModel: String = UserDefaults.standard.string(forKey: "ollamaSelectedModel") ?? "mistral"
    @State private var isCheckingOllama = false
    @State private var isEditingURL = false
    
    var body: some View {
        VStack(alignment: .leading, spacing: 16) {
            // Header Section
            HStack {
                VStack(alignment: .leading, spacing: 4) {
                    Text("Enhance your transcriptions with AI")
                        .font(.headline)
                        .foregroundColor(.secondary)
                }
                
                Spacer()
                
                if aiService.isAPIKeyValid && aiService.selectedProvider != .ollama {
                    HStack(spacing: 6) {
                        Circle()
                            .fill(Color.green)
                            .frame(width: 8, height: 8)
                        Text("Connected to")
                            .font(.caption)
                        Text(aiService.selectedProvider.rawValue)
                            .font(.caption.bold())
                    }
                    .padding(.horizontal, 8)
                    .padding(.vertical, 4)
                    .background(Color.secondary.opacity(0.1))
                    .foregroundColor(.secondary)
                    .cornerRadius(6)
                }
            }
            
            // Provider Selection
            Picker("AI Provider", selection: $aiService.selectedProvider) {
                ForEach(AIProvider.allCases, id: \.self) { provider in
                    Text(provider.rawValue).tag(provider)
                }
            }
            
            .onChange(of: aiService.selectedProvider) { _ in
                if aiService.selectedProvider == .ollama {
                    checkOllamaConnection()
                }
            }
            
            if aiService.selectedProvider == .ollama {
                // Ollama Configuration
                VStack(alignment: .leading, spacing: 16) {
                    // Header
                    HStack {
                        Label("Ollama Configuration", systemImage: "server.rack")
                            .font(.headline)
                        
                        Spacer()
                        
                        // Connection Status Indicator
                        HStack(spacing: 6) {
                            Circle()
                                .fill(isCheckingOllama ? Color.orange : (ollamaModels.isEmpty ? Color.red : Color.green))
                                .frame(width: 8, height: 8)
                            Text(isCheckingOllama ? "Checking..." : (ollamaModels.isEmpty ? "Disconnected" : "Connected"))
                                .font(.caption)
                        .foregroundColor(.secondary)
                        }
                        .padding(.horizontal, 8)
                        .padding(.vertical, 4)
                        .background(Color.secondary.opacity(0.1))
                        .cornerRadius(6)
                    }
                    
                    // Base URL Configuration
                    VStack(alignment: .leading, spacing: 8) {
                        Label("Server URL", systemImage: "link")
                            .font(.subheadline)
                            .foregroundColor(.secondary)
                        
                        HStack(spacing: 8) {
                            if isEditingURL {
                        TextField("Base URL", text: $ollamaBaseURL)
                            .textFieldStyle(RoundedBorderTextFieldStyle())
                                
                                Button(action: {
                                    aiService.updateOllamaBaseURL(ollamaBaseURL)
                                    checkOllamaConnection()
                                    isEditingURL = false
                                }) {
                                    Text("Save")
                                }
                                .buttonStyle(.bordered)
                                .controlSize(.small)
                            } else {
                                Text(ollamaBaseURL)
                                    .font(.system(.body, design: .monospaced))
                                    .foregroundColor(.primary)
                                
                                Spacer()
                                
                                Button(action: {
                                    isEditingURL = true
                                }) {
                                    Image(systemName: "pencil")
                                }
                                .buttonStyle(.borderless)
                                .controlSize(.small)
                                
                                Button(action: {
                                    ollamaBaseURL = "http://localhost:11434"
                                    aiService.updateOllamaBaseURL(ollamaBaseURL)
                                checkOllamaConnection()
                                }) {
                                    Image(systemName: "arrow.counterclockwise")
                                }
                                .buttonStyle(.borderless)
                                .foregroundColor(.secondary)
                                .controlSize(.small)
                            }
                        }
                    }
                    .padding(12)
                    .background(Color.secondary.opacity(0.05))
                    .cornerRadius(8)
                    
                    // Model Selection
                    VStack(alignment: .leading, spacing: 8) {
                        Label("Model Selection", systemImage: "cpu")
                            .font(.subheadline)
                            .foregroundColor(.secondary)
                        
                        if ollamaModels.isEmpty {
                            HStack(spacing: 8) {
                                Image(systemName: "exclamationmark.triangle.fill")
                                    .foregroundColor(.orange)
                            Text("No models available")
                                .foregroundColor(.secondary)
                                .italic()
                            }
                            .padding(12)
                            .frame(maxWidth: .infinity, alignment: .leading)
                            .background(Color.orange.opacity(0.1))
                            .cornerRadius(8)
                        } else {
                            ScrollView(.horizontal, showsIndicators: false) {
                                HStack(spacing: 12) {
                                ForEach(ollamaModels) { model in
                                        VStack(alignment: .leading, spacing: 6) {
                                            // Model Name and Status
                                            HStack {
                                                Text(model.name)
                                                    .font(.subheadline)
                                                    .bold()
                                                
                                                if model.name == selectedOllamaModel {
                                                    Image(systemName: "checkmark.circle.fill")
                                                        .foregroundColor(.green)
                                                }
                                            }
                                            
                                            // Model Details
                                            VStack(alignment: .leading, spacing: 4) {
                                                // Parameters
                                                HStack(spacing: 4) {
                                                    Image(systemName: "cpu.fill")
                                                        .font(.caption2)
                                                    Text(model.details.parameter_size)
                                                        .font(.caption2)
                                                }
                                                .foregroundColor(.secondary)
                                                
                                                // Size
                                                HStack(spacing: 4) {
                                                    Image(systemName: "externaldrive.fill")
                                                        .font(.caption2)
                                                    Text(formatSize(model.size))
                                                        .font(.caption2)
                                                }
                                                .foregroundColor(.secondary)
                                            }
                                        }
                                        .padding(12)
                                        .frame(minWidth: 140)
                                        .background(
                                            RoundedRectangle(cornerRadius: 8)
                                                .fill(model.name == selectedOllamaModel ? Color.accentColor.opacity(0.1) : Color.secondary.opacity(0.05))
                                                .overlay(
                                                    RoundedRectangle(cornerRadius: 8)
                                                        .stroke(model.name == selectedOllamaModel ? Color.accentColor : Color.clear, lineWidth: 1)
                                                )
                                        )
                                        .onTapGesture {
                                            selectedOllamaModel = model.name
                                            aiService.updateSelectedOllamaModel(model.name)
                                        }
                                    }
                                }
                                .padding(.horizontal, 4)  // Add padding for the first and last items
                                .padding(.vertical, 4)
                            }
                        }
                        
                        // Refresh Button
                        Button(action: {
                            checkOllamaConnection()
                        }) {
                            Label(isCheckingOllama ? "Refreshing..." : "Refresh Models", systemImage: isCheckingOllama ? "arrow.triangle.2.circlepath" : "arrow.clockwise")
                                .font(.caption)
                        }
                        .disabled(isCheckingOllama)
                    }
                    .padding(12)
                    .background(Color.secondary.opacity(0.05))
                    .cornerRadius(8)
                    
                    // Help Text
                    if ollamaModels.isEmpty {
                        VStack(alignment: .leading, spacing: 8) {
                            Text("Troubleshooting")
                                .font(.subheadline)
                                .bold()
                            
                            VStack(alignment: .leading, spacing: 4) {
                                bulletPoint("Ensure Ollama is installed and running")
                                bulletPoint("Check if the server URL is correct")
                                bulletPoint("Verify you have at least one model pulled")
                            }
                            
                            Button("Learn More") {
                                NSWorkspace.shared.open(URL(string: "https://ollama.ai/download")!)
                            }
                            .font(.caption)
                        }
                        .padding(12)
                        .frame(maxWidth: .infinity, alignment: .leading)
                        .background(Color.secondary.opacity(0.05))
                        .cornerRadius(8)
                    }
                    
                    // Ollama Information
                    DisclosureGroup {
                        VStack(alignment: .leading, spacing: 12) {
                            // Important Warning about Model Size
                            HStack(alignment: .top, spacing: 8) {
                                Image(systemName: "exclamationmark.triangle.fill")
                                    .frame(width: 20)
                                    .foregroundColor(.orange)
                                VStack(alignment: .leading, spacing: 2) {
                                    Text("Important: Model Selection")
                                        .font(.subheadline)
                                        .bold()
                                        .foregroundColor(.orange)
                                    Text("Smaller models (< 7B parameters) significantly impact transcription enhancement quality. For optimal results, use models with 14B+ parameters. Also reasoning models don't work with transcript enhancement. So avoid them.")
                                        .font(.caption)
                                        .foregroundColor(.secondary)
                                }
                            }
                            .padding(8)
                            .background(Color.orange.opacity(0.1))
                            .cornerRadius(6)

                            // Local Processing
                            HStack(alignment: .top) {
                                Image(systemName: "cpu")
                                    .frame(width: 20)
                                    .foregroundColor(.secondary)
                                VStack(alignment: .leading, spacing: 2) {
                                    Text("Local Processing")
                                        .font(.subheadline)
                                        .bold()
                                    Text("Ollama runs entirely on your system, processing all text locally without sending data to external servers.")
                                        .font(.caption)
                                        .foregroundColor(.secondary)
                                }
                            }
                            
                            // System Requirements
                            HStack(alignment: .top) {
                                Image(systemName: "memorychip")
                                    .frame(width: 20)
                                    .foregroundColor(.secondary)
                                VStack(alignment: .leading, spacing: 2) {
                                    Text("System Requirements")
                                        .font(.subheadline)
                                        .bold()
                                    Text("Local processing requires significant system resources. Larger, more capable models need more RAM (32GB+ recommended for optimal performance).")
                                        .font(.caption)
                                        .foregroundColor(.secondary)
                                }
                            }
                            
                            // Use Cases
                            HStack(alignment: .top) {
                                Image(systemName: "checkmark.shield")
                                    .frame(width: 20)
                                    .foregroundColor(.secondary)
                                VStack(alignment: .leading, spacing: 2) {
                                    Text("Best For")
                                        .font(.subheadline)
                                        .bold()
                                    Text("‚Ä¢ Privacy-focused users who need data to stay local\n‚Ä¢ Systems with powerful hardware\n‚Ä¢ Users who can prioritize quality over processing speed")
                                        .font(.caption)
                                        .foregroundColor(.secondary)
                                }
                            }
                            
                            // Recommendation Note
                            HStack(alignment: .top) {
                                Image(systemName: "lightbulb")
                                    .frame(width: 20)
                                    .foregroundColor(.secondary)
                                VStack(alignment: .leading, spacing: 2) {
                                    Text("Recommendation")
                                        .font(.subheadline)
                                        .bold()
                                    Text("For optimal transcription enhancement, either use cloud providers or ensure you're using a larger local model (14B+ parameters). Smaller models may produce poor or inconsistent results.")
                                .font(.caption)
                                .foregroundColor(.secondary)
                                }
                            }
                        }
                    } label: {
                        Label("Important Information About Local AI", systemImage: "info.circle.fill")
                            .font(.subheadline)
                            .foregroundColor(.secondary)
                    }
                    .padding(8)
                    .background(Color.secondary.opacity(0.05))
                    .cornerRadius(8)
                }
                .padding(16)
                .background(Color.secondary.opacity(0.03))
                .cornerRadius(12)
            } else if aiService.selectedProvider == .custom {
                VStack(alignment: .leading, spacing: 16) {
                    // Header
                    VStack(alignment: .leading, spacing: 4) {
                        Text("Custom Provider Configuration")
                            .font(.headline)
                        HStack(spacing: 4) {
                            Image(systemName: "exclamationmark.triangle.fill")
                                .foregroundColor(.orange)
                                .font(.caption)
                            Text("Requires OpenAI-compatible API endpoint")
                                .font(.caption)
                                .foregroundColor(.secondary)
                        }
                    }
                    
                    // Configuration Fields
                    VStack(alignment: .leading, spacing: 8) {
                        TextField("Base URL (e.g., https://api.example.com/v1/chat/completions)", text: $aiService.customBaseURL)
                            .textFieldStyle(.roundedBorder)
                        
                        TextField("Model Name (e.g., gpt-4o-mini, claude-3-5-sonnet-20240620)", text: $aiService.customModel)
                            .textFieldStyle(.roundedBorder)
                        
                        if aiService.isAPIKeyValid {
                            // Show masked API key when valid
                            Text("API Key")
                                .font(.subheadline)
                                .foregroundColor(.secondary)
                            
                            HStack {
                                Text(String(repeating: "‚Ä¢", count: 40))
                                    .font(.system(.body, design: .monospaced))
                                
                                Spacer()
                                
                                Button(action: {
                                    aiService.clearAPIKey()
                                }) {
                                    Label("Remove Key", systemImage: "trash")
                                        .foregroundColor(.red)
                                }
                                .buttonStyle(.borderless)
                            }
                        } else {
                            // Show API key input when not valid
                            Text("Enter your API Key")
                                .font(.subheadline)
                                .foregroundColor(.secondary)
                            
                            SecureField("API Key", text: $apiKey)
                                .textFieldStyle(.roundedBorder)
                                .font(.system(.body, design: .monospaced))
                            
                            HStack {
                                Button(action: {
                                    isVerifying = true
                                    aiService.saveAPIKey(apiKey) { success in
                                        isVerifying = false
                                        if !success {
                                            alertMessage = "Invalid API key. Please check and try again."
                                            showAlert = true
                                        }
                                        apiKey = ""
                                    }
                                }) {
                                    HStack {
                                        if isVerifying {
                                            ProgressView()
                                                .scaleEffect(0.5)
                                                .frame(width: 16, height: 16)
                                        } else {
                                            Image(systemName: "checkmark.circle.fill")
                                        }
                                        Text("Verify and Save")
                                    }
                                }
                                .disabled(aiService.customBaseURL.isEmpty || aiService.customModel.isEmpty || apiKey.isEmpty)
                                
                                Spacer()
                            }
                        }
                    }
                }
                .padding()
                .background(Color.secondary.opacity(0.03))
                .cornerRadius(12)
            } else if aiService.isAPIKeyValid {
                // API Key Display for other providers
                VStack(alignment: .leading, spacing: 8) {
                    Text("API Key")
                        .font(.subheadline)
                        .foregroundColor(.secondary)
                    
                    HStack {
                        Text(String(repeating: "‚Ä¢", count: 40))
                            .font(.system(.body, design: .monospaced))
                        
                        Spacer()
                        
                        Button(action: {
                            aiService.clearAPIKey()
                        }) {
                            Label("Remove Key", systemImage: "trash")
                                .foregroundColor(.red)
                        }
                        .buttonStyle(.borderless)
                    }
                }
            } else {
                // API Key Input for other providers
                VStack(alignment: .leading, spacing: 8) {
                    Text("Enter your API Key")
                        .font(.subheadline)
                        .foregroundColor(.secondary)
                    
                    SecureField("API Key", text: $apiKey)
                        .textFieldStyle(RoundedBorderTextFieldStyle())
                        .font(.system(.body, design: .monospaced))
                    
                    HStack {
                        Button(action: {
                            isVerifying = true
                            aiService.saveAPIKey(apiKey) { success in
                                isVerifying = false
                                if !success {
                                    alertMessage = "Invalid API key. Please check and try again."
                                    showAlert = true
                                }
                                apiKey = ""
                            }
                        }) {
                            HStack {
                                if isVerifying {
                                    ProgressView()
                                        .scaleEffect(0.5)
                                        .frame(width: 16, height: 16)
                                } else {
                                    Image(systemName: "checkmark.circle.fill")
                                }
                                Text("Verify and Save")
                            }
                        }
                        
                        Spacer()
                        
                        HStack(spacing: 8) {
                            Text(aiService.selectedProvider == .groq || aiService.selectedProvider == .gemini ? "Free" : "Paid")
                                .font(.caption2)
                                .foregroundColor(.secondary)
                                .padding(.horizontal, 6)
                                .padding(.vertical, 2)
                                .background(Color.secondary.opacity(0.1))
                                .cornerRadius(4)
                            
                            if aiService.selectedProvider != .ollama && aiService.selectedProvider != .custom {
                                Button {
                                    let url = switch aiService.selectedProvider {
                                    case .groq:
                                        URL(string: "https://console.groq.com/keys")!
                                    case .openAI:
                                        URL(string: "https://platform.openai.com/api-keys")!
                                    case .deepSeek:
                                        URL(string: "https://platform.deepseek.com/api-keys")!
                                    case .gemini:
                                        URL(string: "https://makersuite.google.com/app/apikey")!
                                    case .anthropic:
                                        URL(string: "https://console.anthropic.com/settings/keys")!
                                    case .ollama, .custom:
                                        URL(string: "")! // This case should never be reached
                                    
                                    }
                                    NSWorkspace.shared.open(url)
                                } label: {
                                    HStack(spacing: 4) {
                                        Text("Get API Key")
                                            .foregroundColor(.accentColor)
                                        Image(systemName: "arrow.up.right")
                                            .font(.caption)
                                            .foregroundColor(.accentColor)
                                    }
                                }
                                .buttonStyle(.plain)
                            }
                        }
                    }
                }
            }
        }
        .padding()
        .alert("Error", isPresented: $showAlert) {
            Button("OK", role: .cancel) { }
        } message: {
            Text(alertMessage)
        }
        .onAppear {
            if aiService.selectedProvider == .ollama {
                checkOllamaConnection()
            }
        }
    }
    
    private func checkOllamaConnection() {
        isCheckingOllama = true
        aiService.checkOllamaConnection { connected in
            if connected {
                Task {
                    ollamaModels = await aiService.fetchOllamaModels()
                    isCheckingOllama = false
                }
            } else {
                ollamaModels = []
                isCheckingOllama = false
                alertMessage = "Could not connect to Ollama. Please check if Ollama is running and the base URL is correct."
                showAlert = true
            }
        }
    }
    
    private func bulletPoint(_ text: String) -> some View {
        HStack(alignment: .top, spacing: 4) {
            Text("‚Ä¢")
            Text(text)
        }
    }
    
    private func formatSize(_ bytes: Int64) -> String {
        let gigabytes = Double(bytes) / 1_000_000_000
        return String(format: "%.1f GB", gigabytes)
    }
}

#Preview {
    APIKeyManagementView()
        .environmentObject(AIService())
}

================
File: VoiceInk/Views/AudioPlayerView.swift
================
import SwiftUI
import AVFoundation

class WaveformGenerator {
    static func generateWaveformSamples(from url: URL, sampleCount: Int = 200) async -> [Float] {
        guard let audioFile = try? AVAudioFile(forReading: url) else { return [] }
        let format = audioFile.processingFormat
        let frameCount = UInt32(audioFile.length)
        let stride = max(1, Int(frameCount) / sampleCount)
        let bufferSize = min(UInt32(4096), frameCount)
        
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: bufferSize) else { return [] }
        
        do {
            var maxValues = [Float](repeating: 0.0, count: sampleCount)
            var sampleIndex = 0
            var framePosition: AVAudioFramePosition = 0
            
            while sampleIndex < sampleCount && framePosition < AVAudioFramePosition(frameCount) {
                audioFile.framePosition = framePosition
                try audioFile.read(into: buffer)
                
                if let channelData = buffer.floatChannelData?[0], buffer.frameLength > 0 {
                    maxValues[sampleIndex] = abs(channelData[0])
                    sampleIndex += 1
                }
                
                framePosition += AVAudioFramePosition(stride)
            }
            
            if let maxSample = maxValues.max(), maxSample > 0 {
                return maxValues.map { $0 / maxSample }
            }
            return maxValues
        } catch {
            print("Error reading audio file: \(error)")
            return []
        }
    }
}

class AudioPlayerManager: ObservableObject {
    private var audioPlayer: AVAudioPlayer?
    private var timer: Timer?
    @Published var isPlaying = false
    @Published var currentTime: TimeInterval = 0
    @Published var duration: TimeInterval = 0
    @Published var waveformSamples: [Float] = []
    @Published var isLoadingWaveform = false
    
    func loadAudio(from url: URL) {
        do {
            audioPlayer = try AVAudioPlayer(contentsOf: url)
            audioPlayer?.prepareToPlay()
            duration = audioPlayer?.duration ?? 0
            isLoadingWaveform = true
            
            Task {
                let samples = await WaveformGenerator.generateWaveformSamples(from: url)
                await MainActor.run {
                    self.waveformSamples = samples
                    self.isLoadingWaveform = false
                }
            }
        } catch {
            print("Error loading audio: \(error.localizedDescription)")
        }
    }
    
    func play() {
        audioPlayer?.play()
        isPlaying = true
        startTimer()
    }
    
    func pause() {
        audioPlayer?.pause()
        isPlaying = false
        stopTimer()
    }
    
    func seek(to time: TimeInterval) {
        audioPlayer?.currentTime = time
        currentTime = time
    }
    
    private func startTimer() {
        timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            guard let self = self else { return }
            self.currentTime = self.audioPlayer?.currentTime ?? 0
            if self.currentTime >= self.duration {
                self.pause()
                self.seek(to: 0)
            }
        }
    }
    
    private func stopTimer() {
        timer?.invalidate()
        timer = nil
    }
    
    deinit {
        stopTimer()
    }
}

struct WaveformView: View {
    let samples: [Float]
    let currentTime: TimeInterval
    let duration: TimeInterval
    let isLoading: Bool
    var onSeek: (Double) -> Void
    @State private var isHovering = false
    @State private var hoverLocation: CGFloat = 0
    
    var body: some View {
        GeometryReader { geometry in
            ZStack(alignment: .leading) {
                if isLoading {
                    VStack {
                        ProgressView()
                            .controlSize(.small)
                        Text("Generating waveform...")
                            .font(.system(size: 12))
                            .foregroundColor(.secondary)
                    }
                    .frame(maxWidth: .infinity, maxHeight: .infinity)
                } else {
                    HStack(spacing: 1) {
                        ForEach(0..<samples.count, id: \.self) { index in
                            WaveformBar(
                                sample: samples[index],
                                isPlayed: CGFloat(index) / CGFloat(samples.count) <= CGFloat(currentTime / duration),
                                totalBars: samples.count,
                                geometryWidth: geometry.size.width,
                                isHovering: isHovering,
                                hoverProgress: hoverLocation / geometry.size.width
                            )
                        }
                    }
                    .frame(maxHeight: .infinity)
                    .padding(.horizontal, 2)
                    
                    if isHovering {
                        Text(formatTime(duration * Double(hoverLocation / geometry.size.width)))
                            .font(.system(size: 12, weight: .medium))
                            .monospacedDigit()
                            .foregroundColor(.white)
                            .padding(.horizontal, 8)
                            .padding(.vertical, 4)
                            .background(Capsule().fill(Color.accentColor))
                            .offset(x: max(0, min(hoverLocation - 30, geometry.size.width - 60)))
                            .offset(y: -30)
                        
                        Rectangle()
                            .fill(Color.accentColor)
                            .frame(width: 2)
                            .frame(maxHeight: .infinity)
                            .offset(x: hoverLocation)
                    }
                }
            }
            .contentShape(Rectangle())
            .gesture(
                DragGesture(minimumDistance: 0)
                    .onChanged { value in
                        if !isLoading {
                            hoverLocation = value.location.x
                            onSeek(Double(value.location.x / geometry.size.width) * duration)
                        }
                    }
            )
            .onHover { hovering in
                if !isLoading {
                    withAnimation(.easeInOut(duration: 0.2)) {
                        isHovering = hovering
                    }
                }
            }
            .onContinuousHover { phase in
                if !isLoading {
                    if case .active(let location) = phase {
                        hoverLocation = location.x
                    }
                }
            }
        }
        .frame(height: 56)
    }
    
    private func formatTime(_ time: TimeInterval) -> String {
        let minutes = Int(time) / 60
        let seconds = Int(time) % 60
        return String(format: "%d:%02d", minutes, seconds)
    }
}

struct WaveformBar: View {
    let sample: Float
    let isPlayed: Bool
    let totalBars: Int
    let geometryWidth: CGFloat
    let isHovering: Bool
    let hoverProgress: CGFloat
    
    private var isNearHover: Bool {
        let barPosition = geometryWidth / CGFloat(totalBars)
        let hoverPosition = hoverProgress * geometryWidth
        return abs(barPosition - hoverPosition) < 20
    }
    
    var body: some View {
        Capsule()
            .fill(
                LinearGradient(
                    colors: [
                        isPlayed ? Color.accentColor : Color.accentColor.opacity(0.3),
                        isPlayed ? Color.accentColor.opacity(0.8) : Color.accentColor.opacity(0.2)
                    ],
                    startPoint: .bottom,
                    endPoint: .top
                )
            )
            .frame(
                width: max((geometryWidth / CGFloat(totalBars)) - 1, 1),
                height: max(CGFloat(sample) * 40, 3)
            )
            .scaleEffect(y: isHovering && isNearHover ? 1.2 : 1.0)
            .animation(.interpolatingSpring(stiffness: 300, damping: 15), value: isHovering && isNearHover)
    }
}

struct AudioPlayerView: View {
    let url: URL
    @StateObject private var playerManager = AudioPlayerManager()
    @State private var isHovering = false
    @State private var isRetranscribing = false
    @State private var showRetranscribeSuccess = false
    @State private var showRetranscribeError = false
    @State private var errorMessage = ""
    @EnvironmentObject private var whisperState: WhisperState
    @Environment(\.modelContext) private var modelContext
    
    private var transcriptionService: AudioTranscriptionService {
        AudioTranscriptionService(modelContext: modelContext, whisperState: whisperState)
    }
    
    var body: some View {
        VStack(spacing: 16) {
            HStack {
                HStack(spacing: 6) {
                    Image(systemName: "waveform")
                        .foregroundStyle(Color.accentColor)
                    Text("Recording")
                        .font(.system(size: 14, weight: .medium))
                }
                .foregroundColor(.secondary)
                
                Spacer()
                
                Text(formatTime(playerManager.duration))
                    .font(.system(size: 14, weight: .medium))
                    .monospacedDigit()
                    .foregroundColor(.secondary)
            }
            
            VStack(spacing: 16) {
                WaveformView(
                    samples: playerManager.waveformSamples,
                    currentTime: playerManager.currentTime,
                    duration: playerManager.duration,
                    isLoading: playerManager.isLoadingWaveform,
                    onSeek: { playerManager.seek(to: $0) }
                )
                
                HStack(spacing: 20) {
                    Button(action: {
                        if playerManager.isPlaying {
                            playerManager.pause()
                        } else {
                            playerManager.play()
                        }
                    }) {
                        Circle()
                            .fill(Color.accentColor.opacity(0.1))
                            .frame(width: 44, height: 44)
                            .overlay(
                                Image(systemName: playerManager.isPlaying ? "pause.fill" : "play.fill")
                                    .font(.system(size: 18, weight: .semibold))
                                    .foregroundStyle(Color.accentColor)
                                    .contentTransition(.symbolEffect(.replace.downUp))
                            )
                    }
                    .buttonStyle(.plain)
                    .scaleEffect(isHovering ? 1.05 : 1.0)
                    .onHover { hovering in
                        withAnimation(.spring(response: 0.3, dampingFraction: 0.7)) {
                            isHovering = hovering
                        }
                    }
                    
                    Button(action: retranscribeAudio) {
                        Circle()
                            .fill(Color.green.opacity(0.1))
                            .frame(width: 44, height: 44)
                            .overlay(
                                Group {
                                    if isRetranscribing {
                                        ProgressView()
                                            .controlSize(.small)
                                    } else if showRetranscribeSuccess {
                                        Image(systemName: "checkmark")
                                            .font(.system(size: 18, weight: .semibold))
                                            .foregroundStyle(Color.green)
                                    } else {
                                        Image(systemName: "arrow.clockwise")
                                            .font(.system(size: 18, weight: .semibold))
                                            .foregroundStyle(Color.green)
                                    }
                                }
                            )
                    }
                    .buttonStyle(.plain)
                    .disabled(isRetranscribing)
                    .help("Retranscribe this audio")
                    
                    Text(formatTime(playerManager.currentTime))
                        .font(.system(size: 14, weight: .medium))
                        .monospacedDigit()
                        .foregroundColor(.secondary)
                }
            }
        }
        .padding(.vertical, 12)
        .padding(.horizontal, 16)
        .onAppear {
            playerManager.loadAudio(from: url)
        }
        .overlay(
            VStack {
                if showRetranscribeSuccess {
                    HStack(spacing: 8) {
                        Image(systemName: "checkmark.circle.fill")
                            .foregroundColor(.green)
                        Text("Retranscription successful")
                            .font(.system(size: 14, weight: .medium))
                    }
                    .padding(.horizontal, 16)
                    .padding(.vertical, 10)
                    .background(
                        RoundedRectangle(cornerRadius: 8)
                            .fill(Color.green.opacity(0.1))
                            .stroke(Color.green.opacity(0.2), lineWidth: 1)
                    )
                    .transition(.move(edge: .top).combined(with: .opacity))
                }
                
                if showRetranscribeError {
                    HStack(spacing: 8) {
                        Image(systemName: "exclamationmark.circle.fill")
                            .foregroundColor(.red)
                        Text(errorMessage.isEmpty ? "Retranscription failed" : errorMessage)
                            .font(.system(size: 14, weight: .medium))
                    }
                    .padding(.horizontal, 16)
                    .padding(.vertical, 10)
                    .background(
                        RoundedRectangle(cornerRadius: 8)
                            .fill(Color.red.opacity(0.1))
                            .stroke(Color.red.opacity(0.2), lineWidth: 1)
                    )
                    .transition(.move(edge: .top).combined(with: .opacity))
                }
                
                Spacer()
            }
            .padding(.top, 16)
            .animation(.spring(response: 0.3, dampingFraction: 0.7), value: showRetranscribeSuccess)
            .animation(.spring(response: 0.3, dampingFraction: 0.7), value: showRetranscribeError)
        )
    }
    
    private func formatTime(_ time: TimeInterval) -> String {
        let minutes = Int(time) / 60
        let seconds = Int(time) % 60
        return String(format: "%d:%02d", minutes, seconds)
    }
    
    private func retranscribeAudio() {
        guard let currentModel = whisperState.currentModel else {
            errorMessage = "No transcription model selected"
            showRetranscribeError = true
            DispatchQueue.main.asyncAfter(deadline: .now() + 3) {
                withAnimation { showRetranscribeError = false }
            }
            return
        }
        
        isRetranscribing = true
        
        Task {
            do {
                let _ = try await transcriptionService.retranscribeAudio(from: url, using: currentModel)
                await MainActor.run {
                    isRetranscribing = false
                    showRetranscribeSuccess = true
                    DispatchQueue.main.asyncAfter(deadline: .now() + 3) {
                        withAnimation { showRetranscribeSuccess = false }
                    }
                }
            } catch {
                await MainActor.run {
                    isRetranscribing = false
                    errorMessage = error.localizedDescription
                    showRetranscribeError = true
                    DispatchQueue.main.asyncAfter(deadline: .now() + 3) {
                        withAnimation { showRetranscribeError = false }
                    }
                }
            }
        }
    }
}

================
File: VoiceInk/Views/AudioTranscribeView.swift
================
import SwiftUI
import SwiftData
import UniformTypeIdentifiers
import AVFoundation

struct AudioTranscribeView: View {
    @Environment(\.modelContext) private var modelContext
    @EnvironmentObject private var whisperState: WhisperState
    @StateObject private var transcriptionManager = AudioTranscriptionManager.shared
    @State private var isDropTargeted = false
    @State private var selectedAudioURL: URL?
    @State private var isAudioFileSelected = false
    @State private var isEnhancementEnabled = false
    @State private var selectedPromptId: UUID?
    
    var body: some View {
        VStack(spacing: 0) {
            if transcriptionManager.isProcessing {
                processingView
            } else {
                dropZoneView
            }
            
            Divider()
                .padding(.vertical)
            
            // Show current transcription result
            if let transcription = transcriptionManager.currentTranscription {
                ScrollView {
                    VStack(alignment: .leading, spacing: 16) {
                        Text("Transcription Result")
                            .font(.headline)
                        
                        if let enhancedText = transcription.enhancedText {
                            VStack(alignment: .leading, spacing: 8) {
                                Text("Enhanced")
                                    .font(.subheadline)
                                    .foregroundColor(.secondary)
                                Text(enhancedText)
                                    .textSelection(.enabled)
                            }
                            
                            Divider()
                            
                            VStack(alignment: .leading, spacing: 8) {
                                Text("Original")
                                    .font(.subheadline)
                                    .foregroundColor(.secondary)
                                Text(transcription.text)
                                    .textSelection(.enabled)
                            }
                        } else {
                            Text(transcription.text)
                                .textSelection(.enabled)
                        }
                        
                        HStack {
                            Text("Duration: \(formatDuration(transcription.duration))")
                                .font(.caption)
                                .foregroundColor(.secondary)
                            Spacer()
                        }
                    }
                    .padding()
                }
            }
        }
        .alert("Error", isPresented: .constant(transcriptionManager.errorMessage != nil)) {
            Button("OK", role: .cancel) {
                transcriptionManager.errorMessage = nil
            }
        } message: {
            if let errorMessage = transcriptionManager.errorMessage {
                Text(errorMessage)
            }
        }
    }
    
    private var dropZoneView: some View {
        VStack(spacing: 16) {
            if isAudioFileSelected {
                VStack(spacing: 16) {
                    Text("Audio file selected: \(selectedAudioURL?.lastPathComponent ?? "")")
                        .font(.headline)
                    
                    // AI Enhancement Settings
                    if let enhancementService = whisperState.getEnhancementService() {
                        VStack(spacing: 16) {
                            // AI Enhancement and Prompt in the same row
                            HStack(spacing: 16) {
                                Toggle("AI Enhancement", isOn: $isEnhancementEnabled)
                                    .toggleStyle(.switch)
                                    .onChange(of: isEnhancementEnabled) { newValue in
                                        enhancementService.isEnhancementEnabled = newValue
                                    }
                                
                                if isEnhancementEnabled {
                                    Divider()
                                        .frame(height: 20)
                                    
                                    // Prompt Selection
                                    HStack(spacing: 8) {
                                        Text("Prompt:")
                                            .font(.subheadline)
                                        
                                        Menu {
                                            ForEach(enhancementService.allPrompts) { prompt in
                                                Button {
                                                    enhancementService.setActivePrompt(prompt)
                                                    selectedPromptId = prompt.id
                                                } label: {
                                                    HStack {
                                                        Image(systemName: prompt.icon.rawValue)
                                                            .foregroundColor(.accentColor)
                                                        Text(prompt.title)
                                                        if selectedPromptId == prompt.id {
                                                            Spacer()
                                                            Image(systemName: "checkmark")
                                                        }
                                                    }
                                                }
                                            }
                                        } label: {
                                            HStack {
                                                Text(enhancementService.allPrompts.first(where: { $0.id == selectedPromptId })?.title ?? "Select Prompt")
                                                    .foregroundColor(.primary)
                                                Image(systemName: "chevron.down")
                                                    .font(.caption)
                                            }
                                            .padding(.horizontal, 8)
                                            .padding(.vertical, 4)
                                            .background(
                                                RoundedRectangle(cornerRadius: 6)
                                                    .fill(Color(.controlBackgroundColor))
                                            )
                                        }
                                        .fixedSize()
                                        .disabled(!isEnhancementEnabled)
                                    }
                                }
                            }
                            .padding(.horizontal, 12)
                            .padding(.vertical, 8)
                            .background(
                                RoundedRectangle(cornerRadius: 8)
                                    .fill(Color(.windowBackgroundColor).opacity(0.4))
                            )
                        }
                        .frame(maxWidth: .infinity, alignment: .center)
                        .onAppear {
                            // Initialize local state from enhancement service
                            isEnhancementEnabled = enhancementService.isEnhancementEnabled
                            selectedPromptId = enhancementService.selectedPromptId
                        }
                    }
                    
                    // Action Buttons in a row
                    HStack(spacing: 12) {
                        Button("Start Transcription") {
                            if let url = selectedAudioURL {
                                transcriptionManager.startProcessing(
                                    url: url,
                                    modelContext: modelContext,
                                    whisperState: whisperState
                                )
                            }
                        }
                        .buttonStyle(.borderedProminent)
                        
                        Button("Choose Different File") {
                            selectedAudioURL = nil
                            isAudioFileSelected = false
                        }
                        .buttonStyle(.bordered)
                    }
                }
                .padding()
            } else {
                ZStack {
                    RoundedRectangle(cornerRadius: 12)
                        .fill(Color(.windowBackgroundColor).opacity(0.4))
                        .overlay(
                            RoundedRectangle(cornerRadius: 12)
                                .strokeBorder(
                                    style: StrokeStyle(
                                        lineWidth: 2,
                                        dash: [8]
                                    )
                                )
                                .foregroundColor(isDropTargeted ? .blue : .gray.opacity(0.5))
                        )
                    
                    VStack(spacing: 16) {
                        Image(systemName: "arrow.down.doc")
                            .font(.system(size: 32))
                            .foregroundColor(isDropTargeted ? .blue : .gray)
                        
                        Text("Drop audio file here")
                            .font(.headline)
                        
                        Text("or")
                            .foregroundColor(.secondary)
                        
                        Button("Choose File") {
                            selectFile()
                        }
                        .buttonStyle(.bordered)
                    }
                    .padding(32)
                }
                .frame(height: 200)
                .padding(.horizontal)
            }
            
            Text("Supported formats: WAV, MP3, M4A, AIFF")
                .font(.caption)
                .foregroundColor(.secondary)
        }
        .padding()
        .onDrop(of: [.audio, .fileURL], isTargeted: $isDropTargeted) { providers in
            Task {
                await handleDroppedFile(providers)
            }
            return true
        }
    }
    
    private var processingView: some View {
        VStack(spacing: 16) {
            ProgressView()
                .scaleEffect(0.8)
            Text(transcriptionManager.processingPhase.message)
                .font(.headline)
            Text(transcriptionManager.messageLog)
                .font(.caption)
                .foregroundColor(.secondary)
                .multilineTextAlignment(.center)
        }
        .padding()
    }
    
    private func selectFile() {
        let panel = NSOpenPanel()
        panel.allowsMultipleSelection = false
        panel.canChooseDirectories = false
        panel.canChooseFiles = true
        panel.allowedContentTypes = [
            .audio,
            .wav,
            .mp3,
            .mpeg4Audio,
            .aiff
        ]
        
        if panel.runModal() == .OK {
            if let url = panel.url {
                selectedAudioURL = url
                isAudioFileSelected = true
            }
        }
    }
    
    private func handleDroppedFile(_ providers: [NSItemProvider]) async {
        guard let provider = providers.first else { return }
        
        if provider.hasItemConformingToTypeIdentifier(UTType.audio.identifier) {
            try? await provider.loadItem(forTypeIdentifier: UTType.audio.identifier) { item, error in
                if let url = item as? URL {
                    Task { @MainActor in
                        selectedAudioURL = url
                        isAudioFileSelected = true
                    }
                }
            }
        }
    }
    
    private func formatDuration(_ duration: TimeInterval) -> String {
        let minutes = Int(duration) / 60
        let seconds = Int(duration) % 60
        return String(format: "%d:%02d", minutes, seconds)
    }
}

================
File: VoiceInk/Views/ContentView.swift
================
import SwiftUI
import SwiftData
import KeyboardShortcuts

// ViewType enum with all cases
enum ViewType: String, CaseIterable {
    case metrics = "Dashboard"
    case record = "Record Audio"
    case transcribeAudio = "Transcribe Audio"
    case history = "History"
    case models = "AI Models"
    case enhancement = "Enhancement"
    case powerMode = "Power Mode"
    case permissions = "Permissions"
    case audioInput = "Audio Input"
    case dictionary = "Dictionary"
    case license = "VoiceInk Pro"
    case settings = "Settings"
    case about = "About"
    
    var icon: String {
        switch self {
        case .metrics: return "gauge.medium"
        case .record: return "mic.circle.fill"
        case .transcribeAudio: return "waveform.circle.fill"
        case .history: return "doc.text.fill"
        case .models: return "brain.head.profile"
        case .enhancement: return "wand.and.stars"
        case .powerMode: return "sparkles.square.fill.on.square"
        case .permissions: return "shield.fill"
        case .audioInput: return "mic.fill"
        case .dictionary: return "character.book.closed.fill"
        case .license: return "checkmark.seal.fill"
        case .settings: return "gearshape.fill"
        case .about: return "info.circle.fill"
        }
    }
}

struct VisualEffectView: NSViewRepresentable {
    let material: NSVisualEffectView.Material
    let blendingMode: NSVisualEffectView.BlendingMode
    
    func makeNSView(context: Context) -> NSVisualEffectView {
        let visualEffectView = NSVisualEffectView()
        visualEffectView.material = material
        visualEffectView.blendingMode = blendingMode
        visualEffectView.state = .active
        return visualEffectView
    }
    
    func updateNSView(_ visualEffectView: NSVisualEffectView, context: Context) {
        visualEffectView.material = material
        visualEffectView.blendingMode = blendingMode
    }
}

struct DynamicSidebar: View {
    @Binding var selectedView: ViewType
    @Binding var hoveredView: ViewType?
    @Environment(\.colorScheme) private var colorScheme
    @StateObject private var licenseViewModel = LicenseViewModel()
    @Namespace private var buttonAnimation

    var body: some View {
        VStack(spacing: 15) {
            // App Header
            HStack(spacing: 6) {
                if let appIcon = NSImage(named: "AppIcon") {
                    Image(nsImage: appIcon)
                        .resizable()
                        .aspectRatio(contentMode: .fit)
                        .frame(width: 28, height: 28)
                        .cornerRadius(8)
                }
                
                Text("VoiceInk")
                    .font(.system(size: 14, weight: .semibold))
                
                if case .licensed = licenseViewModel.licenseState {
                    Text("PRO")
                        .font(.system(size: 9, weight: .heavy))
                        .foregroundStyle(.white)
                        .padding(.horizontal, 4)
                        .padding(.vertical, 2)
                        .background(Color.blue)
                        .cornerRadius(4)
                }
                
                Spacer()
            }
            .padding(.horizontal, 16)
            .padding(.vertical, 12)
            
            // Navigation Items
            ForEach(ViewType.allCases, id: \.self) { viewType in
                DynamicSidebarButton(
                    title: viewType.rawValue,
                    systemImage: viewType.icon,
                    isSelected: selectedView == viewType,
                    isHovered: hoveredView == viewType,
                    namespace: buttonAnimation
                ) {
                    selectedView = viewType
                }
                .onHover { isHovered in
                    hoveredView = isHovered ? viewType : nil
                }
            }
            
            Spacer()
        }
        .frame(maxWidth: .infinity, maxHeight: .infinity)
    }
}

struct DynamicSidebarButton: View {
    let title: String
    let systemImage: String
    let isSelected: Bool
    let isHovered: Bool
    let namespace: Namespace.ID
    let action: () -> Void
    
    @Environment(\.colorScheme) private var colorScheme

    var body: some View {
        Button(action: action) {
            HStack(spacing: 12) {
                Image(systemName: systemImage)
                    .font(.system(size: 18, weight: .medium))
                    .frame(width: 24, height: 24)
                
                Text(title)
                    .font(.system(size: 14, weight: .medium))
                    .lineLimit(1)
                Spacer()
            }
            .foregroundColor(isSelected ? .white : (isHovered ? .accentColor : .primary))
            .frame(height: 40)
            .frame(maxWidth: .infinity, alignment: .leading)
            .padding(.leading, 16)
            .background(
                ZStack {
                    if isSelected {
                        RoundedRectangle(cornerRadius: 12)
                            .fill(Color.accentColor)
                            .shadow(color: Color.accentColor.opacity(0.5), radius: 5, x: 0, y: 2)
                    } else if isHovered {
                        RoundedRectangle(cornerRadius: 12)
                            .fill(colorScheme == .dark ? Color.white.opacity(0.1) : Color.black.opacity(0.05))
                    }
                }
            )
            .padding(.horizontal, 8)
        }
        .buttonStyle(PlainButtonStyle())
    }
}

struct ContentView: View {
    @Environment(\.modelContext) private var modelContext
    @Environment(\.colorScheme) private var colorScheme
    @EnvironmentObject private var whisperState: WhisperState
    @EnvironmentObject private var hotkeyManager: HotkeyManager
    @State private var selectedView: ViewType = .metrics
    @State private var hoveredView: ViewType?
    @State private var hasLoadedData = false
    let appVersion = Bundle.main.infoDictionary?["CFBundleShortVersionString"] as? String ?? "1.0.0"
    @StateObject private var licenseViewModel = LicenseViewModel()
    
    private var isSetupComplete: Bool {
        hasLoadedData &&
        whisperState.currentModel != nil &&
        KeyboardShortcuts.getShortcut(for: .toggleMiniRecorder) != nil &&
        AXIsProcessTrusted() &&
        CGPreflightScreenCaptureAccess()
    }

    var body: some View {
        NavigationSplitView {
            DynamicSidebar(
                selectedView: $selectedView,
                hoveredView: $hoveredView
            )
            .frame(width: 200)
            .navigationSplitViewColumnWidth(200)
        } detail: {
            detailView
                .frame(maxWidth: .infinity, maxHeight: .infinity)
                .toolbar(.hidden, for: .automatic)
                .navigationTitle("")
        }
        .navigationSplitViewStyle(.balanced)
        .frame(minWidth: 1100, minHeight: 750)
       .background(Color(.controlBackgroundColor))
        .onAppear {
            hasLoadedData = true
        }
        .onReceive(NotificationCenter.default.publisher(for: .navigateToDestination)) { notification in
            print("ContentView: Received navigation notification")
            if let destination = notification.userInfo?["destination"] as? String {
                print("ContentView: Destination received: \(destination)")
                switch destination {
                case "Settings":
                    print("ContentView: Navigating to Settings")
                    selectedView = .settings
                case "AI Models":
                    print("ContentView: Navigating to AI Models")
                    selectedView = .models
                case "VoiceInk Pro":
                    print("ContentView: Navigating to VoiceInk Pro")
                    selectedView = .license
                case "History":
                    print("ContentView: Navigating to History")
                    selectedView = .history
                case "Permissions":
                    print("ContentView: Navigating to Permissions")
                    selectedView = .permissions
                case "Enhancement":
                    print("ContentView: Navigating to Enhancement")
                    selectedView = .enhancement
                default:
                    print("ContentView: No matching destination found for: \(destination)")
                    break
                }
            } else {
                print("ContentView: No destination in notification")
            }
        }
    }
    
    @ViewBuilder
    private var detailView: some View {
        switch selectedView {
        case .metrics:
            if isSetupComplete {
                MetricsView(skipSetupCheck: true)
            } else {
                MetricsSetupView()
            }
        case .models:
            ModelManagementView(whisperState: whisperState)
        case .enhancement:
            EnhancementSettingsView()
        case .record:
            RecordView()
        case .transcribeAudio:
            AudioTranscribeView()
        case .history:
            TranscriptionHistoryView()
        case .audioInput:
            AudioInputSettingsView()
        case .dictionary:
            DictionarySettingsView(whisperPrompt: whisperState.whisperPrompt)
        case .powerMode:
            PowerModeView()
        case .settings:
            SettingsView()
                .environmentObject(whisperState)
        case .about:
            AboutView()
        case .license:
            LicenseManagementView()
        case .permissions:
            PermissionsView()
        }
    }
}

================
File: VoiceInk/Views/EnhancementSettingsView.swift
================
import SwiftUI

extension CustomPrompt {
    func promptIcon(isSelected: Bool, onTap: @escaping () -> Void, onEdit: ((CustomPrompt) -> Void)? = nil, onDelete: ((CustomPrompt) -> Void)? = nil) -> some View {
        VStack(spacing: 8) {
            ZStack {
                // Dynamic background with blur effect
                RoundedRectangle(cornerRadius: 14)
                    .fill(
                        LinearGradient(
                            gradient: isSelected ?
                                Gradient(colors: [
                                    Color.accentColor.opacity(0.9),
                                    Color.accentColor.opacity(0.7)
                                ]) :
                                Gradient(colors: [
                                    Color(NSColor.controlBackgroundColor).opacity(0.95),
                                    Color(NSColor.controlBackgroundColor).opacity(0.85)
                                ]),
                            startPoint: .topLeading,
                            endPoint: .bottomTrailing
                        )
                    )
                    .overlay(
                        RoundedRectangle(cornerRadius: 14)
                            .stroke(
                                LinearGradient(
                                    gradient: Gradient(colors: [
                                        isSelected ?
                                            Color.white.opacity(0.3) : Color.white.opacity(0.15),
                                        isSelected ?
                                            Color.white.opacity(0.1) : Color.white.opacity(0.05)
                                    ]),
                                    startPoint: .topLeading,
                                    endPoint: .bottomTrailing
                                ),
                                lineWidth: 1
                            )
                    )
                    .shadow(
                        color: isSelected ?
                            Color.accentColor.opacity(0.4) : Color.black.opacity(0.1),
                        radius: isSelected ? 10 : 6,
                        x: 0,
                        y: 3
                    )
                
                // Decorative background elements
                Circle()
                    .fill(
                        RadialGradient(
                            gradient: Gradient(colors: [
                                isSelected ?
                                    Color.white.opacity(0.15) : Color.white.opacity(0.08),
                                Color.clear
                            ]),
                            center: .center,
                            startRadius: 1,
                            endRadius: 25
                        )
                    )
                    .frame(width: 50, height: 50)
                    .offset(x: -15, y: -15)
                    .blur(radius: 2)
                
                // Icon with enhanced effects
                Image(systemName: icon.rawValue)
                    .font(.system(size: 20, weight: .medium))
                    .foregroundStyle(
                        LinearGradient(
                            colors: isSelected ?
                                [Color.white, Color.white.opacity(0.9)] :
                                [Color.primary.opacity(0.9), Color.primary.opacity(0.7)],
                            startPoint: .topLeading,
                            endPoint: .bottomTrailing
                        )
                    )
                    .shadow(
                        color: isSelected ?
                            Color.white.opacity(0.5) : Color.clear,
                        radius: 4
                    )
                    .shadow(
                        color: isSelected ?
                            Color.accentColor.opacity(0.5) : Color.clear,
                        radius: 3
                    )
            }
            .frame(width: 48, height: 48)
            
            // Enhanced title styling
            Text(title)
                .font(.system(size: 11, weight: .medium))
                .foregroundColor(isSelected ?
                    .primary : .secondary)
                .lineLimit(1)
                .frame(maxWidth: 70)
        }
        .padding(.horizontal, 4)
        .padding(.vertical, 6)
        .contentShape(Rectangle())
        .scaleEffect(isSelected ? 1.05 : 1.0)
        .onTapGesture(perform: onTap)
        .contextMenu {
            if !isPredefined && (onEdit != nil || onDelete != nil) {
                if let onEdit = onEdit {
                    Button {
                        onEdit(self)
                    } label: {
                        Label("Edit", systemImage: "pencil")
                    }
                }
                
                if let onDelete = onDelete {
                    Button(role: .destructive) {
                        onDelete(self)
                    } label: {
                        Label("Delete", systemImage: "trash")
                    }
                }
            }
        }
    }
}

struct EnhancementSettingsView: View {
    @EnvironmentObject private var enhancementService: AIEnhancementService
    @State private var isEditingPrompt = false
    @State private var isSettingsExpanded = true
    @State private var selectedPromptForEdit: CustomPrompt?
    @State private var isEditingTriggerWord = false
    @State private var tempTriggerWord = ""
    
    var body: some View {
        ScrollView {
            VStack(spacing: 32) {
                // Video CTA Section
                VideoCTAView(
                    url: "https://dub.sh/promptmode",
                    subtitle: "Learn how to use AI enhancement modes"
                )
                
                // Main Settings Sections
                VStack(spacing: 24) {
                    // Enable/Disable Toggle Section
                    VStack(alignment: .leading, spacing: 12) {
                        HStack {
                            VStack(alignment: .leading, spacing: 4) {
                                Text("Enable Enhancement")
                                    .font(.headline)
                                Text("Turn on AI-powered enhancement features")
                                    .font(.caption)
                                    .foregroundColor(.secondary)
                            }
                            
                            Spacer()
                            
                            Toggle("", isOn: $enhancementService.isEnhancementEnabled)
                                .toggleStyle(SwitchToggleStyle(tint: .blue))
                                .labelsHidden()
                                .scaleEffect(1.2)
                        }
                        
                        HStack(spacing: 20) {
                            VStack(alignment: .leading, spacing: 4) {
                                Toggle("Clipboard Context", isOn: $enhancementService.useClipboardContext)
                                    .toggleStyle(.switch)
                                    .disabled(!enhancementService.isEnhancementEnabled)
                                Text("Use text from clipboard to understand the context")
                                    .font(.caption)
                                    .foregroundColor(enhancementService.isEnhancementEnabled ? .secondary : .secondary.opacity(0.5))
                            }
                            
                            VStack(alignment: .leading, spacing: 4) {
                                Toggle("Screen Capture", isOn: $enhancementService.useScreenCaptureContext)
                                    .toggleStyle(.switch)
                                    .disabled(!enhancementService.isEnhancementEnabled)
                                Text("Learn what is on the screen to understand the context")
                                    .font(.caption)
                                    .foregroundColor(enhancementService.isEnhancementEnabled ? .secondary : .secondary.opacity(0.5))
                            }
                        }
                    }
                    .padding()
                    .background(
                        RoundedRectangle(cornerRadius: 10)
                            .fill(Color(.windowBackgroundColor).opacity(0.4))
                            .overlay(
                                RoundedRectangle(cornerRadius: 10)
                                    .stroke(Color.blue.opacity(0.2), lineWidth: 1)
                            )
                    )
                    
                    // 1. AI Provider Integration Section
                    VStack(alignment: .leading, spacing: 16) {
                        Text("AI Provider Integration")
                            .font(.headline)
                        
                        APIKeyManagementView()
                            .background(Color(.windowBackgroundColor).opacity(0.4))
                            .cornerRadius(10)
                    }
                    .padding()
                    .background(Color(.windowBackgroundColor).opacity(0.4))
                    .cornerRadius(10)
                    
                    // 3. Enhancement Modes & Assistant Section
                    VStack(alignment: .leading, spacing: 16) {
                        Text("Enhancement Modes & Assistant")
                            .font(.headline)
                        
                        // Modes Section
                        VStack(alignment: .leading, spacing: 12) {
                            HStack {
                                Text("Enhancement Modes")
                                    .font(.subheadline)
                                    .foregroundColor(.primary)
                                Spacer()
                                Button(action: { isEditingPrompt = true }) {
                                    Image(systemName: "plus.circle.fill")
                                        .symbolRenderingMode(.hierarchical)
                                        .font(.system(size: 26, weight: .medium))
                                        .foregroundStyle(Color.accentColor)
                                }
                                .buttonStyle(.plain)
                                .contentShape(Circle())
                                .help("Add new mode")
                            }
                            
                            if enhancementService.allPrompts.isEmpty {
                                Text("No modes available")
                                    .foregroundColor(.secondary)
                                    .font(.caption)
                            } else {
                                let columns = [
                                    GridItem(.adaptive(minimum: 80, maximum: 100), spacing: 36)
                                ]
                                
                                LazyVGrid(columns: columns, spacing: 24) {
                                    ForEach(enhancementService.allPrompts) { prompt in
                                        prompt.promptIcon(
                                            isSelected: enhancementService.selectedPromptId == prompt.id,
                                            onTap: { withAnimation(.spring(response: 0.3, dampingFraction: 0.7)) {
                                                enhancementService.setActivePrompt(prompt)
                                            }},
                                            onEdit: { selectedPromptForEdit = $0 },
                                            onDelete: { enhancementService.deletePrompt($0) }
                                        )
                                    }
                                }
                                .padding(.vertical, 12)
                                .padding(.horizontal, 16)
                            }
                        }
                        
                        Divider()
                        
                        // Assistant Mode Section
                        VStack(alignment: .leading, spacing: 12) {
                            HStack {
                                Text("Assistant Mode")
                                    .font(.subheadline)
                                Image(systemName: "sparkles")
                                    .foregroundColor(.accentColor)
                            }
                            
                            Text("Configure how to trigger the AI assistant mode")
                                .font(.caption)
                                .foregroundColor(.secondary)
                            
                            VStack(alignment: .leading, spacing: 12) {
                                HStack {
                                    Text("Current Trigger:")
                                        .font(.subheadline)
                                    Text("\"\(enhancementService.assistantTriggerWord)\"")
                                        .font(.system(.subheadline, design: .monospaced))
                                        .foregroundColor(.accentColor)
                                }
                                
                                if isEditingTriggerWord {
                                    VStack(alignment: .leading, spacing: 8) {
                                        HStack {
                                            TextField("New trigger word", text: $tempTriggerWord)
                                                .textFieldStyle(.roundedBorder)
                                                .frame(maxWidth: 200)
                                            
                                            Button("Save") {
                                                enhancementService.assistantTriggerWord = tempTriggerWord
                                                isEditingTriggerWord = false
                                            }
                                            .buttonStyle(.borderedProminent)
                                            .disabled(tempTriggerWord.isEmpty)
                                            
                                            Button("Cancel") {
                                                isEditingTriggerWord = false
                                                tempTriggerWord = enhancementService.assistantTriggerWord
                                            }
                                            .buttonStyle(.bordered)
                                        }
                                        
                                        Text("Default: \"hey\"")
                                            .font(.caption)
                                            .foregroundColor(.secondary)
                                    }
                                } else {
                                    Button("Change Trigger Word") {
                                        tempTriggerWord = enhancementService.assistantTriggerWord
                                        isEditingTriggerWord = true
                                    }
                                    .buttonStyle(.bordered)
                                }
                            }
                            
                            Text("Start with \"\(enhancementService.assistantTriggerWord), \" to use AI assistant mode")
                                .font(.caption)
                                .foregroundColor(.secondary)
                            Text("Instead of enhancing the text, VoiceInk will respond like a conversational AI assistant")
                                .font(.caption)
                                .foregroundColor(.secondary)
                        }
                    }
                    .padding()
                    .background(Color(.windowBackgroundColor).opacity(0.4))
                    .cornerRadius(10)
                }
            }
            .padding(24)
        }
        .frame(minWidth: 600, minHeight: 500)
        .background(Color(NSColor.controlBackgroundColor))
        .sheet(isPresented: $isEditingPrompt) {
            PromptEditorView(mode: .add)
        }
        .sheet(item: $selectedPromptForEdit) { prompt in
            PromptEditorView(mode: .edit(prompt))
        }
    }
}

================
File: VoiceInk/Views/KeyboardShortcutView.swift
================
import SwiftUI
import KeyboardShortcuts

struct KeyboardShortcutView: View {
    let shortcut: KeyboardShortcuts.Shortcut?
    @Environment(\.colorScheme) private var colorScheme
    
    var body: some View {
        if let shortcut = shortcut {
            HStack(spacing: 6) {
                ForEach(shortcutComponents(from: shortcut), id: \.self) { component in
                    KeyCapView(text: component)
                }
            }
        } else {
            KeyCapView(text: "Not Set")
                .foregroundColor(.secondary)
        }
    }
    
    private func shortcutComponents(from shortcut: KeyboardShortcuts.Shortcut) -> [String] {
        var components: [String] = []
        
        // Add modifiers
        if shortcut.modifiers.contains(.command) { components.append("‚åò") }
        if shortcut.modifiers.contains(.option) { components.append("‚å•") }
        if shortcut.modifiers.contains(.shift) { components.append("‚áß") }
        if shortcut.modifiers.contains(.control) { components.append("‚åÉ") }
        
        // Add key
        if let key = shortcut.key {
            components.append(keyToString(key))
        }
        
        return components
    }
    
    private func keyToString(_ key: KeyboardShortcuts.Key) -> String {
        switch key {
        case .space: return "Space"
        case .return: return "‚Ü©"
        case .escape: return "‚éã"
        case .tab: return "‚á•"
        case .delete: return "‚å´"
        case .home: return "‚Üñ"
        case .end: return "‚Üò"
        case .pageUp: return "‚áû"
        case .pageDown: return "‚áü"
        case .upArrow: return "‚Üë"
        case .downArrow: return "‚Üì"
        case .leftArrow: return "‚Üê"
        case .rightArrow: return "‚Üí"
        case .period: return "."
        case .comma: return ","
        case .semicolon: return ";"
        case .quote: return "'"
        case .slash: return "/"
        case .backslash: return "\\"
        case .minus: return "-"
        case .equal: return "="
        case .keypad0: return "0"
        case .keypad1: return "1"
        case .keypad2: return "2"
        case .keypad3: return "3"
        case .keypad4: return "4"
        case .keypad5: return "5"
        case .keypad6: return "6"
        case .keypad7: return "7"
        case .keypad8: return "8"
        case .keypad9: return "9"
        case .a: return "A"
        case .b: return "B"
        case .c: return "C"
        case .d: return "D"
        case .e: return "E"
        case .f: return "F"
        case .g: return "G"
        case .h: return "H"
        case .i: return "I"
        case .j: return "J"
        case .k: return "K"
        case .l: return "L"
        case .m: return "M"
        case .n: return "N"
        case .o: return "O"
        case .p: return "P"
        case .q: return "Q"
        case .r: return "R"
        case .s: return "S"
        case .t: return "T"
        case .u: return "U"
        case .v: return "V"
        case .w: return "W"
        case .x: return "X"
        case .y: return "Y"
        case .z: return "Z"
        case .zero: return "0"
        case .one: return "1"
        case .two: return "2"
        case .three: return "3"
        case .four: return "4"
        case .five: return "5"
        case .six: return "6"
        case .seven: return "7"
        case .eight: return "8"
        case .nine: return "9"
        default:
              return String(key.rawValue).uppercased()
        }
    }
}

struct KeyCapView: View {
    let text: String
    @Environment(\.colorScheme) private var colorScheme
    @State private var isPressed = false
    
    private var keyColor: Color {
        colorScheme == .dark ? Color(white: 0.2) : .white
    }
    
    private var surfaceGradient: LinearGradient {
        LinearGradient(
            colors: [
                keyColor,
                keyColor.opacity(0.2)
            ],
            startPoint: .topLeading,
            endPoint: .bottomTrailing
        )
    }
    
    private var highlightGradient: LinearGradient {
        LinearGradient(
            colors: [
                .white.opacity(colorScheme == .dark ? 0.15 : 0.5),
                .white.opacity(0.0)
            ],
            startPoint: .topLeading,
            endPoint: .center
        )
    }
    
    private var shadowColor: Color {
        colorScheme == .dark ? .black : .gray
    }
    
    var body: some View {
        Text(text)
            .font(.system(size: 25, weight: .semibold, design: .rounded))
            .foregroundColor(colorScheme == .dark ? .white : .black)
            .padding(.horizontal, 12)
            .padding(.vertical, 8)
            .background(
                ZStack {
                    // Main key surface
                    RoundedRectangle(cornerRadius: 8)
                        .fill(surfaceGradient)
                        .overlay(
                            RoundedRectangle(cornerRadius: 8)
                                .fill(highlightGradient)
                        )
                    
                    // Border
                    RoundedRectangle(cornerRadius: 8)
                        .strokeBorder(
                            LinearGradient(
                                colors: [
                                    .white.opacity(colorScheme == .dark ? 0.2 : 0.6),
                                    shadowColor.opacity(0.3)
                                ],
                                startPoint: .topLeading,
                                endPoint: .bottomTrailing
                            ),
                            lineWidth: 1
                        )
                }
            )
            // Main shadow
            .shadow(
                color: shadowColor.opacity(0.3),
                radius: 3,
                x: 0,
                y: 2
            )
            // Bottom edge shadow
            .overlay(
                RoundedRectangle(cornerRadius: 8)
                    .fill(
                        LinearGradient(
                            colors: [
                                shadowColor.opacity(0.0),
                                shadowColor.opacity(0.9)
                            ],
                            startPoint: .top,
                            endPoint: .bottom
                        )
                    )
                    .offset(y: 1)
                    .blur(radius: 2)
                    .mask(
                        RoundedRectangle(cornerRadius: 8)
                            .fill(
                                LinearGradient(
                                    colors: [.clear, .black],
                                    startPoint: .top,
                                    endPoint: .bottom
                                )
                            )
                    )
                    .clipped()
            )
            // Inner shadow effect
            .overlay(
                RoundedRectangle(cornerRadius: 8)
                    .stroke(
                        Color.white.opacity(colorScheme == .dark ? 0.1 : 0.3),
                        lineWidth: 1
                    )
                    .blur(radius: 1)
                    .offset(x: -1, y: -1)
                    .mask(RoundedRectangle(cornerRadius: 8))
            )
            .scaleEffect(isPressed ? 0.95 : 1.0)
            .animation(.spring(response: 0.2, dampingFraction: 0.6), value: isPressed)
            .onTapGesture {
                withAnimation {
                    isPressed = true
                    DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) {
                        isPressed = false
                    }
                }
            }
    }
}

#Preview {
    VStack(spacing: 20) {
        KeyboardShortcutView(shortcut: KeyboardShortcuts.getShortcut(for: .toggleMiniRecorder))
        KeyboardShortcutView(shortcut: nil)
    }
    .padding()
}

================
File: VoiceInk/Views/LanguageSelectionView.swift
================
import SwiftUI

// Define a display mode for flexible usage
enum LanguageDisplayMode {
    case full      // For settings page with descriptions
    case menuItem  // For menu bar with compact layout
}

struct LanguageSelectionView: View {
    @ObservedObject var whisperState: WhisperState
    @AppStorage("SelectedLanguage") private var selectedLanguage: String = "en"
    // Add display mode parameter with full as the default
    var displayMode: LanguageDisplayMode = .full
    
    let languages = [
        "auto": "Auto-detect",
        "af": "Afrikaans",
        "am": "Amharic",
        "ar": "Arabic",
        "as": "Assamese",
        "az": "Azerbaijani",
        "ba": "Bashkir",
        "be": "Belarusian",
        "bg": "Bulgarian",
        "bn": "Bengali",
        "bo": "Tibetan",
        "br": "Breton",
        "bs": "Bosnian",
        "ca": "Catalan",
        "cs": "Czech",
        "cy": "Welsh",
        "da": "Danish",
        "de": "German",
        "el": "Greek",
        "en": "English",
        "es": "Spanish",
        "et": "Estonian",
        "eu": "Basque",
        "fa": "Persian",
        "fi": "Finnish",
        "fo": "Faroese",
        "fr": "French",
        "ga": "Irish",
        "gl": "Galician",
        "gu": "Gujarati",
        "ha": "Hausa",
        "he": "Hebrew",
        "hi": "Hindi",
        "hr": "Croatian",
        "ht": "Haitian Creole",
        "hu": "Hungarian",
        "hy": "Armenian",
        "id": "Indonesian",
        "is": "Icelandic",
        "it": "Italian",
        "ja": "Japanese",
        "jw": "Javanese",
        "ka": "Georgian",
        "kk": "Kazakh",
        "km": "Khmer",
        "kn": "Kannada",
        "ko": "Korean",
        "la": "Latin",
        "lb": "Luxembourgish",
        "ln": "Lingala",
        "lo": "Lao",
        "lt": "Lithuanian",
        "lv": "Latvian",
        "mg": "Malagasy",
        "mi": "Maori",
        "mk": "Macedonian",
        "ml": "Malayalam",
        "mn": "Mongolian",
        "mr": "Marathi",
        "ms": "Malay",
        "mt": "Maltese",
        "my": "Myanmar",
        "ne": "Nepali",
        "nl": "Dutch",
        "nn": "Norwegian Nynorsk",
        "no": "Norwegian",
        "oc": "Occitan",
        "pa": "Punjabi",
        "pl": "Polish",
        "ps": "Pashto",
        "pt": "Portuguese",
        "ro": "Romanian",
        "ru": "Russian",
        "sa": "Sanskrit",
        "sd": "Sindhi",
        "si": "Sinhala",
        "sk": "Slovak",
        "sl": "Slovenian",
        "sn": "Shona",
        "so": "Somali",
        "sq": "Albanian",
        "sr": "Serbian",
        "su": "Sundanese",
        "sv": "Swedish",
        "sw": "Swahili",
        "ta": "Tamil",
        "te": "Telugu",
        "tg": "Tajik",
        "th": "Thai",
        "tk": "Turkmen",
        "tl": "Tagalog",
        "tr": "Turkish",
        "tt": "Tatar",
        "ug": "Uyghur",
        "uk": "Ukrainian",
        "ur": "Urdu",
        "uz": "Uzbek",
        "vi": "Vietnamese",
        "yi": "Yiddish",
        "yo": "Yoruba",
        "zh": "Chinese"
    ]
    
    private func updateLanguage(_ language: String) {
        // Update UI state - the UserDefaults updating is now automatic with @AppStorage
        selectedLanguage = language
    }
    
    // Function to check if current model is multilingual
    private func isMultilingualModel() -> Bool {
        guard let currentModel = whisperState.currentModel,
               let predefinedModel = PredefinedModels.models.first(where: { $0.name == currentModel.name }) else {
            return false
        }
        return predefinedModel.language == "Multilingual"
    }
    
    // Get the display name of the current language
    private func currentLanguageDisplayName() -> String {
        return languages[selectedLanguage] ?? "Unknown"
    }
    
    var body: some View {
        switch displayMode {
        case .full:
            fullView
        case .menuItem:
            menuItemView
        }
    }
    
    // The original full view layout for settings page
    private var fullView: some View {
        VStack(alignment: .leading, spacing: 16) {
            Text("Transcription Language")
                .font(.headline)
            
            if let currentModel = whisperState.currentModel,
               let predefinedModel = PredefinedModels.models.first(where: { $0.name == currentModel.name }) {
                
                if predefinedModel.language == "Multilingual" {
                    VStack(alignment: .leading, spacing: 8) {
                        Picker("Select Language", selection: $selectedLanguage) {
                            ForEach(languages.sorted(by: { $0.value < $1.value }), id: \.key) { key, value in
                                Text(value).tag(key)
                            }
                        }
                        .pickerStyle(MenuPickerStyle())
                        .onChange(of: selectedLanguage) { newValue in
                            updateLanguage(newValue)
                        }
                        
                        Text("Current model: \(predefinedModel.displayName)")
                            .font(.caption)
                            .foregroundColor(.secondary)
                        
                        Text("This model supports multiple languages. You can choose auto-detect or select a specific language.")
                            .font(.caption)
                            .foregroundColor(.secondary)
                    }
                } else {
                    // For English-only models, force set language to English
                    VStack(alignment: .leading, spacing: 8) {
                        Text("Language: English")
                            .font(.subheadline)
                            .foregroundColor(.primary)
                        
                        Text("Current model: \(predefinedModel.displayName)")
                            .font(.caption)
                            .foregroundColor(.secondary)
                        
                        Text("This is an English-optimized model and only supports English transcription.")
                            .font(.caption)
                            .foregroundColor(.secondary)
                    }
                    .onAppear {
                        // Ensure English is set when viewing English-only model
                        updateLanguage("en")
                    }
                }
            } else {
                Text("No model selected")
                    .font(.subheadline)
                    .foregroundColor(.secondary)
            }
        }
        .padding()
        .frame(maxWidth: .infinity, alignment: .leading)
        .background(Color(NSColor.controlBackgroundColor))
        .cornerRadius(10)
    }
    
    // New compact view for menu bar
    private var menuItemView: some View {
        Group {
            if isMultilingualModel() {
                Menu {
                    ForEach(languages.sorted(by: { $0.value < $1.value }), id: \.key) { key, value in
                        Button {
                            updateLanguage(key)
                        } label: {
                            HStack {
                                Text(value)
                                if selectedLanguage == key {
                                    Image(systemName: "checkmark")
                                }
                            }
                        }
                    }
                } label: {
                    HStack {
                        Text("Language: \(currentLanguageDisplayName())")
                        Image(systemName: "chevron.up.chevron.down")
                            .font(.system(size: 10))
                    }
                }
            } else {
                // For English-only models
                Button {
                    // Do nothing, just showing info
                } label: {
                    Text("Language: English (only)")
                        .foregroundColor(.secondary)
                }
                .disabled(true)
                .onAppear {
                    // Ensure English is set for English-only models
                    updateLanguage("en")
                }
            }
        }
    }
}

================
File: VoiceInk/Views/LicenseManagementView.swift
================
import SwiftUI

struct LicenseManagementView: View {
    @StateObject private var licenseViewModel = LicenseViewModel()
    @Environment(\.colorScheme) private var colorScheme
    
    var body: some View {
        ScrollView {
            VStack(spacing: 0) {
                // Hero Section
                heroSection
                
                // Main Content
                VStack(spacing: 32) {
                    if case .licensed = licenseViewModel.licenseState {
                        activatedContent
                    } else {
                        purchaseContent
                    }
                }
                .padding(32)
            }
        }
        .background(Color(NSColor.controlBackgroundColor))
    }
    
    private var heroSection: some View {
        VStack(spacing: 24) {
            // App Icon
            if let appIcon = NSImage(named: "AppIcon") {
                Image(nsImage: appIcon)
                    .resizable()
                    .aspectRatio(contentMode: .fit)
                    .frame(width: 96, height: 96)
                    .cornerRadius(24)
                    .shadow(color: .black.opacity(0.1), radius: 20, x: 0, y: 10)
            }
            
            // Title Section
            VStack(spacing: 16) {
                HStack(spacing: 16) {
                    Image(systemName: "checkmark.seal.fill")
                        .font(.system(size: 32))
                        .foregroundStyle(.blue)
                    
                    Text(licenseViewModel.licenseState == .licensed ? "VoiceInk Pro" : "Upgrade to Pro")
                        .font(.system(size: 32, weight: .bold))
                }
                
                Text(licenseViewModel.licenseState == .licensed ? 
                     "Thank you for supporting VoiceInk" :
                     "Transform your voice into text with advanced features")
                    .font(.title3)
                    .foregroundStyle(.secondary)
                    .multilineTextAlignment(.center)
                
                if case .licensed = licenseViewModel.licenseState {
                    HStack(spacing: 40) {
                        Button {
                            if let url = URL(string: "https://github.com/Beingpax/VoiceInk/releases") {
                                NSWorkspace.shared.open(url)
                            }
                        } label: {
                            featureItem(icon: "list.bullet.clipboard.fill", title: "Changelog", color: .blue)
                        }
                        .buttonStyle(.plain)
                        
                        Button {
                            if let url = URL(string: "https://discord.gg/xryDy57nYD") {
                                NSWorkspace.shared.open(url)
                            }
                        } label: {
                            featureItem(icon: "bubble.left.and.bubble.right.fill", title: "Discord", color: .purple)
                        }
                        .buttonStyle(.plain)
                        
                        Button {
                            if let url = URL(string: "mailto:prakashjoshipax@gmail.com") {
                                NSWorkspace.shared.open(url)
                            }
                        } label: {
                            featureItem(icon: "envelope.fill", title: "Email Support", color: .orange)
                        }
                        .buttonStyle(.plain)
                        
                        Button {
                            if let url = URL(string: "https://github.com/Beingpax/VoiceInk/issues") {
                                NSWorkspace.shared.open(url)
                            }
                        } label: {
                            featureItem(icon: "map.fill", title: "Roadmap", color: .green)
                        }
                        .buttonStyle(.plain)
                    }
                    .padding(.top, 8)
                }
            }
        }
        .padding(.vertical, 60)
    }
    
    private var purchaseContent: some View {
        VStack(spacing: 40) {
            // Purchase Card
            VStack(spacing: 24) {
                // Lifetime Access Badge
                HStack {
                    Image(systemName: "infinity.circle.fill")
                        .font(.system(size: 20))
                        .foregroundStyle(.blue)
                    Text("Buy Once, Own Forever")
                        .font(.headline)
                }
                .padding(.vertical, 8)
                .padding(.horizontal, 16)
                .background(Color.blue.opacity(0.1))
                .cornerRadius(12)
                
                // Purchase Button 
                Button(action: {
                    if let url = URL(string: "https://tryvoiceink.com/buy") {
                        NSWorkspace.shared.open(url)
                    }
                }) {
                    Text("Upgrade to VoiceInk Pro")
                        .font(.headline)
                        .frame(maxWidth: .infinity)
                        .padding(.vertical, 12)
                }
                .buttonStyle(.borderedProminent)
                
                // Features Grid
                HStack(spacing: 40) {
                    featureItem(icon: "bubble.left.and.bubble.right.fill", title: "Priority Support", color: .purple)
                    featureItem(icon: "infinity.circle.fill", title: "Lifetime Access", color: .blue)
                    featureItem(icon: "arrow.up.circle.fill", title: "Free Updates", color: .green)
                    featureItem(icon: "macbook.and.iphone", title: "All Devices", color: .orange)
                }
                .frame(maxWidth: .infinity, alignment: .center)
            }
            .padding(32)
            .background(Color(.windowBackgroundColor).opacity(0.4))
            .cornerRadius(16)
            .shadow(color: .black.opacity(0.05), radius: 10)

            // License Activation
            VStack(spacing: 20) {
                Text("Already have a license?")
                    .font(.headline)
                
                HStack(spacing: 12) {
                    TextField("Enter your license key", text: $licenseViewModel.licenseKey)
                        .textFieldStyle(.roundedBorder)
                        .font(.system(.body, design: .monospaced))
                        .textCase(.uppercase)
                    
                    Button(action: {
                        Task { await licenseViewModel.validateLicense() }
                    }) {
                        if licenseViewModel.isValidating {
                            ProgressView()
                                .controlSize(.small)
                        } else {
                            Text("Activate")
                                .frame(width: 80)
                        }
                    }
                    .buttonStyle(.borderedProminent)
                    .disabled(licenseViewModel.isValidating)
                }
                
                if let message = licenseViewModel.validationMessage {
                    Text(message)
                        .foregroundColor(.red)
                        .font(.callout)
                }
            }
            .padding(32)
            .background(Color(.windowBackgroundColor).opacity(0.4))
            .cornerRadius(16)
            .shadow(color: .black.opacity(0.05), radius: 10)
        }
    }
    
    private var activatedContent: some View {
        VStack(spacing: 32) {
            // Status Card
            VStack(spacing: 24) {
                HStack {
                    Image(systemName: "checkmark.circle.fill")
                        .font(.system(size: 24))
                        .foregroundStyle(.green)
                    Text("License Active")
                        .font(.headline)
                    Spacer()
                    Text("Active")
                        .font(.caption)
                        .padding(.horizontal, 12)
                        .padding(.vertical, 4)
                        .background(Capsule().fill(.green))
                        .foregroundStyle(.white)
                }
                
                Divider()
                
                if licenseViewModel.activationsLimit > 0 {
                    Text("This license can be activated on up to \(licenseViewModel.activationsLimit) devices")
                        .font(.subheadline)
                        .foregroundStyle(.secondary)
                } else {
                    Text("You can use VoiceInk Pro on all your personal devices")
                        .font(.subheadline)
                        .foregroundStyle(.secondary)
                }
            }
            .padding(32)
            .background(Color(.windowBackgroundColor).opacity(0.4))
            .cornerRadius(16)
            .shadow(color: .black.opacity(0.05), radius: 10)
            
            // Deactivation Card
            VStack(alignment: .leading, spacing: 16) {
                Text("License Management")
                    .font(.headline)
                
                Button(role: .destructive, action: {
                    licenseViewModel.removeLicense()
                }) {
                    Label("Deactivate License", systemImage: "xmark.circle.fill")
                        .frame(maxWidth: .infinity)
                        .padding(.vertical, 8)
                }
                .buttonStyle(.bordered)
            }
            .padding(32)
            .background(Color(.windowBackgroundColor).opacity(0.4))
            .cornerRadius(16)
            .shadow(color: .black.opacity(0.05), radius: 10)
        }
    }
    
    private func featureItem(icon: String, title: String, color: Color) -> some View {
        HStack(spacing: 8) {
            Image(systemName: icon)
                .font(.system(size: 16, weight: .medium))
                .foregroundStyle(color)
            
            Text(title)
                .font(.system(size: 13, weight: .medium))
                .foregroundStyle(.primary)
        }
    }
}

================
File: VoiceInk/Views/LicenseView.swift
================
import SwiftUI

struct LicenseView: View {
    @StateObject private var licenseViewModel = LicenseViewModel()
    
    var body: some View {
        VStack(spacing: 15) {
            Text("License Management")
                .font(.headline)
            
            if case .licensed = licenseViewModel.licenseState {
                VStack(spacing: 10) {
                    Text("Premium Features Activated")
                        .foregroundColor(.green)
                    
                    Button(role: .destructive, action: {
                        licenseViewModel.removeLicense()
                    }) {
                        Text("Remove License")
                    }
                }
            } else {
                TextField("Enter License Key", text: $licenseViewModel.licenseKey)
                    .textFieldStyle(RoundedBorderTextFieldStyle())
                    .frame(maxWidth: 300)
                
                Button(action: {
                    Task {
                        await licenseViewModel.validateLicense()
                    }
                }) {
                    if licenseViewModel.isValidating {
                        ProgressView()
                    } else {
                        Text("Activate License")
                    }
                }
                .disabled(licenseViewModel.isValidating)
            }
            
            if let message = licenseViewModel.validationMessage {
                Text(message)
                    .foregroundColor(licenseViewModel.licenseState == .licensed ? .green : .red)
                    .font(.caption)
            }
        }
        .padding()
    }
}

struct LicenseView_Previews: PreviewProvider {
    static var previews: some View {
        LicenseView()
    }
}

================
File: VoiceInk/Views/MenuBarView.swift
================
import SwiftUI
import LaunchAtLogin

struct MenuBarView: View {
    @EnvironmentObject var whisperState: WhisperState
    @EnvironmentObject var hotkeyManager: HotkeyManager
    @EnvironmentObject var menuBarManager: MenuBarManager
    @EnvironmentObject var updaterViewModel: UpdaterViewModel
    @EnvironmentObject var enhancementService: AIEnhancementService
    @EnvironmentObject var aiService: AIService
    @State private var launchAtLoginEnabled = LaunchAtLogin.isEnabled
    @State private var menuRefreshTrigger = false  // Added to force menu updates
    
    var body: some View {
        VStack {
            Button("Toggle Mini Recorder") {
                Task {
                    await whisperState.toggleMiniRecorder()
                }
            }
            
            Toggle("AI Enhancement", isOn: $enhancementService.isEnhancementEnabled)
            
            Menu {
                ForEach(aiService.connectedProviders, id: \.self) { provider in
                    Button {
                        aiService.selectedProvider = provider
                    } label: {
                        HStack {
                            Text(provider.rawValue)
                            if aiService.selectedProvider == provider {
                                Image(systemName: "checkmark")
                            }
                        }
                    }
                }
                
                if aiService.connectedProviders.isEmpty {
                    Text("No providers connected")
                        .foregroundColor(.secondary)
                }
                
                Divider()
                
                Button("Manage AI Providers") {
                    menuBarManager.openMainWindowAndNavigate(to: "Enhancement")
                }
            } label: {
                HStack {
                    Text("AI Provider: \(aiService.selectedProvider.rawValue)")
                    Image(systemName: "chevron.up.chevron.down")
                        .font(.system(size: 10))
                }
            }
            
            Menu {
                ForEach(whisperState.availableModels) { model in
                    Button {
                        Task {
                            await whisperState.setDefaultModel(model)
                        }
                    } label: {
                        HStack {
                            Text(PredefinedModels.models.first { $0.name == model.name }?.displayName ?? model.name)
                            if whisperState.currentModel?.name == model.name {
                                Image(systemName: "checkmark")
                            }
                        }
                    }
                }
                
                if whisperState.availableModels.isEmpty {
                    Text("No models downloaded")
                        .foregroundColor(.secondary)
                }
                
                Divider()
                
                Button("Manage Models") {
                    menuBarManager.openMainWindowAndNavigate(to: "AI Models")
                }
            } label: {
                HStack {
                    Text("Model: \(PredefinedModels.models.first { $0.name == whisperState.currentModel?.name }?.displayName ?? "None")")
                    Image(systemName: "chevron.up.chevron.down")
                        .font(.system(size: 10))
                }
            }
            
            LanguageSelectionView(whisperState: whisperState, displayMode: .menuItem)
            
            Toggle("Use Clipboard Context", isOn: $enhancementService.useClipboardContext)
                .disabled(!enhancementService.isEnhancementEnabled)
            
            Toggle("Use Screen Context", isOn: $enhancementService.useScreenCaptureContext)
                .disabled(!enhancementService.isEnhancementEnabled)
            
            Menu("Additional") {
                Button {
                    whisperState.isAutoCopyEnabled.toggle()
                } label: {
                    HStack {
                        Text("Auto-copy to Clipboard")
                        Spacer()
                        if whisperState.isAutoCopyEnabled {
                            Image(systemName: "checkmark")
                        }
                    }
                }
                
                Button {
                    SoundManager.shared.isEnabled.toggle()
                    menuRefreshTrigger.toggle()
                } label: {
                    HStack {
                        Text("Sound Feedback")
                        Spacer()
                        if SoundManager.shared.isEnabled {
                            Image(systemName: "checkmark")
                        }
                    }
                }
                
                Button {
                    MediaController.shared.isMediaPauseEnabled.toggle()
                    menuRefreshTrigger.toggle()
                } label: {
                    HStack {
                        Text("Pause Media During Recording")
                        Spacer()
                        if MediaController.shared.isMediaPauseEnabled {
                            Image(systemName: "checkmark")
                        }
                    }
                }
            }
            .id("additional-menu-\(menuRefreshTrigger)")
            
            Divider()
            
            Button("History") {
                menuBarManager.openMainWindowAndNavigate(to: "History")
            }
            
            Button("Settings") {
                menuBarManager.openMainWindowAndNavigate(to: "Settings")
            }
            
            Button(menuBarManager.isMenuBarOnly ? "Show Dock Icon" : "Hide Dock Icon") {
                menuBarManager.toggleMenuBarOnly()
            }
            
            Toggle("Launch at Login", isOn: $launchAtLoginEnabled)
                .onChange(of: launchAtLoginEnabled) { newValue in
                    LaunchAtLogin.isEnabled = newValue
                }
            
            Divider()
            
            Button("Check for Updates") {
                updaterViewModel.checkForUpdates()
            }
            .disabled(!updaterViewModel.canCheckForUpdates)
            
            Button("About VoiceInk") {
                NSApplication.shared.orderFrontStandardAboutPanel(nil)
                NSApp.activate(ignoringOtherApps: true)
            }
            
            Button("Help and Support") {
                openMailForSupport()
            }
            
            Divider()
            
            Button("Quit VoiceInk") {
                NSApplication.shared.terminate(nil)
            }
        }
    }
    
    private func openMailForSupport() {
        let subject = "VoiceInk Help & Support"
        let encodedSubject = subject.addingPercentEncoding(withAllowedCharacters: .urlQueryAllowed) ?? ""
        let mailtoURL = URL(string: "mailto:prakashjoshipax@gmail.com?subject=\(encodedSubject)")!
        NSWorkspace.shared.open(mailtoURL)
    }
}

================
File: VoiceInk/Views/MetricsView.swift
================
import SwiftUI
import SwiftData
import Charts
import KeyboardShortcuts

struct MetricsView: View {
    @Environment(\.modelContext) private var modelContext
    @Query(sort: \Transcription.timestamp) private var transcriptions: [Transcription]
    @EnvironmentObject private var whisperState: WhisperState
    @EnvironmentObject private var hotkeyManager: HotkeyManager
    @StateObject private var licenseViewModel = LicenseViewModel()
    @State private var hasLoadedData = false
    let skipSetupCheck: Bool
    
    init(skipSetupCheck: Bool = false) {
        self.skipSetupCheck = skipSetupCheck
    }
    
    var body: some View {
        VStack {
            // Trial Message
            if case .trial(let daysRemaining) = licenseViewModel.licenseState {
                TrialMessageView(
                    message: "You have \(daysRemaining) days left in your trial",
                    type: daysRemaining <= 2 ? .warning : .info
                )
                .padding()
            } else if case .trialExpired = licenseViewModel.licenseState {
                TrialMessageView(
                    message: "Your trial has expired. Upgrade to continue using VoiceInk",
                    type: .expired
                )
                .padding()
            }
            
            Group {
                if skipSetupCheck {
                    MetricsContent(transcriptions: Array(transcriptions))
                } else if isSetupComplete {
                    MetricsContent(transcriptions: Array(transcriptions))
                } else {
                    MetricsSetupView()
                }
            }
        }
        .background(Color(.controlBackgroundColor))
        .task {
            // Ensure the model context is ready
            hasLoadedData = true
        }
    }
    
    private var isSetupComplete: Bool {
        hasLoadedData &&
        whisperState.currentModel != nil &&
        KeyboardShortcuts.getShortcut(for: .toggleMiniRecorder) != nil &&
        AXIsProcessTrusted() &&
        CGPreflightScreenCaptureAccess()
    }
}

================
File: VoiceInk/Views/MiniRecorderPanel.swift
================
import SwiftUI
import AppKit

class MiniRecorderPanel: NSPanel {
    override var canBecomeKey: Bool { false }
    override var canBecomeMain: Bool { false }
    
    init(contentRect: NSRect) {
        super.init(
            contentRect: contentRect,
            styleMask: [.nonactivatingPanel, .fullSizeContentView],
            backing: .buffered,
            defer: false
        )
        
        self.isFloatingPanel = true
        self.level = .floating
        self.backgroundColor = .clear
        self.isOpaque = false
        self.hasShadow = false
        self.isMovableByWindowBackground = true
        self.hidesOnDeactivate = false
        self.collectionBehavior = [.canJoinAllSpaces, .fullScreenAuxiliary]
        
        self.titlebarAppearsTransparent = true
        self.titleVisibility = .hidden
        
        self.standardWindowButton(.closeButton)?.isHidden = true
        
        self.isMovable = true
    }
    
    static func calculateWindowMetrics() -> NSRect {
        guard let screen = NSScreen.main else {
            return NSRect(x: 0, y: 0, width: 150, height: 34)
        }
        
        let width: CGFloat = 150  // Adjusted for new spacing and negative padding
        let height: CGFloat = 34
        let padding: CGFloat = 24
        
        let visibleFrame = screen.visibleFrame
        
        let xPosition = visibleFrame.midX - (width / 2)
        let yPosition = visibleFrame.minY + padding
        
        return NSRect(
            x: xPosition,
            y: yPosition,
            width: width,
            height: height
        )
    }
    
    func show() {
        let metrics = MiniRecorderPanel.calculateWindowMetrics()
        setFrame(metrics, display: true)
        orderFrontRegardless()
    }
    
    func hide(completion: @escaping () -> Void) {
        completion()
    }
}

================
File: VoiceInk/Views/MiniRecorderView.swift
================
import SwiftUI

struct MiniRecorderView: View {
    @ObservedObject var whisperState: WhisperState
    @ObservedObject var recorder: Recorder
    @EnvironmentObject var windowManager: MiniWindowManager
    @State private var showPromptPopover = false
    
    var body: some View {
        Group {
            if windowManager.isVisible {
                Capsule()
                    .fill(.clear)
                    .background(
                        ZStack {
                            // Base dark background
                            Color.black.opacity(0.9)
                            
                            // Subtle gradient overlay
                            LinearGradient(
                                colors: [
                                    Color.black.opacity(0.95),
                                    Color(red: 0.15, green: 0.15, blue: 0.15).opacity(0.9)
                                ],
                                startPoint: .top,
                                endPoint: .bottom
                            )
                            
                            // Very subtle visual effect for depth
                            VisualEffectView(material: .hudWindow, blendingMode: .withinWindow)
                                .opacity(0.05)
                        }
                        .clipShape(Capsule())
                    )
                    .overlay {
                        // Subtle inner border
                        Capsule()
                            .strokeBorder(Color.white.opacity(0.1), lineWidth: 0.5)
                    }
                    .overlay {
                        HStack(spacing: 16) {
                            // Record Button
                            NotchRecordButton(
                                isRecording: whisperState.isRecording,
                                isProcessing: whisperState.isProcessing
                            ) {
                                Task { await whisperState.toggleRecord() }
                            }
                            .frame(width: 18)
                            .padding(.leading, -4)
                            
                            // AI Enhancement Toggle
                            if let enhancementService = whisperState.getEnhancementService() {
                                NotchToggleButton(
                                    isEnabled: enhancementService.isEnhancementEnabled,
                                    icon: "sparkles",
                                    color: .blue
                                ) {
                                    enhancementService.isEnhancementEnabled.toggle()
                                }
                                .frame(width: 18)
                                .disabled(!enhancementService.isConfigured)
                            }
                            
                            // Custom Prompt Toggle and Selector
                            if let enhancementService = whisperState.getEnhancementService() {
                                NotchToggleButton(
                                    isEnabled: enhancementService.isEnhancementEnabled,
                                    icon: enhancementService.activePrompt?.icon.rawValue ?? "text.badge.checkmark",
                                    color: .green
                                ) {
                                    showPromptPopover.toggle()
                                }
                                .frame(width: 18)
                                .disabled(!enhancementService.isEnhancementEnabled)
                                .popover(isPresented: $showPromptPopover, arrowEdge: .bottom) {
                                    NotchPromptPopover(enhancementService: enhancementService)
                                }
                            }
                            
                            // Visualizer
                            Group {
                                if whisperState.isProcessing {
                                    NotchStaticVisualizer(color: .white)
                                } else {
                                    NotchAudioVisualizer(
                                        audioMeter: recorder.audioMeter,
                                        color: .white,
                                        isActive: whisperState.isRecording
                                    )
                                }
                            }
                            .frame(width: 18)
                            .padding(.trailing, -4)
                        }
                        .padding(.horizontal, 8)
                        .padding(.vertical, 8)
                    }
                    .opacity(windowManager.isVisible ? 1 : 0)
            }
        }
    }
}

// Visual Effect View wrapper for NSVisualEffectVie

================
File: VoiceInk/Views/MiniWindowManager.swift
================
import SwiftUI
import AppKit

class MiniWindowManager: ObservableObject {
    @Published var isVisible = false
    private var windowController: NSWindowController?
    private var miniPanel: MiniRecorderPanel?
    private let whisperState: WhisperState
    private let recorder: Recorder
    
    init(whisperState: WhisperState, recorder: Recorder) {
        self.whisperState = whisperState
        self.recorder = recorder
        
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleHideNotification),
            name: NSNotification.Name("HideMiniRecorder"),
            object: nil
        )
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self)
    }
    
    @objc private func handleHideNotification() {
        hide()
    }
    
    func show() {
        if isVisible { return }
        
        let activeScreen = NSApp.keyWindow?.screen ?? NSScreen.main ?? NSScreen.screens[0]
        
        initializeWindow(screen: activeScreen)
        self.isVisible = true
        miniPanel?.show()
    }
    
    func hide() {
        guard isVisible else { return }
        
        self.isVisible = false
        
        self.miniPanel?.hide { [weak self] in
            guard let self = self else { return }
            self.deinitializeWindow()
        }
    }
    
    private func initializeWindow(screen: NSScreen) {
        deinitializeWindow()
        
        let metrics = MiniRecorderPanel.calculateWindowMetrics()
        let panel = MiniRecorderPanel(contentRect: metrics)
        
        let miniRecorderView = MiniRecorderView(whisperState: whisperState, recorder: recorder)
            .environmentObject(self)
        
        let hostingController = NSHostingController(rootView: miniRecorderView)
        panel.contentView = hostingController.view
        
        self.miniPanel = panel
        self.windowController = NSWindowController(window: panel)
        
        panel.orderFrontRegardless()
    }
    
    private func deinitializeWindow() {
        windowController?.close()
        windowController = nil
        miniPanel = nil
    }
    
    func toggle() {
        if isVisible {
            hide()
        } else {
            show()
        }
    }
}

================
File: VoiceInk/Views/ModelManagementView.swift
================
import SwiftUI
import SwiftData

struct ModelManagementView: View {
    @ObservedObject var whisperState: WhisperState
    @State private var modelToDelete: WhisperModel?
    @StateObject private var aiService = AIService()
    @EnvironmentObject private var enhancementService: AIEnhancementService
    @Environment(\.modelContext) private var modelContext
    
    var body: some View {
        ScrollView {
            VStack(alignment: .leading, spacing: 24) {
                defaultModelSection
                languageSelectionSection
                availableModelsSection
            }
            .padding(40)
        }
        .frame(minWidth: 600, minHeight: 500)
        .background(Color(NSColor.controlBackgroundColor))
        .alert(item: $modelToDelete) { model in
            Alert(
                title: Text("Delete Model"),
                message: Text("Are you sure you want to delete the model '\(model.name)'?"),
                primaryButton: .destructive(Text("Delete")) {
                    Task {
                        await whisperState.deleteModel(model)
                    }
                },
                secondaryButton: .cancel()
            )
        }
    }
    
    private var defaultModelSection: some View {
        VStack(alignment: .leading, spacing: 8) {
            Text("Default Model")
                .font(.headline)
                .foregroundColor(.secondary)
            Text(whisperState.currentModel.flatMap { model in
                PredefinedModels.models.first { $0.name == model.name }?.displayName
            } ?? "No model selected")
                .font(.title2)
                .fontWeight(.bold)
        }
        .padding()
        .frame(maxWidth: .infinity, alignment: .leading)
        .background(Color(.windowBackgroundColor).opacity(0.4))
        .cornerRadius(10)
    }
    
    private var languageSelectionSection: some View {
        LanguageSelectionView(whisperState: whisperState, displayMode: .full)
    }
    
    private var availableModelsSection: some View {
        VStack(alignment: .leading, spacing: 16) {
            HStack {
                Text("Available Models")
                    .font(.title3)
                    .fontWeight(.semibold)
                
                Text("(\(whisperState.predefinedModels.count))")
                    .foregroundColor(.secondary)
                    .font(.subheadline)
                
                Spacer()
            }
            
            LazyVGrid(columns: [GridItem(.adaptive(minimum: 300, maximum: 400), spacing: 16)], spacing: 16) {
                ForEach(whisperState.predefinedModels) { model in
                    modelCard(for: model)
                }
            }
        }
        .padding()
        .background(Color(.windowBackgroundColor).opacity(0.4))
        .cornerRadius(10)
    }
    
    private func modelCard(for model: PredefinedModel) -> some View {
        let isDownloaded = whisperState.availableModels.contains { $0.name == model.name }
        let isCurrent = whisperState.currentModel?.name == model.name
        
        return VStack(alignment: .leading, spacing: 12) {
            // Model name and details
            HStack {
                VStack(alignment: .leading, spacing: 4) {
                    Text(model.displayName)
                        .font(.headline)
                    Text("\(model.size) ‚Ä¢ \(model.language)")
                        .font(.caption)
                        .foregroundColor(.secondary)
                }
                Spacer()
                modelStatusBadge(isDownloaded: isDownloaded, isCurrent: isCurrent)
            }
            
            // Description
            Text(model.description)
                .font(.subheadline)
                .foregroundColor(.secondary)
                .lineLimit(2)
            
            // Performance indicators
            HStack(spacing: 16) {
                performanceIndicator(label: "Speed", value: model.speed)
                performanceIndicator(label: "Accuracy", value: model.accuracy)
                ramUsageLabel(gb: model.ramUsage)
            }
            
            // Action buttons
            HStack {
                modelActionButton(isDownloaded: isDownloaded, isCurrent: isCurrent, model: model)
                
                if isDownloaded {
                    Menu {
                        Button(action: {
                            if let downloadedModel = whisperState.availableModels.first(where: { $0.name == model.name }) {
                                modelToDelete = downloadedModel
                            }
                        }) {
                            Label("Delete", systemImage: "trash")
                        }
                        
                        Button(action: {
                            if let downloadedModel = whisperState.availableModels.first(where: { $0.name == model.name }) {
                                NSWorkspace.shared.selectFile(downloadedModel.url.path, inFileViewerRootedAtPath: "")
                            }
                        }) {
                            Label("Show in Finder", systemImage: "folder")
                        }
                    } label: {
                        Image(systemName: "ellipsis.circle")
                            .foregroundColor(.secondary)
                    }
                    .menuStyle(BorderlessButtonMenuStyle())
                    .frame(width: 30, height: 30)
                }
            }
        }
        .padding()
        .background(Color(.windowBackgroundColor).opacity(0.9))
        .cornerRadius(10)
        .overlay(
            RoundedRectangle(cornerRadius: 10)
                .stroke(isCurrent ? Color.accentColor : Color.gray.opacity(0.2), lineWidth: isCurrent ? 2 : 1)
        )
    }

    private func modelStatusBadge(isDownloaded: Bool, isCurrent: Bool) -> some View {
        Group {
            if isCurrent {
                Text("Default")
                    .font(.caption)
                    .padding(.horizontal, 8)
                    .padding(.vertical, 4)
                    .background(Color.green)
                    .foregroundColor(.white)
                    .cornerRadius(8)
            } else if isDownloaded {
                Text("Downloaded")
                    .font(.caption)
                    .padding(.horizontal, 8)
                    .padding(.vertical, 4)
                    .background(Color.indigo)
                    .foregroundColor(.white)
                    .cornerRadius(8)
            }
        }
    }

    private func performanceIndicator(label: String, value: Double) -> some View {
        VStack(alignment: .leading, spacing: 4) {
            Text(label)
                .font(.caption)
                .foregroundColor(.secondary)
            
            HStack(spacing: 2) {
                ForEach(0..<5) { index in
                    RoundedRectangle(cornerRadius: 2)
                        .fill(index < Int(value * 5) ? performanceColor(value: value) : Color.secondary.opacity(0.2))
                        .frame(width: 16, height: 8)
                }
            }
            
            Text(String(format: "%.1f", value * 10))
                .font(.caption)
                .foregroundColor(.secondary)
        }
    }
    
    private func performanceColor(value: Double) -> Color {
        switch value {
        case 0.8...: return .green
        case 0.6..<0.8: return .yellow
        case 0.4..<0.6: return .orange
        default: return .red
        }
    }
    
    private func modelActionButton(isDownloaded: Bool, isCurrent: Bool, model: PredefinedModel) -> some View {
        Group {
            if isCurrent {
                Text("Default Model")
                    .foregroundColor(.white)
            } else if isDownloaded {
                Button("Set as Default") {
                    if let downloadedModel = whisperState.availableModels.first(where: { $0.name == model.name }) {
                        Task {
                            await whisperState.setDefaultModel(downloadedModel)
                        }
                    }
                }
                .foregroundColor(.white)
            } else if whisperState.downloadProgress[model.name] != nil {
                VStack {
                    ProgressView(value: whisperState.downloadProgress[model.name] ?? 0)
                        .progressViewStyle(LinearProgressViewStyle())
                        .animation(.linear, value: whisperState.downloadProgress[model.name])
                    Text("\(Int((whisperState.downloadProgress[model.name] ?? 0) * 100))%")
                        .font(.caption)
                        .animation(.none)
                }
            } else {
                Button("Download Model") {
                    Task {
                        await whisperState.downloadModel(model)
                    }
                }
                .foregroundColor(.white)
            }
        }
        .buttonStyle(GradientButtonStyle(isDownloaded: isDownloaded, isCurrent: isCurrent))
        .frame(maxWidth: .infinity)
    }

    private func ramUsageLabel(gb: Double) -> some View {
        VStack(alignment: .leading, spacing: 4) {
            Text("RAM")
                .font(.caption)
                .foregroundColor(.secondary)
            
            Text(formatRAMSize(gb))
                .font(.system(size: 12, weight: .bold))
                .foregroundColor(.primary)
        }
    }

    private func formatRAMSize(_ gb: Double) -> String {
        if gb >= 1.0 {
            return String(format: "%.1f GB", gb)
        } else {
            return String(format: "%d MB", Int(gb * 1024))
        }
    }
}

struct GradientButtonStyle: ButtonStyle {
    let isDownloaded: Bool
    let isCurrent: Bool
    
    func makeBody(configuration: Configuration) -> some View {
        configuration.label
            .padding(.vertical, 5)
            .padding(.horizontal, 10)
            .background(
                Group {
                    if isCurrent {
                        LinearGradient(gradient: Gradient(colors: [Color.green, Color.green.opacity(0.7)]), startPoint: .top, endPoint: .bottom)
                    } else if isDownloaded {
                        LinearGradient(gradient: Gradient(colors: [Color.purple, Color.purple.opacity(0.7)]), startPoint: .top, endPoint: .bottom)
                    } else {
                        LinearGradient(gradient: Gradient(colors: [Color.blue, Color.blue.opacity(0.7)]), startPoint: .top, endPoint: .bottom)
                    }
                }
            )
            .cornerRadius(10)
            .shadow(color: Color.black.opacity(0.2), radius: 5, x: 0, y: 2)
            .scaleEffect(configuration.isPressed ? 0.95 : 1)
            .animation(.easeInOut(duration: 0.2), value: configuration.isPressed)
    }
}

================
File: VoiceInk/Views/NotchRecorderPanel.swift
================
import SwiftUI
import AppKit

class KeyablePanel: NSPanel {
    override var canBecomeKey: Bool { true }
    override var canBecomeMain: Bool { true }
}

class NotchRecorderPanel: KeyablePanel {
    override var canBecomeKey: Bool { false }
    override var canBecomeMain: Bool { false }
    
    private var notchMetrics: (width: CGFloat, height: CGFloat) {
        if let screen = NSScreen.main {
            let safeAreaInsets = screen.safeAreaInsets
            
            // Simplified height calculation - matching calculateWindowMetrics
            let notchHeight: CGFloat
            if safeAreaInsets.top > 0 {
                // We're definitely on a notched MacBook
                notchHeight = safeAreaInsets.top
            } else {
                // For external displays or non-notched MacBooks, use system menu bar height
                notchHeight = NSStatusBar.system.thickness
            }
            
            // Get actual notch width from safe area insets
            let baseNotchWidth: CGFloat = safeAreaInsets.left > 0 ? safeAreaInsets.left * 2 : 200
            
            // Calculate total width including controls and padding
            // 16pt padding on each side + space for controls
            let controlsWidth: CGFloat = 44 // Space for buttons on each side (22 * 2)
            let paddingWidth: CGFloat = 32 // 16pt on each side
            let totalWidth = baseNotchWidth + controlsWidth * 2 + paddingWidth
            
            return (totalWidth, notchHeight)
        }
        return (280, 24)  // Increased fallback width
    }
    
    init(contentRect: NSRect) {
        let metrics = NotchRecorderPanel.calculateWindowMetrics()
        
        super.init(
            contentRect: metrics.frame,
            styleMask: [.nonactivatingPanel, .fullSizeContentView, .hudWindow],
            backing: .buffered,
            defer: false
        )
        
        self.isFloatingPanel = true
        self.level = .statusBar + 3
        self.backgroundColor = .clear
        self.isOpaque = false
        self.alphaValue = 1.0
        self.hasShadow = false
        self.isMovableByWindowBackground = false
        self.hidesOnDeactivate = false
        self.collectionBehavior = [.canJoinAllSpaces, .fullScreenAuxiliary, .ignoresCycle]
        
        self.appearance = NSAppearance(named: .darkAqua)
        self.styleMask.remove(.titled)
        self.titlebarAppearsTransparent = true
        self.titleVisibility = .hidden
        
        // Keep escape key functionality
        self.standardWindowButton(.closeButton)?.isHidden = true
        
        // Make window transparent to mouse events except for the content
        self.ignoresMouseEvents = false
        self.isMovable = false
        
        print("NotchRecorderPanel initialized")
        
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleScreenParametersChange),
            name: NSApplication.didChangeScreenParametersNotification,
            object: nil
        )
    }
    
    static func calculateWindowMetrics() -> (frame: NSRect, notchWidth: CGFloat, notchHeight: CGFloat) {
        guard let screen = NSScreen.main else {
            return (NSRect(x: 0, y: 0, width: 280, height: 24), 280, 24)
        }
        
        let safeAreaInsets = screen.safeAreaInsets
        
        // Simplified height calculation
        let notchHeight: CGFloat
        if safeAreaInsets.top > 0 {
            // We're definitely on a notched MacBook
            notchHeight = safeAreaInsets.top
        } else {
            // For external displays or non-notched MacBooks, use system menu bar height
            notchHeight = NSStatusBar.system.thickness
        }
        
        // Calculate exact notch width
        let baseNotchWidth: CGFloat = safeAreaInsets.left > 0 ? safeAreaInsets.left * 2 : 200
        
        // Calculate total width including controls and padding
        let controlsWidth: CGFloat = 44 // Space for buttons on each side (22 * 2)
        let paddingWidth: CGFloat = 32 // 16pt on each side
        let totalWidth = baseNotchWidth + controlsWidth * 2 + paddingWidth
        
        // Position exactly at the center
        let xPosition = screen.frame.midX - (totalWidth / 2)
        let yPosition = screen.frame.maxY - notchHeight
        
        let frame = NSRect(
            x: xPosition,
            y: yPosition,
            width: totalWidth,
            height: notchHeight
        )
        
        return (frame, baseNotchWidth, notchHeight)
    }
    
    func show() {
        guard let screen = NSScreen.main else { return }
        let metrics = NotchRecorderPanel.calculateWindowMetrics()
        setFrame(metrics.frame, display: true)
        orderFrontRegardless()
    }
    
    func hide(completion: @escaping () -> Void) {
        completion()
    }
    
    @objc private func handleScreenParametersChange() {
        // Add a small delay to ensure we get the correct screen metrics
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) { [weak self] in
            guard let self = self else { return }
            let metrics = NotchRecorderPanel.calculateWindowMetrics()
            self.setFrame(metrics.frame, display: true)
        }
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self)
    }
}

class NotchRecorderHostingController<Content: View>: NSHostingController<Content> {
    override func viewDidLoad() {
        super.viewDidLoad()
        
        view.wantsLayer = true
        view.layer?.backgroundColor = NSColor.clear.cgColor
        
        // Add visual effect view as background
        let visualEffect = NSVisualEffectView()
        visualEffect.material = .dark
        visualEffect.state = .active
        visualEffect.blendingMode = .withinWindow
        visualEffect.wantsLayer = true
        visualEffect.layer?.backgroundColor = NSColor.black.withAlphaComponent(0.95).cgColor
        
        // Create a mask layer for the notched shape
        let maskLayer = CAShapeLayer()
        let path = CGMutablePath()
        let bounds = view.bounds
        let cornerRadius: CGFloat = 10
        
        // Create the notched path
        path.move(to: CGPoint(x: bounds.minX, y: bounds.minY))
        path.addLine(to: CGPoint(x: bounds.maxX, y: bounds.minY))
        path.addLine(to: CGPoint(x: bounds.maxX, y: bounds.maxY - cornerRadius))
        path.addQuadCurve(to: CGPoint(x: bounds.maxX - cornerRadius, y: bounds.maxY),
                         control: CGPoint(x: bounds.maxX, y: bounds.maxY))
        path.addLine(to: CGPoint(x: bounds.minX + cornerRadius, y: bounds.maxY))
        path.addQuadCurve(to: CGPoint(x: bounds.minX, y: bounds.maxY - cornerRadius),
                         control: CGPoint(x: bounds.minX, y: bounds.maxY))
        path.closeSubpath()
        
        maskLayer.path = path
        visualEffect.layer?.mask = maskLayer
        
        view.addSubview(visualEffect, positioned: .below, relativeTo: nil)
        visualEffect.translatesAutoresizingMaskIntoConstraints = false
        NSLayoutConstraint.activate([
            visualEffect.topAnchor.constraint(equalTo: view.topAnchor),
            visualEffect.leadingAnchor.constraint(equalTo: view.leadingAnchor),
            visualEffect.trailingAnchor.constraint(equalTo: view.trailingAnchor),
            visualEffect.bottomAnchor.constraint(equalTo: view.bottomAnchor)
        ])
    }
}

================
File: VoiceInk/Views/NotchRecorderView.swift
================
import SwiftUI

struct NotchRecorderView: View {
    @ObservedObject var whisperState: WhisperState
    @ObservedObject var recorder: Recorder
    @EnvironmentObject var windowManager: NotchWindowManager
    @State private var isHovering = false
    @State private var showPromptPopover = false
    
    private var menuBarHeight: CGFloat {
        if let screen = NSScreen.main {
            if screen.safeAreaInsets.top > 0 {
                return screen.safeAreaInsets.top
            }
            return NSApplication.shared.mainMenu?.menuBarHeight ?? NSStatusBar.system.thickness
        }
        return NSStatusBar.system.thickness
    }
    
    // Calculate exact notch width
    private var exactNotchWidth: CGFloat {
        if let screen = NSScreen.main {
            // On MacBooks with notch, safeAreaInsets.left represents half the notch width
            if screen.safeAreaInsets.left > 0 {
                // Multiply by 2 because safeAreaInsets.left is half the notch width
                return screen.safeAreaInsets.left * 2
            }
            // Fallback for non-notched Macs - use a standard width
            return 200
        }
        return 200 // Default fallback
    }
    
    var body: some View {
        Group {
            if windowManager.isVisible {
                HStack(spacing: 0) {
                    // Left side group with fixed width
                    HStack(spacing: 8) {
                        // Record Button
                        NotchRecordButton(
                            isRecording: whisperState.isRecording,
                            isProcessing: whisperState.isProcessing
                        ) {
                            Task { await whisperState.toggleRecord() }
                        }
                        .frame(width: 22)
                        
                        // AI Enhancement Toggle
                        if let enhancementService = whisperState.getEnhancementService() {
                            NotchToggleButton(
                                isEnabled: enhancementService.isEnhancementEnabled,
                                icon: "sparkles",
                                color: .blue
                            ) {
                                enhancementService.isEnhancementEnabled.toggle()
                            }
                            .frame(width: 22)
                            .disabled(!enhancementService.isConfigured)
                        }
                    }
                    .frame(width: 44) // Fixed width for controls
                    .padding(.leading, 16)
                    
                    // Center section with exact notch width
                    Rectangle()
                        .fill(Color.clear)
                        .frame(width: exactNotchWidth)
                        .contentShape(Rectangle()) // Make the entire area tappable
                    
                    // Right side group with fixed width
                    HStack(spacing: 8) {
                        // Custom Prompt Toggle and Selector
                        if let enhancementService = whisperState.getEnhancementService() {
                            NotchToggleButton(
                                isEnabled: enhancementService.isEnhancementEnabled,
                                icon: enhancementService.activePrompt?.icon.rawValue ?? "text.badge.checkmark",
                                color: .green
                            ) {
                                showPromptPopover.toggle()
                            }
                            .frame(width: 22)
                            .disabled(!enhancementService.isEnhancementEnabled)
                            .popover(isPresented: $showPromptPopover, arrowEdge: .bottom) {
                                NotchPromptPopover(enhancementService: enhancementService)
                            }
                        }
                        
                        // Visualizer
                        Group {
                            if whisperState.isProcessing {
                                NotchStaticVisualizer(color: .white)
                            } else {
                                NotchAudioVisualizer(
                                    audioMeter: recorder.audioMeter,
                                    color: .white,
                                    isActive: whisperState.isRecording
                                )
                            }
                        }
                        .frame(width: 22)
                    }
                    .frame(width: 44) // Fixed width for controls
                    .padding(.trailing, 16)
                }
                .frame(height: menuBarHeight)
                .frame(maxWidth: windowManager.isVisible ? .infinity : 0)
                .background(Color.black)
                .mask {
                    NotchShape(cornerRadius: 10)
                }
                .clipped()
                .onHover { hovering in
                    isHovering = hovering
                }
                .opacity(windowManager.isVisible ? 1 : 0)
            }
        }
    }
}

// Popover view for prompt selection
struct NotchPromptPopover: View {
    @ObservedObject var enhancementService: AIEnhancementService
    
    var body: some View {
        VStack(alignment: .leading, spacing: 8) {
            Text("Select Mode")
                .font(.headline)
                .foregroundColor(.white.opacity(0.9))
                .padding(.horizontal)
                .padding(.top, 8)
            
            Divider()
                .background(Color.white.opacity(0.1))
            
            ScrollView {
                VStack(alignment: .leading, spacing: 4) {
                    ForEach(enhancementService.allPrompts) { prompt in
                        NotchPromptRow(prompt: prompt, isSelected: enhancementService.selectedPromptId == prompt.id) {
                            enhancementService.setActivePrompt(prompt)
                        }
                    }
                }
                .padding(.horizontal)
            }
        }
        .frame(width: 180)
        .frame(maxHeight: 300)
        .padding(.vertical, 8)
        .background(Color.black)
        .environment(\.colorScheme, .dark)
    }
}

// Row view for each prompt
struct NotchPromptRow: View {
    let prompt: CustomPrompt
    let isSelected: Bool
    let action: () -> Void
    
    var body: some View {
        Button(action: action) {
            HStack(spacing: 8) {
                Image(systemName: prompt.icon.rawValue)
                    .foregroundColor(isSelected ? .green : .white.opacity(0.8))
                    .font(.system(size: 12))
                Text(prompt.title)
                    .foregroundColor(.white.opacity(0.9))
                    .font(.system(size: 13))
                    .lineLimit(1)
                if isSelected {
                    Spacer()
                    Image(systemName: "checkmark")
                        .foregroundColor(.green)
                        .font(.system(size: 10))
                }
            }
            .contentShape(Rectangle())
            .padding(.vertical, 4)
            .padding(.horizontal, 8)
        }
        .buttonStyle(.plain)
        .background(isSelected ? Color.white.opacity(0.1) : Color.clear)
        .cornerRadius(4)
    }
}

// New toggle button component matching the notch aesthetic
struct NotchToggleButton: View {
    let isEnabled: Bool
    let icon: String
    let color: Color
    let action: () -> Void
    
    var body: some View {
        Button(action: action) {
            ZStack {
                Circle()
                    .fill(isEnabled ? color.opacity(0.2) : Color(red: 0.4, green: 0.4, blue: 0.45).opacity(0.2))
                    .frame(width: 20, height: 20)
                
                Image(systemName: icon)
                    .font(.system(size: 10, weight: .medium))
                    .foregroundColor(isEnabled ? color : .white.opacity(0.6))
            }
        }
        .buttonStyle(PlainButtonStyle())
    }
}

struct CustomScaleModifier: ViewModifier {
    let scale: CGFloat
    let opacity: CGFloat
    
    func body(content: Content) -> some View {
        content
            .scaleEffect(scale, anchor: .center)
            .opacity(opacity)
    }
}

// Notch-specific button styles
struct NotchRecordButton: View {
    let isRecording: Bool
    let isProcessing: Bool
    let action: () -> Void
    
    var body: some View {
        Button(action: action) {
            ZStack {
                Circle()
                    .fill(buttonColor)
                    .frame(width: 22, height: 22)
                
                if isProcessing {
                    ProcessingIndicator(color: .white)
                        .frame(width: 14, height: 14)
                } else if isRecording {
                    // Show white square for recording state
                    RoundedRectangle(cornerRadius: 3)
                        .fill(Color.white)
                        .frame(width: 8, height: 8)
                } else {
                    // Show white circle for idle state
                    Circle()
                        .fill(Color.white)
                        .frame(width: 8, height: 8)
                }
            }
        }
        .buttonStyle(PlainButtonStyle())
        .disabled(isProcessing)
    }
    
    private var buttonColor: Color {
        if isProcessing {
            return Color(red: 0.4, green: 0.4, blue: 0.45)
        } else if isRecording {
            return .red
        } else {
            // Neutral gray for idle state
            return Color(red: 0.3, green: 0.3, blue: 0.35)
        }
    }
}

struct NotchAudioVisualizer: View {
    let audioMeter: AudioMeter
    let color: Color
    let isActive: Bool
    
    private let barCount = 5
    private let minHeight: CGFloat = 3
    private let maxHeight: CGFloat = 18
    private let audioThreshold: CGFloat = 0.01
    
    @State private var barHeights: [BarLevel] = []
    
    struct BarLevel {
        var average: CGFloat
        var peak: CGFloat
    }
    
    init(audioMeter: AudioMeter, color: Color, isActive: Bool) {
        self.audioMeter = audioMeter
        self.color = color
        self.isActive = isActive
        _barHeights = State(initialValue: Array(repeating: BarLevel(average: minHeight, peak: minHeight), count: 5))
    }
    
    var body: some View {
        HStack(spacing: 2) {
            ForEach(0..<barCount, id: \.self) { index in
                NotchVisualizerBar(
                    averageHeight: barHeights[index].average,
                    peakHeight: barHeights[index].peak,
                    color: color
                )
            }
        }
        .onChange(of: audioMeter) { newMeter in
           
            if isActive {
                updateBars()
            } else {
                resetBars()
            }
        }
    }
    
    private func updateBars() {
        for i in 0..<barCount {
            let targetHeight = calculateTargetHeight(for: i)
            let speed = CGFloat.random(in: 0.4...0.8)
            
            withAnimation(.spring(response: 0.2, dampingFraction: 0.7)) {
                barHeights[i].average += (targetHeight.average - barHeights[i].average) * speed
                barHeights[i].peak += (targetHeight.peak - barHeights[i].peak) * speed
            }
        }
    }
    
    private func resetBars() {
        withAnimation(.spring(response: 0.2, dampingFraction: 0.7)) {
            for i in 0..<barCount {
                barHeights[i].average = minHeight
                barHeights[i].peak = minHeight
            }
        }
    }
    
    private func calculateTargetHeight(for index: Int) -> BarLevel {
        let positionFactor = CGFloat(index) / CGFloat(barCount - 1)
        let curve = sin(positionFactor * .pi)
        
        let randomFactor = Double.random(in: 0.8...1.2)
        let averageBase = audioMeter.averagePower * randomFactor
        let peakBase = audioMeter.peakPower * randomFactor
        
        let averageHeight = CGFloat(averageBase) * maxHeight * 1.7 * curve
        let peakHeight = CGFloat(peakBase) * maxHeight * 1.7 * curve
        
        let finalAverage = max(minHeight, min(averageHeight, maxHeight))
        let finalPeak = max(minHeight, min(peakHeight, maxHeight))
        
        
        return BarLevel(
            average: finalAverage,
            peak: finalPeak
        )
    }
}

struct NotchVisualizerBar: View {
    let averageHeight: CGFloat
    let peakHeight: CGFloat
    let color: Color
    
    var body: some View {
        ZStack(alignment: .bottom) {
            // Average level bar
            RoundedRectangle(cornerRadius: 1.5)
                .fill(
                    LinearGradient(
                        gradient: Gradient(colors: [
                            color.opacity(0.6),
                            color.opacity(0.8),
                            color
                        ]),
                        startPoint: .bottom,
                        endPoint: .top
                    )
                )
                .frame(width: 2, height: averageHeight)
        
        }
        .animation(.spring(response: 0.2, dampingFraction: 0.7, blendDuration: 0), value: averageHeight)
        .animation(.spring(response: 0.2, dampingFraction: 0.7, blendDuration: 0), value: peakHeight)
    }
}

struct NotchStaticVisualizer: View {
    private let barCount = 5
    private let barHeights: [CGFloat] = [0.7, 0.5, 0.8, 0.4, 0.6]
    let color: Color
    
    var body: some View {
        HStack(spacing: 2) {
            ForEach(0..<barCount, id: \.self) { index in
                NotchVisualizerBar(
                    averageHeight: barHeights[index] * 18,
                    peakHeight: barHeights[index] * 18,
                    color: color
                )
            }
        }
    }
}

struct ProcessingIndicator: View {
    @State private var rotation: Double = 0
    let color: Color
    
    var body: some View {
        Circle()
            .trim(from: 0.1, to: 0.9)
            .stroke(color, lineWidth: 1.5)
            .frame(width: 12, height: 12)
            .rotationEffect(.degrees(rotation))
            .onAppear {
                withAnimation(.linear(duration: 1).repeatForever(autoreverses: false)) {
                    rotation = 360
                }
            }
    }
}

================
File: VoiceInk/Views/NotchShape.swift
================
import SwiftUI

struct NotchShape: Shape {
    var topCornerRadius: CGFloat {
        if bottomCornerRadius > 15 {
            bottomCornerRadius - 5
        } else {
            5
        }
    }
    
    var bottomCornerRadius: CGFloat
    
    init(cornerRadius: CGFloat? = nil) {
        if cornerRadius == nil {
            self.bottomCornerRadius = 10
        } else {
            self.bottomCornerRadius = cornerRadius!
        }
    }
    
    var animatableData: CGFloat {
        get { bottomCornerRadius }
        set { bottomCornerRadius = newValue }
    }
    
    func path(in rect: CGRect) -> Path {
        var path = Path()
        // Start from the top left corner
        path.move(to: CGPoint(x: rect.minX, y: rect.minY))
        // Top left inner curve
        path.addQuadCurve(
            to: CGPoint(x: rect.minX + topCornerRadius, y: topCornerRadius),
            control: CGPoint(x: rect.minX + topCornerRadius, y: rect.minY)
        )
        // Left vertical line
        path.addLine(to: CGPoint(x: rect.minX + topCornerRadius, y: rect.maxY - bottomCornerRadius))
        // Bottom left corner
        path.addQuadCurve(
            to: CGPoint(x: rect.minX + topCornerRadius + bottomCornerRadius, y: rect.maxY),
            control: CGPoint(x: rect.minX + topCornerRadius, y: rect.maxY)
        )
        path.addLine(to: CGPoint(x: rect.maxX - topCornerRadius - bottomCornerRadius, y: rect.maxY))
        // Bottom right corner
        path.addQuadCurve(
            to: CGPoint(x: rect.maxX - topCornerRadius, y: rect.maxY - bottomCornerRadius),
            control: CGPoint(x: rect.maxX - topCornerRadius, y: rect.maxY)
        )
        path.addLine(to: CGPoint(x: rect.maxX - topCornerRadius, y: rect.minY + bottomCornerRadius))
        
        // Closing the path to top right inner curve
        path.addQuadCurve(
            to: CGPoint(x: rect.maxX, y: rect.minY),
            control: CGPoint(x: rect.maxX - topCornerRadius, y: rect.minY)
        )
        path.addLine(to: CGPoint(x: rect.minX, y: rect.minY))
        return path
    }
}

================
File: VoiceInk/Views/NotchWindowManager.swift
================
import SwiftUI
import AppKit

class NotchWindowManager: ObservableObject {
    @Published var isVisible = false
    private var windowController: NSWindowController?
    private var notchPanel: NotchRecorderPanel?
    private let whisperState: WhisperState
    private let recorder: Recorder
    
    init(whisperState: WhisperState, recorder: Recorder) {
        self.whisperState = whisperState
        self.recorder = recorder
        
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleHideNotification),
            name: NSNotification.Name("HideNotchRecorder"),
            object: nil
        )
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self)
    }
    
    @objc private func handleHideNotification() {
        hide()
    }
    
    func show() {
        if isVisible { return }
        
        // Get the active screen from the key window or fallback to main screen
        let activeScreen = NSApp.keyWindow?.screen ?? NSScreen.main ?? NSScreen.screens[0]
        
        initializeWindow(screen: activeScreen)
        self.isVisible = true
        notchPanel?.show()
    }
    
    func hide() {
        guard isVisible else { return }
        
        // Remove animation for instant state change
        self.isVisible = false
        
        // Don't wait for animation, clean up immediately
        self.notchPanel?.hide { [weak self] in
            guard let self = self else { return }
            self.deinitializeWindow()
        }
    }
    
    private func initializeWindow(screen: NSScreen) {
        deinitializeWindow()
        
        let metrics = NotchRecorderPanel.calculateWindowMetrics()
        let panel = NotchRecorderPanel(contentRect: metrics.frame)
        
        let notchRecorderView = NotchRecorderView(whisperState: whisperState, recorder: recorder)
            .environmentObject(self)
        
        let hostingController = NotchRecorderHostingController(rootView: notchRecorderView)
        panel.contentView = hostingController.view
        
        self.notchPanel = panel
        self.windowController = NSWindowController(window: panel)
        
        panel.orderFrontRegardless()
    }
    
    private func deinitializeWindow() {
        windowController?.close()
        windowController = nil
        notchPanel = nil
    }
    
    func toggle() {
        if isVisible {
            hide()
        } else {
            show()
        }
    }
}

================
File: VoiceInk/Views/PermissionsView.swift
================
import SwiftUI
import AVFoundation
import Cocoa
import KeyboardShortcuts

class PermissionManager: ObservableObject {
    @Published var audioPermissionStatus = AVCaptureDevice.authorizationStatus(for: .audio)
    @Published var isAccessibilityEnabled = false
    @Published var isScreenRecordingEnabled = false
    @Published var isKeyboardShortcutSet = false
    
    init() {
        // Start observing system events that might indicate permission changes
        setupNotificationObservers()
        
        // Initial permission checks
        checkAllPermissions()
    }
    
    
    deinit {
        NotificationCenter.default.removeObserver(self)
    }
    
    private func setupNotificationObservers() {
        // Only observe when app becomes active, as this is a likely time for permissions to have changed
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(applicationDidBecomeActive),
            name: NSApplication.didBecomeActiveNotification,
            object: nil
        )
    }
    
    @objc private func applicationDidBecomeActive() {
        checkAllPermissions()
    }
    
    func checkAllPermissions() {
        checkAccessibilityPermissions()
        checkScreenRecordingPermission()
        checkAudioPermissionStatus()
        checkKeyboardShortcut()
    }
    
    func checkAccessibilityPermissions() {
        let options: NSDictionary = [kAXTrustedCheckOptionPrompt.takeUnretainedValue() as String: false]
        let accessibilityEnabled = AXIsProcessTrustedWithOptions(options)
        DispatchQueue.main.async {
            self.isAccessibilityEnabled = accessibilityEnabled
        }
    }
    
    func checkScreenRecordingPermission() {
        DispatchQueue.main.async {
            self.isScreenRecordingEnabled = CGPreflightScreenCaptureAccess()
        }
    }
    
    func requestScreenRecordingPermission() {
        CGRequestScreenCaptureAccess()
    }
    
    func checkAudioPermissionStatus() {
        DispatchQueue.main.async {
            self.audioPermissionStatus = AVCaptureDevice.authorizationStatus(for: .audio)
        }
    }
    
    func requestAudioPermission() {
        AVCaptureDevice.requestAccess(for: .audio) { granted in
            DispatchQueue.main.async {
                self.audioPermissionStatus = granted ? .authorized : .denied
            }
        }
    }
    
    func checkKeyboardShortcut() {
        DispatchQueue.main.async {
            self.isKeyboardShortcutSet = KeyboardShortcuts.getShortcut(for: .toggleMiniRecorder) != nil
        }
    }
}

struct PermissionCard: View {
    let icon: String
    let title: String
    let description: String
    let isGranted: Bool
    let buttonTitle: String
    let buttonAction: () -> Void
    let checkPermission: () -> Void
    @State private var isRefreshing = false
    
    var body: some View {
        VStack(alignment: .leading, spacing: 16) {
            HStack(spacing: 16) {
                // Icon with background
                ZStack {
                    Circle()
                        .fill(isGranted ? Color.green.opacity(0.15) : Color.orange.opacity(0.15))
                        .frame(width: 44, height: 44)
                    
                    Image(systemName: isGranted ? "\(icon).fill" : icon)
                        .font(.system(size: 20, weight: .semibold))
                        .foregroundColor(isGranted ? .green : .orange)
                        .symbolRenderingMode(.hierarchical)
                }
                
                VStack(alignment: .leading, spacing: 4) {
                    Text(title)
                        .font(.headline)
                    Text(description)
                        .font(.subheadline)
                        .foregroundColor(.secondary)
                }
                
                Spacer()
                
                // Status indicator with refresh
                HStack(spacing: 12) {
                    Button(action: {
                        withAnimation(.easeInOut(duration: 0.5)) {
                            isRefreshing = true
                        }
                        checkPermission()
                        
                        // Reset the animation after a delay
                        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                            isRefreshing = false
                        }
                    }) {
                        Image(systemName: "arrow.clockwise")
                            .font(.system(size: 14, weight: .medium))
                            .foregroundColor(.secondary)
                            .rotationEffect(.degrees(isRefreshing ? 360 : 0))
                    }
                    .buttonStyle(.plain)
                    .contentShape(Rectangle())
                    
                    if isGranted {
                        Image(systemName: "checkmark.seal.fill")
                            .font(.system(size: 20))
                            .foregroundColor(.green)
                            .symbolRenderingMode(.hierarchical)
                    } else {
                        Image(systemName: "xmark.seal.fill")
                            .font(.system(size: 20))
                            .foregroundColor(.orange)
                            .symbolRenderingMode(.hierarchical)
                    }
                }
            }
            
            if !isGranted {
                Button(action: buttonAction) {
                    HStack {
                        Text(buttonTitle)
                        Spacer()
                        Image(systemName: "arrow.right")
                    }
                    .font(.headline)
                    .foregroundColor(.white)
                    .padding()
                    .frame(maxWidth: .infinity)
                    .background(
                        LinearGradient(
                            colors: [Color.accentColor, Color.accentColor.opacity(0.8)],
                            startPoint: .leading,
                            endPoint: .trailing
                        )
                    )
                    .cornerRadius(10)
                }
                .buttonStyle(.plain)
            }
        }
        .padding()
        .background(Color(.windowBackgroundColor).opacity(0.9))
        .cornerRadius(16)
        .shadow(color: Color.black.opacity(0.05), radius: 5, y: 2)
    }
}

struct PermissionsView: View {
    @StateObject private var permissionManager = PermissionManager()
    
    var body: some View {
        ScrollView {
            VStack(spacing: 32) {
                // Header
                VStack(spacing: 24) {
                    Image(systemName: "shield.lefthalf.filled")
                        .font(.system(size: 40))
                        .foregroundStyle(.blue)
                        .padding(20)
                        .background(Circle()
                            .fill(Color(.windowBackgroundColor).opacity(0.9))
                            .shadow(color: .black.opacity(0.1), radius: 10, y: 5))
                    
                    VStack(spacing: 8) {
                        Text("App Permissions")
                            .font(.system(size: 28, weight: .bold))
                        Text("VoiceInk requires the following permissions to function properly")
                            .font(.system(size: 15))
                            .foregroundStyle(.secondary)
                    }
                }
                .padding(.vertical, 40)
                .frame(maxWidth: .infinity)
                
                // Permission Cards
                VStack(spacing: 16) {
                    // Keyboard Shortcut Permission
                    PermissionCard(
                        icon: "keyboard",
                        title: "Keyboard Shortcut",
                        description: "Set up a keyboard shortcut to use VoiceInk anywhere",
                        isGranted: permissionManager.isKeyboardShortcutSet,
                        buttonTitle: "Configure Shortcut",
                        buttonAction: {
                            NotificationCenter.default.post(
                                name: .navigateToDestination,
                                object: nil,
                                userInfo: ["destination": "Settings"]
                            )
                        },
                        checkPermission: { permissionManager.checkKeyboardShortcut() }
                    )
                    
                    // Audio Permission
                    PermissionCard(
                        icon: "mic",
                        title: "Microphone Access",
                        description: "Allow VoiceInk to record your voice for transcription",
                        isGranted: permissionManager.audioPermissionStatus == .authorized,
                        buttonTitle: permissionManager.audioPermissionStatus == .notDetermined ? "Request Permission" : "Open System Settings",
                        buttonAction: {
                            if permissionManager.audioPermissionStatus == .notDetermined {
                                permissionManager.requestAudioPermission()
                            } else {
                                if let url = URL(string: "x-apple.systempreferences:com.apple.preference.security?Privacy_Microphone") {
                                    NSWorkspace.shared.open(url)
                                }
                            }
                        },
                        checkPermission: { permissionManager.checkAudioPermissionStatus() }
                    )
                    
                    // Accessibility Permission
                    PermissionCard(
                        icon: "hand.raised",
                        title: "Accessibility Access",
                        description: "Allow VoiceInk to paste transcribed text directly at your cursor position",
                        isGranted: permissionManager.isAccessibilityEnabled,
                        buttonTitle: "Open System Settings",
                        buttonAction: {
                            if let url = URL(string: "x-apple.systempreferences:com.apple.preference.security?Privacy_Accessibility") {
                                NSWorkspace.shared.open(url)
                            }
                        },
                        checkPermission: { permissionManager.checkAccessibilityPermissions() }
                    )
                    
                    // Screen Recording Permission
                    PermissionCard(
                        icon: "rectangle.on.rectangle",
                        title: "Screen Recording Access",
                        description: "Allow VoiceInk to understand context from your screen for transcript Enhancement",
                        isGranted: permissionManager.isScreenRecordingEnabled,
                        buttonTitle: "Request Permission",
                        buttonAction: {
                            permissionManager.requestScreenRecordingPermission()
                            // After requesting, open system preferences as fallback
                            if let url = URL(string: "x-apple.systempreferences:com.apple.preference.security?Privacy_ScreenCapture") {
                                NSWorkspace.shared.open(url)
                            }
                        },
                        checkPermission: { permissionManager.checkScreenRecordingPermission() }
                    )
                }
            }
            .padding(24)
        }
        .background(Color(NSColor.controlBackgroundColor))
        .onAppear {
            permissionManager.checkAllPermissions()
        }
    }
}

#Preview {
    PermissionsView()
}

================
File: VoiceInk/Views/PowerModeView.swift
================
import SwiftUI

// Configuration Mode Enum
enum ConfigurationMode {
    case add
    case edit(PowerModeConfig)
    case editDefault(PowerModeConfig)
    
    var isAdding: Bool {
        if case .add = self { return true }
        return false
    }
    
    var isEditingDefault: Bool {
        if case .editDefault = self { return true }
        return false
    }
    
    var title: String {
        switch self {
        case .add: return "Add Configuration"
        case .editDefault: return "Edit Default Configuration"
        case .edit: return "Edit Configuration"
        }
    }
}

// Configuration Type
enum ConfigurationType {
    case application
    case website
}

// Main Configuration Sheet
struct ConfigurationSheet: View {
    let mode: ConfigurationMode
    @Binding var isPresented: Bool
    let powerModeManager: PowerModeManager
    @EnvironmentObject var enhancementService: AIEnhancementService
    
    // State for configuration
    @State private var configurationType: ConfigurationType = .application
    @State private var selectedAppURL: URL?
    @State private var isAIEnhancementEnabled: Bool
    @State private var selectedPromptId: UUID?
    @State private var installedApps: [(url: URL, name: String, bundleId: String, icon: NSImage)] = []
    @State private var searchText = ""
    
    // Website configuration state
    @State private var websiteURL: String = ""
    @State private var websiteName: String = ""
    
    private var filteredApps: [(url: URL, name: String, bundleId: String, icon: NSImage)] {
        if searchText.isEmpty {
            return installedApps
        }
        return installedApps.filter { app in
            app.name.localizedCaseInsensitiveContains(searchText) ||
            app.bundleId.localizedCaseInsensitiveContains(searchText)
        }
    }
    
    init(mode: ConfigurationMode, isPresented: Binding<Bool>, powerModeManager: PowerModeManager) {
        self.mode = mode
        self._isPresented = isPresented
        self.powerModeManager = powerModeManager
        
        switch mode {
        case .add:
            _isAIEnhancementEnabled = State(initialValue: true)
            _selectedPromptId = State(initialValue: nil)
        case .edit(let config), .editDefault(let config):
            _isAIEnhancementEnabled = State(initialValue: config.isAIEnhancementEnabled)
            _selectedPromptId = State(initialValue: config.selectedPrompt.flatMap { UUID(uuidString: $0) })
            if case .edit(let config) = mode {
                // Initialize website configuration if it exists
                if let urlConfig = config.urlConfigs?.first {
                    _configurationType = State(initialValue: .website)
                    _websiteURL = State(initialValue: urlConfig.url)
                    _websiteName = State(initialValue: config.appName)
                } else {
                    _configurationType = State(initialValue: .application)
                    _selectedAppURL = State(initialValue: NSWorkspace.shared.urlForApplication(withBundleIdentifier: config.bundleIdentifier))
                }
            }
        }
    }
    
    var body: some View {
        VStack(spacing: 0) {
            // Header
            HStack {
                Text(mode.title)
                    .font(.headline)
                Spacer()
            }
            .padding()
            
            Divider()
            
            if mode.isAdding {
                // Configuration Type Selector
                Picker("Configuration Type", selection: $configurationType) {
                    Text("Application").tag(ConfigurationType.application)
                    Text("Website").tag(ConfigurationType.website)
                }
                
                .padding()
                
                if configurationType == .application {
                    // Search bar
                    HStack {
                        Image(systemName: "magnifyingglass")
                            .foregroundColor(.secondary)
                        TextField("Search applications...", text: $searchText)
                            .textFieldStyle(PlainTextFieldStyle())
                        if !searchText.isEmpty {
                            Button(action: { searchText = "" }) {
                                Image(systemName: "xmark.circle.fill")
                                    .foregroundColor(.secondary)
                            }
                            .buttonStyle(PlainButtonStyle())
                        }
                    }
                    .padding(8)
                    .background(Color(.windowBackgroundColor).opacity(0.4))
                    .cornerRadius(8)
                    .padding()
                    
                    // App Grid
                    ScrollView {
                        LazyVGrid(columns: [GridItem(.adaptive(minimum: 100, maximum: 120), spacing: 16)], spacing: 16) {
                            ForEach(filteredApps.sorted(by: { $0.name.localizedCaseInsensitiveCompare($1.name) == .orderedAscending }), id: \.bundleId) { app in
                                AppGridItem(
                                    app: app,
                                    isSelected: app.url == selectedAppURL,
                                    action: { selectedAppURL = app.url }
                                )
                            }
                        }
                        .padding()
                    }
                } else {
                    // Website Configuration
                    VStack(spacing: 16) {
                        VStack(alignment: .leading, spacing: 8) {
                            Text("Website Name")
                                .font(.headline)
                            TextField("Enter website name", text: $websiteName)
                                .textFieldStyle(.roundedBorder)
                        }
                        
                        VStack(alignment: .leading, spacing: 8) {
                            Text("Website URL")
                                .font(.headline)
                            TextField("Enter website URL (e.g., google.com)", text: $websiteURL)
                                .textFieldStyle(.roundedBorder)
                        }
                    }
                    .padding()
                }
            }
            
            // Configuration Form
            if let config = getConfigForForm() {
                if let appURL = !mode.isEditingDefault ? NSWorkspace.shared.urlForApplication(withBundleIdentifier: config.bundleIdentifier) : nil {
                    AppConfigurationFormView(
                        appName: config.appName,
                        appIcon: NSWorkspace.shared.icon(forFile: appURL.path),
                        isDefaultConfig: mode.isEditingDefault,
                        isAIEnhancementEnabled: $isAIEnhancementEnabled,
                        selectedPromptId: $selectedPromptId
                    )
                } else {
                    AppConfigurationFormView(
                        appName: nil,
                        appIcon: nil,
                        isDefaultConfig: mode.isEditingDefault,
                        isAIEnhancementEnabled: $isAIEnhancementEnabled,
                        selectedPromptId: $selectedPromptId
                    )
                }
            }
            
            Divider()
            
            // Bottom buttons
            HStack {
                Button("Cancel") {
                    isPresented = false
                }
                .keyboardShortcut(.escape, modifiers: [])
                
                Spacer()
                
                Button(mode.isAdding ? "Add" : "Save") {
                    saveConfiguration()
                }
                .keyboardShortcut(.return, modifiers: [])
                .disabled(mode.isAdding && !canSave)
            }
            .padding()
        }
        .frame(width: 600)
        .frame(maxHeight: mode.isAdding ? 700 : 600)
        .onAppear {
            print("üîç ConfigurationSheet appeared - Mode: \(mode)")
            if mode.isAdding {
                print("üîç Loading installed apps...")
                loadInstalledApps()
            }
        }
    }
    
    private var canSave: Bool {
        if configurationType == .application {
            return selectedAppURL != nil
        } else {
            return !websiteURL.isEmpty && !websiteName.isEmpty
        }
    }
    
    private func getConfigForForm() -> PowerModeConfig? {
        switch mode {
        case .add:
            if configurationType == .application {
                guard let url = selectedAppURL,
                      let bundle = Bundle(url: url),
                      let bundleId = bundle.bundleIdentifier else { return nil }
                
                let appName = bundle.infoDictionary?["CFBundleName"] as? String ??
                             bundle.infoDictionary?["CFBundleDisplayName"] as? String ??
                             "Unknown App"
                
                return PowerModeConfig(
                    bundleIdentifier: bundleId,
                    appName: appName,
                    isAIEnhancementEnabled: isAIEnhancementEnabled,
                    selectedPrompt: selectedPromptId?.uuidString
                )
            } else {
                // Create a special PowerModeConfig for websites
                let urlConfig = URLConfig(url: websiteURL, promptId: selectedPromptId?.uuidString)
                return PowerModeConfig(
                    bundleIdentifier: "website.\(UUID().uuidString)",
                    appName: websiteName,
                    isAIEnhancementEnabled: isAIEnhancementEnabled,
                    selectedPrompt: selectedPromptId?.uuidString,
                    urlConfigs: [urlConfig]
                )
            }
        case .edit(let config), .editDefault(let config):
            return config
        }
    }
    
    private func loadInstalledApps() {
        // Get both user-installed and system applications
        let userAppURLs = FileManager.default.urls(for: .applicationDirectory, in: .localDomainMask)
        let systemAppURLs = FileManager.default.urls(for: .applicationDirectory, in: .systemDomainMask)
        let allAppURLs = userAppURLs + systemAppURLs
        
        let apps = allAppURLs.flatMap { baseURL -> [URL] in
            let enumerator = FileManager.default.enumerator(
                at: baseURL,
                includingPropertiesForKeys: [.isApplicationKey],
                options: [.skipsHiddenFiles, .skipsPackageDescendants]
            )
            
            return enumerator?.compactMap { item -> URL? in
                guard let url = item as? URL,
                      url.pathExtension == "app" else { return nil }
                return url
            } ?? []
        }
        
        installedApps = apps.compactMap { url in
            guard let bundle = Bundle(url: url),
                  let bundleId = bundle.bundleIdentifier,
                  let name = (bundle.infoDictionary?["CFBundleName"] as? String) ??
                            (bundle.infoDictionary?["CFBundleDisplayName"] as? String) else {
                return nil
            }
            
            let icon = NSWorkspace.shared.icon(forFile: url.path)
            return (url: url, name: name, bundleId: bundleId, icon: icon)
        }
        .sorted { $0.name.localizedCaseInsensitiveCompare($1.name) == .orderedAscending }
    }
    
    private func saveConfiguration() {
        if isAIEnhancementEnabled && selectedPromptId == nil {
            selectedPromptId = enhancementService.allPrompts.first?.id
        }
        
        switch mode {
        case .add:
            if let config = getConfigForForm() {
                powerModeManager.addConfiguration(config)
            }
        case .edit(let config), .editDefault(let config):
            var updatedConfig = config
            updatedConfig.isAIEnhancementEnabled = isAIEnhancementEnabled
            updatedConfig.selectedPrompt = selectedPromptId?.uuidString
            
            // Update URL configurations if this is a website config
            if configurationType == .website {
                let urlConfig = URLConfig(url: cleanURL(websiteURL), promptId: selectedPromptId?.uuidString)
                updatedConfig.urlConfigs = [urlConfig]
                updatedConfig.appName = websiteName
            }
            
            powerModeManager.updateConfiguration(updatedConfig)
        }
        
        isPresented = false
    }
    
    private func cleanURL(_ url: String) -> String {
        var cleanedURL = url.lowercased()
            .replacingOccurrences(of: "https://", with: "")
            .replacingOccurrences(of: "http://", with: "")
            .replacingOccurrences(of: "www.", with: "")
        
        // Remove trailing slash if present
        if cleanedURL.last == "/" {
            cleanedURL.removeLast()
        }
        
        return cleanedURL
    }
}

// Main View
struct PowerModeView: View {
    @StateObject private var powerModeManager = PowerModeManager.shared
    @EnvironmentObject private var enhancementService: AIEnhancementService
    @State private var showingConfigSheet = false {
        didSet {
            print("üîç showingConfigSheet changed to: \(showingConfigSheet)")
        }
    }
    @State private var configurationMode: ConfigurationMode? {
        didSet {
            print("üîç configurationMode changed to: \(String(describing: configurationMode))")
        }
    }
    
    var body: some View {
        ScrollView {
            VStack(spacing: 32) {
                // Video CTA Section
                VideoCTAView(
                    url: "https://dub.sh/powermode",
                    subtitle: "See Power Mode in action"
                )
                
                // Power Mode Toggle Section
                VStack(alignment: .leading, spacing: 16) {
                    HStack {
                        Text("Enable Power Mode")
                            .font(.headline)
                        Spacer()
                        Toggle("", isOn: $powerModeManager.isPowerModeEnabled)
                            .toggleStyle(SwitchToggleStyle(tint: .blue))
                            .labelsHidden()
                            .scaleEffect(1.2)
                            .onChange(of: powerModeManager.isPowerModeEnabled) { _ in
                                powerModeManager.savePowerModeEnabled()
                            }
                    }
                }
                .padding(.horizontal)
                
                if powerModeManager.isPowerModeEnabled {
                    // Default Configuration Section
                    VStack(alignment: .leading, spacing: 16) {
                        Text("Default Configuration")
                            .font(.headline)
                        
                        ConfiguredAppRow(
                            config: powerModeManager.defaultConfig,
                            isEditing: configurationMode?.isEditingDefault ?? false,
                            action: { 
                                configurationMode = .editDefault(powerModeManager.defaultConfig)
                                showingConfigSheet = true
                            }
                        )
                        .background(RoundedRectangle(cornerRadius: 8)
                            .fill(Color(.windowBackgroundColor).opacity(0.4)))
                        .overlay(RoundedRectangle(cornerRadius: 8)
                            .stroke(Color.accentColor.opacity(0.2), lineWidth: 1))
                    }
                    .padding(.horizontal)
                    
                    // Apps Section
                    VStack(spacing: 16) {
                        if powerModeManager.configurations.isEmpty {
                            PowerModeEmptyStateView(
                                showAddModal: $showingConfigSheet,
                                configMode: $configurationMode
                            )
                        } else {
                            Text("Power Mode Configurations")
                                .font(.headline)
                                .frame(maxWidth: .infinity, alignment: .leading)
                                .padding(.horizontal)
                            
                            ConfiguredAppsGrid(powerModeManager: powerModeManager)
                            
                            Button(action: { 
                                print("üîç Add button clicked - Setting config mode and showing sheet")
                                configurationMode = .add
                                print("üîç Configuration mode set to: \(String(describing: configurationMode))")
                                showingConfigSheet = true
                                print("üîç showingConfigSheet set to: \(showingConfigSheet)")
                            }) {
                                HStack(spacing: 6) {
                                    Image(systemName: "plus")
                                        .font(.system(size: 12, weight: .semibold))
                                    Text("Add New Mode")
                                        .font(.system(size: 13, weight: .medium))
                                }
                            }
                            .buttonStyle(.borderedProminent)
                            .controlSize(.regular)
                            .tint(Color(NSColor.controlAccentColor))
                            .frame(maxWidth: .infinity, alignment: .center)
                            .help("Add a new mode")
                            .padding(.top, 12)
                        }
                    }
                }
            }
            .padding(24)
        }
        .background(Color(NSColor.controlBackgroundColor))
        .sheet(isPresented: $showingConfigSheet, onDismiss: { 
            print("üîç Sheet dismissed - Clearing configuration mode")
            configurationMode = nil 
        }) {
            Group {
                if let mode = configurationMode {
                    ConfigurationSheet(
                        mode: mode,
                        isPresented: $showingConfigSheet,
                        powerModeManager: powerModeManager
                    )
                    .environmentObject(enhancementService)
                    .onAppear {
                        print("üîç Creating ConfigurationSheet with mode: \(mode)")
                    }
                }
            }
        }
    }
}

================
File: VoiceInk/Views/PowerModeViewComponents.swift
================
import SwiftUI
// Supporting Views
struct PowerModeEmptyStateView: View {
    @Binding var showAddModal: Bool
    @Binding var configMode: ConfigurationMode?
    
    var body: some View {
        VStack(spacing: 16) {
            Image(systemName: "bolt.circle.fill")
                .font(.system(size: 48))
                .foregroundColor(.secondary)
            
            Text("No Applications Configured")
                .font(.title2)
                .fontWeight(.semibold)
            
            Text("Add applications to customize their AI enhancement settings.")
                .foregroundColor(.secondary)
                .multilineTextAlignment(.center)
            
            Button(action: { 
                print("üîç Empty state Add Application button clicked")
                configMode = .add
                print("üîç Configuration mode set to: \(String(describing: configMode))")
                showAddModal = true 
                print("üîç Empty state showAddModal set to: \(showAddModal)")
            }) {
                Label("Add Application", systemImage: "plus.circle.fill")
                    .font(.headline)
            }
            .buttonStyle(.borderedProminent)
        }
        .frame(maxWidth: .infinity, maxHeight: .infinity)
        
    }
}

struct ConfiguredAppsGrid: View {
    @ObservedObject var powerModeManager: PowerModeManager
    @EnvironmentObject var enhancementService: AIEnhancementService
    @State private var editingConfig: PowerModeConfig?
    @State private var showingConfigSheet = false
    
    var body: some View {
        ScrollView {
            VStack(spacing: 8) {
                ForEach(powerModeManager.configurations.sorted(by: { $0.appName.localizedCaseInsensitiveCompare($1.appName) == .orderedAscending })) { config in
                    ConfiguredAppRow(
                        config: config,
                        isEditing: editingConfig?.id == config.id,
                        action: { 
                            editingConfig = config
                            showingConfigSheet = true
                        }
                    )
                    .contextMenu {
                        Button(action: { 
                            editingConfig = config
                            showingConfigSheet = true
                        }) {
                            Label("Edit", systemImage: "pencil")
                        }
                        Button(role: .destructive, action: {
                            powerModeManager.removeConfiguration(for: config.bundleIdentifier)
                        }) {
                            Label("Remove", systemImage: "trash")
                        }
                    }
                }
            }
            .padding()
        }
        .sheet(isPresented: $showingConfigSheet, onDismiss: { editingConfig = nil }) {
            if let config = editingConfig {
                ConfigurationSheet(
                    mode: .edit(config),
                    isPresented: $showingConfigSheet,
                    powerModeManager: powerModeManager
                )
                .environmentObject(enhancementService)
            }
        }
    }
}

struct ConfiguredAppRow: View {
    let config: PowerModeConfig
    let isEditing: Bool
    let action: () -> Void
    @EnvironmentObject var enhancementService: AIEnhancementService
    
    private var selectedPrompt: CustomPrompt? {
        guard let promptId = config.selectedPrompt,
              let uuid = UUID(uuidString: promptId) else { return nil }
        return enhancementService.allPrompts.first { $0.id == uuid }
    }
    
    private var isWebsiteConfig: Bool {
        return config.urlConfigs != nil && !config.urlConfigs!.isEmpty
    }
    
    var body: some View {
        Button(action: action) {
            HStack(spacing: 12) {
                // Icon
                if isWebsiteConfig {
                    Image(systemName: "globe")
                        .resizable()
                        .aspectRatio(contentMode: .fit)
                        .frame(width: 32, height: 32)
                        .foregroundColor(.accentColor)
                } else if let appURL = NSWorkspace.shared.urlForApplication(withBundleIdentifier: config.bundleIdentifier) {
                    Image(nsImage: NSWorkspace.shared.icon(forFile: appURL.path))
                        .resizable()
                        .frame(width: 32, height: 32)
                }
                
                // Info
                VStack(alignment: .leading, spacing: 2) {
                    Text(config.appName)
                        .font(.headline)
                    if isWebsiteConfig {
                        if let urlConfig = config.urlConfigs?.first {
                            Text(urlConfig.url)
                                .font(.caption)
                                .foregroundColor(.secondary)
                        }
                    } else {
                        Text(config.bundleIdentifier)
                            .font(.caption)
                            .foregroundColor(.secondary)
                    }
                }
                
                Spacer()
                
                HStack(spacing: 8) {
                    HStack(spacing: 4) {
                        Image(systemName: config.isAIEnhancementEnabled ? "checkmark.circle.fill" : "circle")
                            .foregroundColor(config.isAIEnhancementEnabled ? .accentColor : .secondary)
                            .font(.system(size: 14))
                        Text("AI Enhancement")
                            .font(.system(size: 12, weight: .medium))
                            .foregroundColor(config.isAIEnhancementEnabled ? .accentColor : .secondary)
                    }
                    .padding(.horizontal, 8)
                    .padding(.vertical, 4)
                    .background(RoundedRectangle(cornerRadius: 6)
                        .fill(config.isAIEnhancementEnabled ? Color.accentColor.opacity(0.1) : Color.secondary.opacity(0.1)))
                    
                    if config.isAIEnhancementEnabled {
                        if let prompt = selectedPrompt {
                            HStack(spacing: 4) {
                                Image(systemName: prompt.icon.rawValue)
                                    .foregroundColor(.accentColor)
                                    .font(.system(size: 14))
                                Text(prompt.title)
                                    .font(.system(size: 12))
                                    .foregroundColor(.secondary)
                            }
                            .padding(.horizontal, 8)
                            .padding(.vertical, 4)
                            .background(RoundedRectangle(cornerRadius: 6)
                                .fill(Color.accentColor.opacity(0.1)))
                        } else {
                            Text("No Prompt")
                                .font(.system(size: 12))
                                .foregroundColor(.secondary)
                                .padding(.horizontal, 8)
                                .padding(.vertical, 4)
                                .background(RoundedRectangle(cornerRadius: 6)
                                    .fill(Color.secondary.opacity(0.1)))
                        }
                    }
                }
            }
            .contentShape(Rectangle())
            .padding(12)
            .background(RoundedRectangle(cornerRadius: 8)
                .fill(isEditing ? Color.accentColor.opacity(0.1) : Color(.windowBackgroundColor).opacity(0.4)))
            .overlay(RoundedRectangle(cornerRadius: 8)
                .stroke(isEditing ? Color.accentColor : Color.clear, lineWidth: 1))
        }
        .buttonStyle(.plain)
    }
}

struct AppConfigurationFormView: View {
    let appName: String?
    let appIcon: NSImage?
    let isDefaultConfig: Bool
    @Binding var isAIEnhancementEnabled: Bool
    @Binding var selectedPromptId: UUID?
    @EnvironmentObject var enhancementService: AIEnhancementService
    
    var body: some View {
        VStack(spacing: 20) {
            VStack(spacing: 16) {
                if !isDefaultConfig {
                    if let appIcon = appIcon {
                        HStack {
                            Image(nsImage: appIcon)
                                .resizable()
                                .frame(width: 32, height: 32)
                            Text(appName ?? "")
                                .font(.headline)
                            Spacer()
                        }
                    }
                } else {
                    HStack {
                        Image(systemName: "gearshape.fill")
                            .font(.system(size: 24))
                            .foregroundColor(.accentColor)
                        Text("Default Settings")
                            .font(.headline)
                        Spacer()
                    }
                    
                    Text("These settings will be applied to all applications that don't have specific configurations.")
                        .font(.subheadline)
                        .foregroundColor(.secondary)
                        .padding(.bottom, 8)
                }
                
                Toggle("AI Enhancement", isOn: $isAIEnhancementEnabled)
            }
            .padding(.horizontal)
            
            if isAIEnhancementEnabled {
                Divider()
                
                VStack(alignment: .leading) {
                    Text("Select Prompt")
                        .font(.headline)
                        .padding(.horizontal)
                    
                    let columns = [
                        GridItem(.adaptive(minimum: 80, maximum: 100), spacing: 36)
                    ]
                    
                    LazyVGrid(columns: columns, spacing: 24) {
                        ForEach(enhancementService.allPrompts) { prompt in
                            prompt.promptIcon(
                                isSelected: selectedPromptId == prompt.id,
                                onTap: { selectedPromptId = prompt.id }
                            )
                        }
                    }
                    .padding(.vertical, 12)
                    .padding(.horizontal, 16)
                }
            }
        }
        .padding(.vertical)
    }
}

struct AppGridItem: View {
    let app: (url: URL, name: String, bundleId: String, icon: NSImage)
    let isSelected: Bool
    let action: () -> Void
    
    var body: some View {
        Button(action: action) {
            VStack(spacing: 8) {
                Image(nsImage: app.icon)
                    .resizable()
                    .frame(width: 48, height: 48)
                Text(app.name)
                    .font(.system(size: 12))
                    .lineLimit(2)
                    .multilineTextAlignment(.center)
                    .frame(height: 32)
            }
            .frame(width: 100)
            .padding(8)
            .background(RoundedRectangle(cornerRadius: 8)
                .fill(isSelected ? Color.accentColor.opacity(0.1) : Color.clear))
            .overlay(RoundedRectangle(cornerRadius: 8)
                .stroke(isSelected ? Color.accentColor : Color.clear, lineWidth: 1))
        }
        .buttonStyle(.plain)
    }
}

// New component for feature highlights
struct FeatureHighlight: View {
    let icon: String
    let title: String
    let description: String
    
    var body: some View {
        VStack(alignment: .leading, spacing: 8) {
            HStack(spacing: 6) {
                Image(systemName: icon)
                    .font(.system(size: 14, weight: .semibold))
                    .foregroundStyle(.blue)
                Text(title)
                    .font(.system(size: 13, weight: .semibold))
            }
            
            Text(description)
                .font(.system(size: 12))
                .foregroundColor(.secondary)
                .lineLimit(2)
        }
        .frame(maxWidth: .infinity, alignment: .leading)
    }
}

================
File: VoiceInk/Views/PromptEditorView.swift
================
import SwiftUI

struct PromptEditorView: View {
    enum Mode {
        case add
        case edit(CustomPrompt)
        
        static func == (lhs: Mode, rhs: Mode) -> Bool {
            switch (lhs, rhs) {
            case (.add, .add):
                return true
            case let (.edit(prompt1), .edit(prompt2)):
                return prompt1.id == prompt2.id
            default:
                return false
            }
        }
    }
    
    let mode: Mode
    @Environment(\.dismiss) private var dismiss
    @EnvironmentObject private var enhancementService: AIEnhancementService
    @State private var title: String
    @State private var promptText: String
    @State private var selectedIcon: PromptIcon
    @State private var description: String
    @State private var showingPredefinedPrompts = false
    
    init(mode: Mode) {
        self.mode = mode
        switch mode {
        case .add:
            _title = State(initialValue: "")
            _promptText = State(initialValue: "")
            _selectedIcon = State(initialValue: .documentFill)
            _description = State(initialValue: "")
        case .edit(let prompt):
            _title = State(initialValue: prompt.title)
            _promptText = State(initialValue: prompt.promptText)
            _selectedIcon = State(initialValue: prompt.icon)
            _description = State(initialValue: prompt.description ?? "")
        }
    }
    
    var body: some View {
        VStack(spacing: 0) {
            // Header with modern styling
            HStack {
                Text(mode == .add ? "New Mode" : "Edit Mode")
                    .font(.title2)
                    .fontWeight(.bold)
                Spacer()
                HStack(spacing: 12) {
                    Button("Cancel") {
                        dismiss()
                    }
                    .buttonStyle(.plain)
                    .foregroundColor(.secondary)
                    
                    Button {
                        save()
                        dismiss()
                    } label: {
                        Text("Save")
                            .fontWeight(.medium)
                    }
                    .buttonStyle(.borderedProminent)
                    .disabled(title.isEmpty || promptText.isEmpty)
                    .keyboardShortcut(.return, modifiers: .command)
                }
            }
            .padding()
            .background(
                Color(NSColor.windowBackgroundColor)
                    .shadow(color: .black.opacity(0.1), radius: 8, y: 2)
            )
            
            ScrollView {
                VStack(spacing: 24) {
                    // Title and Icon Section with improved layout
                    HStack(spacing: 20) {
                        // Title Field
                        VStack(alignment: .leading, spacing: 8) {
                            Text("Title")
                                .font(.headline)
                                .foregroundColor(.secondary)
                            TextField("Enter a short, descriptive title", text: $title)
                                .textFieldStyle(.roundedBorder)
                                .font(.body)
                        }
                        .frame(maxWidth: .infinity)
                        
                        // Icon Selector with preview
                        VStack(alignment: .leading, spacing: 8) {
                            Text("Icon")
                                .font(.headline)
                                .foregroundColor(.secondary)
                            
                            Menu {
                                IconMenuContent(selectedIcon: $selectedIcon)
                            } label: {
                                HStack {
                                    Image(systemName: selectedIcon.rawValue)
                                        .font(.system(size: 16))
                                        .foregroundColor(.accentColor)
                                        .frame(width: 24)
                                    
                                    Text(selectedIcon.title)
                                        .foregroundColor(.primary)
                                    
                                    Spacer()
                                    
                                    Image(systemName: "chevron.up.chevron.down")
                                        .font(.system(size: 12))
                                        .foregroundColor(.secondary)
                                }
                                .padding(8)
                                .background(Color(NSColor.controlBackgroundColor))
                                .cornerRadius(8)
                            }
                            .frame(width: 180)
                        }
                    }
                    .padding(.horizontal)
                    .padding(.top, 8)
                    
                    // Description Field
                    VStack(alignment: .leading, spacing: 8) {
                        Text("Description")
                            .font(.headline)
                            .foregroundColor(.secondary)
                        
                        Text("Add a brief description of what this mode does")
                            .font(.subheadline)
                            .foregroundColor(.secondary)
                        
                        TextField("Enter a description", text: $description)
                            .textFieldStyle(.roundedBorder)
                            .font(.body)
                    }
                    .padding(.horizontal)
                    
                    // Prompt Text Section with improved styling
                    VStack(alignment: .leading, spacing: 8) {
                        Text("Mode Instructions")
                            .font(.headline)
                            .foregroundColor(.secondary)
                        
                        Text("Define how AI should enhance your transcriptions")
                            .font(.subheadline)
                            .foregroundColor(.secondary)
                        
                        TextEditor(text: $promptText)
                            .font(.system(.body, design: .monospaced))
                            .frame(minHeight: 200)
                            .padding(12)
                            .background(
                                RoundedRectangle(cornerRadius: 8)
                                    .fill(Color(NSColor.textBackgroundColor))
                            )
                            .overlay(
                                RoundedRectangle(cornerRadius: 8)
                                    .stroke(Color.secondary.opacity(0.2), lineWidth: 1)
                            )
                    }
                    .padding(.horizontal)
                    
                    if case .add = mode {
                        // Templates Section with improved styling
                        VStack(alignment: .leading, spacing: 12) {
                            Text("Start with a Predefined Template")
                                .font(.headline)
                                .foregroundColor(.secondary)
                            
                            Text("Scroll horizontally to see more templates")
                                .font(.subheadline)
                                .foregroundColor(.secondary)
                            
                            ScrollView(.horizontal, showsIndicators: false) {
                                HStack(spacing: 16) {
                                    ForEach(PromptTemplates.all) { template in
                                        TemplateButton(prompt: template) {
                                            title = template.title
                                            promptText = template.promptText
                                            selectedIcon = template.icon
                                            description = template.description
                                        }
                                    }
                                }
                                .padding(.horizontal, 2)
                                .padding(.bottom, 2)
                            }
                            .scrollClipDisabled(true)
                        }
                        .padding(.horizontal)
                    }
                }
                .padding(.vertical, 20)
            }
        }
        .frame(minWidth: 600, minHeight: 500)
    }
    
    private func save() {
        switch mode {
        case .add:
            enhancementService.addPrompt(
                title: title,
                promptText: promptText,
                icon: selectedIcon,
                description: description.isEmpty ? nil : description
            )
        case .edit(let prompt):
            let updatedPrompt = CustomPrompt(
                id: prompt.id,
                title: title,
                promptText: promptText,
                isActive: prompt.isActive,
                icon: selectedIcon,
                description: description.isEmpty ? nil : description
            )
            enhancementService.updatePrompt(updatedPrompt)
        }
    }
}

// Template button with modern styling
struct TemplateButton: View {
    let prompt: TemplatePrompt
    let action: () -> Void
    
    var body: some View {
        Button(action: action) {
            VStack(alignment: .leading, spacing: 8) {
                HStack {
                    Image(systemName: prompt.icon.rawValue)
                        .font(.system(size: 16))
                        .foregroundColor(.accentColor)
                    Text(prompt.title)
                        .fontWeight(.medium)
                }
                
                Text(prompt.description)
                    .font(.caption)
                    .foregroundColor(.secondary)
                    .lineLimit(2)
                    .multilineTextAlignment(.leading)
            }
            .frame(width: 200, alignment: .leading)
            .padding()
            .background(Color(NSColor.controlBackgroundColor))
            .cornerRadius(10)
            .overlay(
                RoundedRectangle(cornerRadius: 10)
                    .stroke(Color.secondary.opacity(0.2), lineWidth: 1)
            )
        }
        .buttonStyle(.plain)
    }
}

// Icon menu content for better organization
struct IconMenuContent: View {
    @Binding var selectedIcon: PromptIcon
    
    var body: some View {
        Group {
            IconMenuSection(title: "Document & Text", icons: [.documentFill, .textbox, .sealedFill], selectedIcon: $selectedIcon)
            IconMenuSection(title: "Communication", icons: [.chatFill, .messageFill, .emailFill], selectedIcon: $selectedIcon)
            IconMenuSection(title: "Professional", icons: [.meetingFill, .presentationFill, .briefcaseFill], selectedIcon: $selectedIcon)
            IconMenuSection(title: "Technical", icons: [.codeFill, .terminalFill, .gearFill], selectedIcon: $selectedIcon)
            IconMenuSection(title: "Content", icons: [.blogFill, .notesFill, .bookFill, .bookmarkFill, .pencilFill], selectedIcon: $selectedIcon)
            IconMenuSection(title: "Media & Creative", icons: [.videoFill, .micFill, .musicFill, .photoFill, .brushFill], selectedIcon: $selectedIcon)
        }
    }
}

// Icon menu section for better organization
struct IconMenuSection: View {
    let title: String
    let icons: [PromptIcon]
    @Binding var selectedIcon: PromptIcon
    
    var body: some View {
        Group {
            Text(title)
                .font(.caption)
                .foregroundColor(.secondary)
            ForEach(icons, id: \.self) { icon in
                Button(action: { selectedIcon = icon }) {
                    Label(icon.title, systemImage: icon.rawValue)
                }
            }
            if title != "Media & Creative" {
                Divider()
            }
        }
    }
}

================
File: VoiceInk/Views/RecordView.swift
================
import SwiftUI
import KeyboardShortcuts
import AppKit

struct RecordView: View {
    @EnvironmentObject var whisperState: WhisperState
    @EnvironmentObject var hotkeyManager: HotkeyManager
    @Environment(\.colorScheme) private var colorScheme
    @ObservedObject private var mediaController = MediaController.shared
    
    private var hasShortcutSet: Bool {
        KeyboardShortcuts.getShortcut(for: .toggleMiniRecorder) != nil
    }
    
    var body: some View {
        ScrollView(showsIndicators: false) {
            mainContent
        }
        .background(Color(.controlBackgroundColor).opacity(0.5))
    }
    
    private var mainContent: some View {
        VStack(spacing: 48) {
            heroSection
            controlsSection
        }
        .padding(32)
    }
    
    private var heroSection: some View {
        VStack(spacing: 20) {
            appIconView
            titleSection
        }
    }
    
    private var appIconView: some View {
        ZStack {
            Circle()
                .fill(Color.accentColor.opacity(0.15))
                .frame(width: 160, height: 160)
                .blur(radius: 30)
            
            if let image = NSImage(named: "AppIcon") {
                Image(nsImage: image)
                    .resizable()
                    .aspectRatio(contentMode: .fit)
                    .frame(width: 120, height: 120)
                    .cornerRadius(30)
                    .overlay(
                        RoundedRectangle(cornerRadius: 30)
                            .stroke(.white.opacity(0.2), lineWidth: 1)
                    )
                    .shadow(color: .accentColor.opacity(0.3), radius: 20)
            }
        }
    }
    
    private var titleSection: some View {
        VStack(spacing: 8) {
            Text("VOICEINK")
                .font(.system(size: 42, weight: .bold))
            
            if whisperState.currentModel != nil {
                Text("Powered by Whisper AI")
                    .font(.system(size: 15))
                    .foregroundColor(.secondary)
            }
        }
    }
    
    private var controlsSection: some View {
        VStack(spacing: 32) {
            compactControlsCard
            instructionsCard
        }
    }
    
    private var compactControlsCard: some View {
        HStack(spacing: 32) {
            shortcutSection
            
            if hasShortcutSet {
                Divider()
                    .frame(height: 40)
                pushToTalkSection
                
                Divider()
                    .frame(height: 40)
                
                // Settings section
                VStack(alignment: .leading, spacing: 12) {
                    Toggle(isOn: $whisperState.isAutoCopyEnabled) {
                        HStack {
                            Image(systemName: "doc.on.clipboard")
                                .foregroundColor(.secondary)
                            Text("Auto-copy to clipboard")
                                .font(.subheadline.weight(.medium))
                        }
                    }
                    .toggleStyle(.switch)
                    
                    Toggle(isOn: .init(
                        get: { SoundManager.shared.isEnabled },
                        set: { SoundManager.shared.isEnabled = $0 }
                    )) {
                        HStack {
                            Image(systemName: "speaker.wave.2")
                                .foregroundColor(.secondary)
                            Text("Sound feedback")
                                .font(.subheadline.weight(.medium))
                        }
                    }
                    .toggleStyle(.switch)
                    
                    Toggle(isOn: $mediaController.isMediaPauseEnabled) {
                        HStack {
                            Image(systemName: "play.slash")
                                .foregroundColor(.secondary)
                            Text("Pause media during recording")
                                .font(.subheadline.weight(.medium))
                        }
                    }
                    .toggleStyle(.switch)
                    .help("Automatically pause music playback when recording starts and resume when recording stops")
                }
            }
        }
        .padding(24)
    }
    
    private var shortcutSection: some View {
        VStack(spacing: 12) {
            if hasShortcutSet {
                if let shortcut = KeyboardShortcuts.getShortcut(for: .toggleMiniRecorder) {
                    KeyboardShortcutView(shortcut: shortcut)
                        .scaleEffect(1.2)
                }
            } else {
                Image(systemName: "keyboard.badge.exclamationmark")
                    .font(.system(size: 28))
                    .foregroundColor(.orange)
            }
            
            Button(action: {
                NotificationCenter.default.post(
                    name: .navigateToDestination,
                    object: nil,
                    userInfo: ["destination": "Settings"]
                )
            }) {
                Text(hasShortcutSet ? "Change" : "Set Shortcut")
                    .font(.subheadline.weight(.medium))
                    .foregroundColor(.accentColor)
            }
            .buttonStyle(.plain)
        }
    }
    
    private var pushToTalkSection: some View {
        VStack(alignment: .leading, spacing: 12) {
            Toggle(isOn: $hotkeyManager.isPushToTalkEnabled) {
                Text("Push-to-Talk")
                    .font(.subheadline.weight(.medium))
            }
            .toggleStyle(.switch)
            
            if hotkeyManager.isPushToTalkEnabled {
                pushToTalkOptions
            }
        }
    }
    
    private var pushToTalkOptions: some View {
        VStack(alignment: .leading, spacing: 8) {
            PushToTalkKeySelector(selectedKey: $hotkeyManager.pushToTalkKey)
            
            HStack(spacing: 6) {
                Image(systemName: "arrow.left.arrow.right.circle.fill")
                    .foregroundColor(.secondary)
                    .font(.system(size: 12))
                Text("Click to switch")
                    .font(.caption)
                    .foregroundColor(.secondary)
            }
        }
    }
    
    private var instructionsCard: some View {
        VStack(alignment: .leading, spacing: 28) {
            Text("How it works")
                .font(.title3.weight(.bold))
            
            VStack(alignment: .leading, spacing: 24) {
                ForEach(getInstructions(), id: \.title) { instruction in
                    InstructionRow(instruction: instruction)
                }
                
                Divider()
                    .padding(.vertical, 4)
                
                afterRecordingSection
            }
        }
        .padding(28)
        .background(
            RoundedRectangle(cornerRadius: 16)
                .fill(Color(.windowBackgroundColor).opacity(0.4))
                
        )
    }
    
    private var afterRecordingSection: some View {
        VStack(alignment: .leading, spacing: 16) {
            Text("After recording")
                .font(.headline)
            
            VStack(alignment: .leading, spacing: 12) {
                InfoRow(icon: "doc.on.clipboard", text: "Copied to clipboard")
                InfoRow(icon: "text.cursor", text: "Pasted at cursor position")
            }
        }
    }
    
    private func getInstructions() -> [(icon: String, title: String, description: String)] {
        let keyName: String
        switch hotkeyManager.pushToTalkKey {
        case .rightOption:
            keyName = "right Option (‚å•)"
        case .fn:
            keyName = "Fn"
        case .rightCommand:
            keyName = "right Command (‚åò)"
        case .rightShift:
            keyName = "right Shift (‚áß)"
        }
        
        let activateDescription = hotkeyManager.isPushToTalkEnabled ?
            "Hold the \(keyName) key" :
            "Press your configured shortcut"
        
        let finishDescription = hotkeyManager.isPushToTalkEnabled ?
            "Release the \(keyName) key to stop and process" :
            "Press the shortcut again to stop"
        
        return [
            (
                icon: "mic.circle.fill",
                title: "Start Recording",
                description: activateDescription
            ),
            (
                icon: "waveform",
                title: "Speak Clearly",
                description: "Talk into your microphone naturally"
            ),
            (
                icon: "stop.circle.fill",
                title: "Finish Up",
                description: finishDescription
            )
        ]
    }
}

// Simplified InstructionRow
struct InstructionRow: View {
    let instruction: (icon: String, title: String, description: String)
    
    var body: some View {
        HStack(alignment: .top, spacing: 16) {
            Image(systemName: instruction.icon)
                .font(.system(size: 20))
                .foregroundColor(.accentColor)
                .frame(width: 24)
            
            VStack(alignment: .leading, spacing: 4) {
                Text(instruction.title)
                    .font(.subheadline.weight(.medium))
                Text(instruction.description)
                    .font(.subheadline)
                    .foregroundColor(.secondary)
                    .fixedSize(horizontal: false, vertical: true)
            }
        }
    }
}

// Simplified InfoRow
struct InfoRow: View {
    let icon: String
    let text: String
    
    var body: some View {
        HStack(spacing: 12) {
            Image(systemName: icon)
                .font(.system(size: 14))
                .foregroundColor(.secondary)
            Text(text)
                .font(.subheadline)
                .foregroundColor(.secondary)
        }
    }
}

================
File: VoiceInk/Views/TranscriptionCard.swift
================
import SwiftUI
import SwiftData

struct TranscriptionCard: View {
    let transcription: Transcription
    let isExpanded: Bool
    let isSelected: Bool
    let onDelete: () -> Void
    let onToggleSelection: () -> Void
    @State private var showOriginalCopiedAlert = false
    @State private var showEnhancedCopiedAlert = false
    
    var body: some View {
        HStack(spacing: 12) {
            // Selection checkbox in macOS style
            Toggle("", isOn: Binding(
                get: { isSelected },
                set: { _ in onToggleSelection() }
            ))
            .toggleStyle(CircularCheckboxStyle())
            .labelsHidden()
            
            VStack(alignment: .leading, spacing: 8) {
                // Header with date and duration
                HStack {
                    Text(transcription.timestamp, style: .date)
                        .font(.system(size: 14, weight: .medium, design: .default))
                        .foregroundColor(.secondary)
                    Spacer()
                    
                    Text(formatDuration(transcription.duration))
                        .font(.system(size: 14, weight: .medium, design: .default))
                        .padding(.horizontal, 8)
                        .padding(.vertical, 4)
                        .background(Color.blue.opacity(0.1))
                        .foregroundColor(.blue)
                        .cornerRadius(6)
                }
                
                // Original text section
                VStack(alignment: .leading, spacing: 8) {
                    if isExpanded {
                        HStack {
                            Text("Original")
                                .font(.system(size: 14, weight: .medium))
                                .foregroundColor(.secondary)
                            Spacer()
                            Button {
                                copyToClipboard(transcription.text)
                                showOriginalCopiedAlert = true
                            } label: {
                                HStack(spacing: 4) {
                                    Image(systemName: showOriginalCopiedAlert ? "checkmark" : "doc.on.doc")
                                    Text(showOriginalCopiedAlert ? "Copied" : "Copy")
                                }
                                .foregroundColor(showOriginalCopiedAlert ? .green : .blue)
                                .padding(.horizontal, 8)
                                .padding(.vertical, 4)
                                .background(Color.blue.opacity(0.1))
                                .cornerRadius(6)
                            }
                            .buttonStyle(.plain)
                        }
                    }
                    
                    Text(transcription.text)
                        .font(.system(size: 15, weight: .regular, design: .default))
                        .lineLimit(isExpanded ? nil : 2)
                        .lineSpacing(2)
                }
                
                // Enhanced text section (only when expanded)
                if isExpanded, let enhancedText = transcription.enhancedText {
                    Divider()
                        .padding(.vertical, 8)
                    
                    VStack(alignment: .leading, spacing: 8) {
                        HStack {
                            HStack(spacing: 4) {
                                Image(systemName: "sparkles")
                                    .foregroundColor(.blue)
                                Text("Enhanced")
                                    .font(.system(size: 14, weight: .medium))
                                    .foregroundColor(.blue)
                            }
                            Spacer()
                            Button {
                                copyToClipboard(enhancedText)
                                showEnhancedCopiedAlert = true
                            } label: {
                                HStack(spacing: 4) {
                                    Image(systemName: showEnhancedCopiedAlert ? "checkmark" : "doc.on.doc")
                                    Text(showEnhancedCopiedAlert ? "Copied" : "Copy")
                                }
                                .foregroundColor(showEnhancedCopiedAlert ? .green : .blue)
                                .padding(.horizontal, 8)
                                .padding(.vertical, 4)
                                .background(Color.blue.opacity(0.1))
                                .cornerRadius(6)
                            }
                            .buttonStyle(.plain)
                        }
                        
                        Text(enhancedText)
                            .font(.system(size: 15, weight: .regular, design: .default))
                            .lineSpacing(2)
                    }
                }
                
                // Audio player (if available)
                if isExpanded, let urlString = transcription.audioFileURL,
                   let url = URL(string: urlString),
                   FileManager.default.fileExists(atPath: url.path) {
                    Divider()
                        .padding(.vertical, 8)
                    AudioPlayerView(url: url)
                }
                
                // Timestamp (only when expanded)
                if isExpanded {
                    HStack {
                        Text(transcription.timestamp, style: .time)
                            .font(.system(size: 14, weight: .regular, design: .default))
                            .foregroundColor(.secondary)
                        Spacer()
                    }
                    .padding(.top, 4)
                }
            }
        }
        .padding(16)
        .background(
            RoundedRectangle(cornerRadius: 12)
                .fill(Color(.windowBackgroundColor).opacity(0.4))
        )
        .cornerRadius(12)
        .shadow(color: Color.black.opacity(0.05), radius: 3, x: 0, y: 2)
        .contextMenu {
            if let enhancedText = transcription.enhancedText {
                Button {
                    copyToClipboard(enhancedText)
                    showEnhancedCopiedAlert = true
                } label: {
                    Label("Copy Enhanced", systemImage: "doc.on.doc")
                }
            }
            
            Button {
                copyToClipboard(transcription.text)
                showOriginalCopiedAlert = true
            } label: {
                Label("Copy Original", systemImage: "doc.on.doc")
            }
            
            Button(role: .destructive) {
                onDelete()
            } label: {
                Label("Delete", systemImage: "trash")
            }
        }
        .onChange(of: showOriginalCopiedAlert) { _, isShowing in
            if isShowing {
                DispatchQueue.main.asyncAfter(deadline: .now() + 1.5) {
                    showOriginalCopiedAlert = false
                }
            }
        }
        .onChange(of: showEnhancedCopiedAlert) { _, isShowing in
            if isShowing {
                DispatchQueue.main.asyncAfter(deadline: .now() + 1.5) {
                    showEnhancedCopiedAlert = false
                }
            }
        }
    }
    
    private func copyToClipboard(_ text: String) {
        let success = ClipboardManager.copyToClipboard(text)
        if !success {
            print("Failed to copy text to clipboard")
        }
    }
    
    private func formatDuration(_ duration: TimeInterval) -> String {
        let minutes = Int(duration) / 60
        let seconds = Int(duration) % 60
        return String(format: "%d:%02d", minutes, seconds)
    }
}

================
File: VoiceInk/Views/TranscriptionHistoryView.swift
================
import SwiftUI
import SwiftData

struct TranscriptionHistoryView: View {
    @Environment(\.modelContext) private var modelContext
    @State private var searchText = ""
    @State private var expandedTranscription: Transcription?
    @State private var selectedTranscriptions: Set<Transcription> = []
    @State private var showDeleteConfirmation = false
    
    // Pagination states
    @State private var displayedTranscriptions: [Transcription] = []
    @State private var isLoading = false
    @State private var hasMoreContent = true
    
    // Cursor-based pagination - track the last timestamp
    @State private var lastTimestamp: Date?
    private let pageSize = 20
    
    // Query for latest transcriptions (used for real-time updates)
    @Query(sort: \Transcription.timestamp, order: .reverse) 
    private var latestTranscriptions: [Transcription]
    
    // Cursor-based query descriptor
    private func cursorQueryDescriptor(after timestamp: Date? = nil) -> FetchDescriptor<Transcription> {
        var descriptor = FetchDescriptor<Transcription>(
            sortBy: [SortDescriptor(\Transcription.timestamp, order: .reverse)]
        )
        
        // Build the predicate based on search text and timestamp cursor
        if let timestamp = timestamp {
            if !searchText.isEmpty {
                descriptor.predicate = #Predicate<Transcription> { transcription in
                    (transcription.text.localizedStandardContains(searchText) ||
                    (transcription.enhancedText?.localizedStandardContains(searchText) ?? false)) &&
                    transcription.timestamp < timestamp
                }
            } else {
                descriptor.predicate = #Predicate<Transcription> { transcription in
                    transcription.timestamp < timestamp
                }
            }
        } else if !searchText.isEmpty {
            descriptor.predicate = #Predicate<Transcription> { transcription in
                transcription.text.localizedStandardContains(searchText) ||
                (transcription.enhancedText?.localizedStandardContains(searchText) ?? false)
            }
        }
        
        descriptor.fetchLimit = pageSize
        return descriptor
    }
    
    var body: some View {
        ZStack(alignment: .bottom) {
            VStack(spacing: 0) {
                searchBar
                
                if displayedTranscriptions.isEmpty && !isLoading {
                    emptyStateView
                } else {
                    ScrollView {
                        LazyVStack(spacing: 10) {
                            ForEach(displayedTranscriptions) { transcription in
                                TranscriptionCard(
                                    transcription: transcription, 
                                    isExpanded: expandedTranscription == transcription,
                                    isSelected: selectedTranscriptions.contains(transcription),
                                    onDelete: { deleteTranscription(transcription) },
                                    onToggleSelection: { toggleSelection(transcription) }
                                )
                                .onTapGesture {
                                    expandedTranscription = expandedTranscription == transcription ? nil : transcription
                                }
                            }
                            
                            if hasMoreContent {
                                Button(action: {
                                    loadMoreContent()
                                }) {
                                    HStack(spacing: 8) {
                                        if isLoading {
                                            ProgressView()
                                                .controlSize(.small)
                                        }
                                        Text(isLoading ? "Loading..." : "Load More")
                                            .font(.system(size: 14, weight: .medium))
                                    }
                                    .frame(maxWidth: .infinity)
                                    .padding(.vertical, 12)
                                    .background(Color(.windowBackgroundColor).opacity(0.4))
                                    .cornerRadius(8)
                                }
                                .buttonStyle(.plain)
                                .disabled(isLoading)
                                .padding(.top, 12)
                            }
                        }
                        .padding(24)
                        // Add bottom padding to ensure content is not hidden by the toolbar when visible
                        .padding(.bottom, !selectedTranscriptions.isEmpty ? 60 : 0)
                    }
                    .padding(.vertical, 16)
                }
            }
            .background(Color(NSColor.controlBackgroundColor))
            
            // Selection toolbar as an overlay
            if !selectedTranscriptions.isEmpty {
                selectionToolbar
                    .transition(.move(edge: .bottom).combined(with: .opacity))
                    .animation(.easeInOut(duration: 0.3), value: !selectedTranscriptions.isEmpty)
            }
        }
        .alert("Delete Selected Items?", isPresented: $showDeleteConfirmation) {
            Button("Delete", role: .destructive) {
                deleteSelectedTranscriptions()
            }
            Button("Cancel", role: .cancel) {}
        } message: {
            Text("This action cannot be undone. Are you sure you want to delete \(selectedTranscriptions.count) item\(selectedTranscriptions.count == 1 ? "" : "s")?")
        }
        .onAppear {
            Task {
                await loadInitialContent()
            }
        }
        .onChange(of: searchText) { _, _ in
            Task {
                await resetPagination()
                await loadInitialContent()
            }
        }
        // Improved change detection for new transcriptions
        .onChange(of: latestTranscriptions) { oldValue, newValue in
            // Check if a new transcription was added
            if !newValue.isEmpty && (oldValue.isEmpty || newValue[0].id != oldValue[0].id) {
                // Only refresh if we're on the first page (no pagination cursor set)
                if lastTimestamp == nil {
                    Task {
                        await loadInitialContent()
                    }
                } else {
                    // Reset pagination to show the latest content
                    Task {
                        await resetPagination()
                        await loadInitialContent()
                    }
                }
            }
        }
    }
    
    private var searchBar: some View {
        HStack {
            Image(systemName: "magnifyingglass")
                .foregroundColor(.secondary)
            TextField("Search transcriptions", text: $searchText)
                .font(.system(size: 16, weight: .regular, design: .default))
                .textFieldStyle(PlainTextFieldStyle())
        }
        .padding(12)
        .background(Color(.windowBackgroundColor).opacity(0.4))
        .cornerRadius(10)
        .padding(.horizontal, 24)
        .padding(.vertical, 16)
    }
    
    private var emptyStateView: some View {
        VStack(spacing: 20) {
            Image(systemName: "doc.text.magnifyingglass")
                .font(.system(size: 50))
                .foregroundColor(.secondary)
            Text("No transcriptions found")
                .font(.system(size: 24, weight: .semibold, design: .default))
            Text("Your history will appear here")
                .font(.system(size: 18, weight: .regular, design: .default))
                .foregroundColor(.secondary)
        }
        .frame(maxWidth: .infinity, maxHeight: .infinity)
        .background(Color(.windowBackgroundColor).opacity(0.4))
        .padding(24)
    }
    
    private var selectionToolbar: some View {
        HStack(spacing: 12) {
            Text("\(selectedTranscriptions.count) selected")
                .foregroundColor(.secondary)
                .font(.system(size: 14))
            
            Spacer()
            
            Button(action: {
                showDeleteConfirmation = true
            }) {
                HStack(spacing: 4) {
                    Image(systemName: "trash")
                    Text("Delete")
                }
            }
            .buttonStyle(.borderless)
            
            if selectedTranscriptions.count < displayedTranscriptions.count {
                Button("Select All") {
                    Task {
                        await selectAllTranscriptions()
                    }
                }
                .buttonStyle(.borderless)
            } else {
                Button("Deselect All") {
                    selectedTranscriptions.removeAll()
                }
                .buttonStyle(.borderless)
            }
        }
        .padding(16)
        .frame(maxWidth: .infinity)
        .background(
            Color(.windowBackgroundColor)
                .shadow(color: Color.black.opacity(0.1), radius: 3, y: -2)
        )
    }
    
    private func loadInitialContent() async {
        isLoading = true
        defer { isLoading = false }
        
        do {
            // Reset cursor
            lastTimestamp = nil
            
            // Fetch initial page without a cursor
            let items = try modelContext.fetch(cursorQueryDescriptor())
            
            await MainActor.run {
                displayedTranscriptions = items
                // Update cursor to the timestamp of the last item
                lastTimestamp = items.last?.timestamp
                // If we got fewer items than the page size, there are no more items
                hasMoreContent = items.count == pageSize
            }
        } catch {
            print("Error loading transcriptions: \(error)")
        }
    }
    
    private func loadMoreContent() {
        guard !isLoading, hasMoreContent, let lastTimestamp = lastTimestamp else { return }
        
        Task {
            isLoading = true
            defer { isLoading = false }
            
            do {
                // Fetch next page using the cursor
                let newItems = try modelContext.fetch(cursorQueryDescriptor(after: lastTimestamp))
                
                await MainActor.run {
                    // Append new items to the displayed list
                    displayedTranscriptions.append(contentsOf: newItems)
                    // Update cursor to the timestamp of the last new item
                    self.lastTimestamp = newItems.last?.timestamp
                    // If we got fewer items than the page size, there are no more items
                    hasMoreContent = newItems.count == pageSize
                }
            } catch {
                print("Error loading more transcriptions: \(error)")
            }
        }
    }
    
    private func resetPagination() async {
        await MainActor.run {
            displayedTranscriptions = []
            lastTimestamp = nil
            hasMoreContent = true
            isLoading = false
        }
    }
    
    private func deleteTranscription(_ transcription: Transcription) {
        // First delete the audio file if it exists
        if let urlString = transcription.audioFileURL,
           let url = URL(string: urlString) {
            try? FileManager.default.removeItem(at: url)
        }
        
        modelContext.delete(transcription)
        if expandedTranscription == transcription {
            expandedTranscription = nil
        }
        
        // Remove from selection if selected
        selectedTranscriptions.remove(transcription)
        
        // Refresh the view
        Task {
            try? await modelContext.save()
            await loadInitialContent()
        }
    }
    
    private func deleteSelectedTranscriptions() {
        // Delete audio files and transcriptions
        for transcription in selectedTranscriptions {
            if let urlString = transcription.audioFileURL,
               let url = URL(string: urlString) {
                try? FileManager.default.removeItem(at: url)
            }
            modelContext.delete(transcription)
            if expandedTranscription == transcription {
                expandedTranscription = nil
            }
        }
        
        // Clear selection
        selectedTranscriptions.removeAll()
        
        // Save changes and refresh
        Task {
            try? await modelContext.save()
            await loadInitialContent()
        }
    }
    
    private func toggleSelection(_ transcription: Transcription) {
        if selectedTranscriptions.contains(transcription) {
            selectedTranscriptions.remove(transcription)
        } else {
            selectedTranscriptions.insert(transcription)
        }
    }
    
    // Modified function to select all transcriptions in the database
    private func selectAllTranscriptions() async {
        do {
            // Create a descriptor without pagination limits to get all IDs
            var allDescriptor = FetchDescriptor<Transcription>()
            
            // Apply search filter if needed
            if !searchText.isEmpty {
                allDescriptor.predicate = #Predicate<Transcription> { transcription in
                    transcription.text.localizedStandardContains(searchText) ||
                    (transcription.enhancedText?.localizedStandardContains(searchText) ?? false)
                }
            }
            
            // For better performance, only fetch the IDs
            allDescriptor.propertiesToFetch = [\.id]
            
            // Fetch all matching transcriptions
            let allTranscriptions = try modelContext.fetch(allDescriptor)
            
            // Create a set of all visible transcriptions for quick lookup
            let visibleIds = Set(displayedTranscriptions.map { $0.id })
            
            // Add all transcriptions to the selection
            await MainActor.run {
                // First add all visible transcriptions directly
                selectedTranscriptions = Set(displayedTranscriptions)
                
                // Then add any non-visible transcriptions by ID
                for transcription in allTranscriptions {
                    if !visibleIds.contains(transcription.id) {
                        selectedTranscriptions.insert(transcription)
                    }
                }
            }
        } catch {
            print("Error selecting all transcriptions: \(error)")
        }
    }
}

struct CircularCheckboxStyle: ToggleStyle {
    func makeBody(configuration: Configuration) -> some View {
        Button(action: {
            configuration.isOn.toggle()
        }) {
            Image(systemName: configuration.isOn ? "checkmark.circle.fill" : "circle")
                .symbolRenderingMode(.hierarchical)
                .foregroundColor(configuration.isOn ? .blue : .gray)
                .font(.system(size: 18))
        }
        .buttonStyle(.plain)
    }
}

================
File: VoiceInk/Whisper/LibWhisper.swift
================
import Foundation
#if canImport(whisper)
import whisper
#else
#error("Unable to import whisper module. Please check your project configuration.")
#endif
import os

enum WhisperError: Error {
    case couldNotInitializeContext
}

// Meet Whisper C++ constraint: Don't access from more than one thread at a time.
actor WhisperContext {
    private var context: OpaquePointer?
    private var languageCString: [CChar]?
    private var prompt: String?
    private var promptCString: [CChar]?
    private let logger = Logger(subsystem: "com.prakashjoshipax.voiceink", category: "WhisperContext")

    private init() {
        // Private initializer without context
    }

    init(context: OpaquePointer) {
        self.context = context
    }

    deinit {
        if let context = context {
            whisper_free(context)
        }
    }

    func fullTranscribe(samples: [Float]) {
        guard let context = context else { return }
        
        // Leave 2 processors free (i.e. the high-efficiency cores).
        let maxThreads = max(1, min(8, cpuCount() - 2))
        var params = whisper_full_default_params(WHISPER_SAMPLING_GREEDY)
        
        // Read language directly from UserDefaults
        let selectedLanguage = UserDefaults.standard.string(forKey: "SelectedLanguage") ?? "auto"
        if selectedLanguage != "auto" {
            languageCString = Array(selectedLanguage.utf8CString)
            params.language = languageCString?.withUnsafeBufferPointer { ptr in
                ptr.baseAddress
            }
            logger.notice("üåê Using language: \(selectedLanguage)")
        } else {
            languageCString = nil
            params.language = nil
            logger.notice("üåê Using auto language detection")
        }
        
        // Only use prompt for English language
        if selectedLanguage == "en" && prompt != nil {
            promptCString = Array(prompt!.utf8CString)
            params.initial_prompt = promptCString?.withUnsafeBufferPointer { ptr in
                ptr.baseAddress
            }
            logger.notice("üí¨ Using prompt for transcription")
        } else {
            promptCString = nil
            params.initial_prompt = nil
        }
        
        // Adapted from whisper.objc
        params.print_realtime   = true
        params.print_progress   = false
        params.print_timestamps = true
        params.print_special    = false
        params.translate        = false
        params.n_threads        = Int32(maxThreads)
        params.offset_ms        = 0
        params.no_context       = false
        params.single_segment   = false
        
        // Adjusted parameters to reduce hallucination
        params.suppress_blank   = true      // Keep suppressing blank outputs
        params.suppress_nst     = true      // Additional suppression of non-speech tokens

        whisper_reset_timings(context)
        logger.notice("‚öôÔ∏è Starting whisper transcription")
        samples.withUnsafeBufferPointer { samples in
            if (whisper_full(context, params, samples.baseAddress, Int32(samples.count)) != 0) {
                logger.error("‚ùå Failed to run whisper model")
            } else {
                // Print detected language info before timings
                let langId = whisper_full_lang_id(context)
                let detectedLang = String(cString: whisper_lang_str(langId))
                logger.notice("‚úÖ Transcription completed - Language: \(detectedLang)")
                whisper_print_timings(context)
            }
        }
        
        languageCString = nil
        promptCString = nil
    }

    func getTranscription() -> String {
        guard let context = context else { return "" }
        var transcription = ""
        for i in 0..<whisper_full_n_segments(context) {
            transcription += String(cString: whisper_full_get_segment_text(context, i))
        }
        return transcription
    }

    static func createContext(path: String) async throws -> WhisperContext {
        // Create empty context first
        let whisperContext = WhisperContext()
        
        // Initialize the context within the actor's isolated context
        try await whisperContext.initializeModel(path: path)
        
        return whisperContext
    }
    
    private func initializeModel(path: String) throws {
        var params = whisper_context_default_params()
        #if targetEnvironment(simulator)
        params.use_gpu = false
        logger.notice("üñ•Ô∏è Running on simulator, using CPU")
        #endif
        
        let context = whisper_init_from_file_with_params(path, params)
        if let context {
            self.context = context
        } else {
            logger.error("‚ùå Couldn't load model at \(path)")
            throw WhisperError.couldNotInitializeContext
        }
    }

    func releaseResources() {
        if let context = context {
            whisper_free(context)
            self.context = nil
        }
        languageCString = nil
    }

    func setPrompt(_ prompt: String?) {
        self.prompt = prompt
        logger.debug("üí¨ Prompt set: \(prompt ?? "none")")
    }
}

fileprivate func cpuCount() -> Int {
    ProcessInfo.processInfo.processorCount
}

================
File: VoiceInk/Whisper/WhisperError.swift
================
import Foundation

enum WhisperStateError: Error, Identifiable {
    case modelLoadFailed
    case transcriptionFailed
    case recordingFailed
    case accessibilityPermissionDenied
    case modelDownloadFailed
    case modelDeletionFailed
    case unknownError
    
    var id: String { UUID().uuidString }
}

extension WhisperStateError: LocalizedError {
    var errorDescription: String? {
        switch self {
        case .modelLoadFailed:
            return "Failed to load the transcription model."
        case .transcriptionFailed:
            return "Failed to transcribe the audio."
        case .recordingFailed:
            return "Failed to start or stop recording."
        case .accessibilityPermissionDenied:
            return "Accessibility permission is required for automatic pasting."
        case .modelDownloadFailed:
            return "Failed to download the model."
        case .modelDeletionFailed:
            return "Failed to delete the model."
        case .unknownError:
            return "An unknown error occurred."
        }
    }
    
    var recoverySuggestion: String? {
        switch self {
        case .modelLoadFailed:
            return "Try selecting a different model or redownloading the current model."
        case .transcriptionFailed:
            return "Check your audio input and try again. If the problem persists, try a different model."
        case .recordingFailed:
            return "Check your microphone permissions and try again."
        case .accessibilityPermissionDenied:
            return "Go to System Preferences > Security & Privacy > Privacy > Accessibility and allow VoiceInk."
        case .modelDownloadFailed:
            return "Check your internet connection and try again. If the problem persists, try a different model."
        case .modelDeletionFailed:
            return "Restart the application and try again. If the problem persists, you may need to manually delete the model file."
        case .unknownError:
            return "Please restart the application. If the problem persists, contact support."
        }
    }
}

================
File: VoiceInk/Whisper/WhisperPrompt.swift
================
import Foundation

@MainActor
class WhisperPrompt: ObservableObject {
    @Published var transcriptionPrompt: String = UserDefaults.standard.string(forKey: "TranscriptionPrompt") ?? ""
    
    private var dictionaryWords: [String] = []
    private let saveKey = "CustomDictionaryItems"
    
    private let basePrompt = """
    Hey, How are you doing? Are you good? It's nice to meet after so long.
    
    """
    
    init() {
        loadDictionaryItems()
        updateTranscriptionPrompt()
    }
    
    private func loadDictionaryItems() {
        guard let data = UserDefaults.standard.data(forKey: saveKey) else { return }
        
        if let savedItems = try? JSONDecoder().decode([DictionaryItem].self, from: data) {
            let enabledWords = savedItems.filter { $0.isEnabled }.map { $0.word }
            dictionaryWords = enabledWords
            updateTranscriptionPrompt()
        }
    }
    
    func updateDictionaryWords(_ words: [String]) {
        dictionaryWords = words
        updateTranscriptionPrompt()
    }
    
    private func updateTranscriptionPrompt() {
        var prompt = basePrompt
        var allWords = ["VoiceInk"]
        allWords.append(contentsOf: dictionaryWords)
        
        if !allWords.isEmpty {
            prompt += "\nImportant words: " + allWords.joined(separator: ", ")
        }
        
        transcriptionPrompt = prompt
        UserDefaults.standard.set(prompt, forKey: "TranscriptionPrompt")
    }
    
    func saveDictionaryItems(_ items: [DictionaryItem]) async {
        if let encoded = try? JSONEncoder().encode(items) {
            UserDefaults.standard.set(encoded, forKey: saveKey)
            let enabledWords = items.filter { $0.isEnabled }.map { $0.word }
            dictionaryWords = enabledWords
            updateTranscriptionPrompt()
        }
    }
}

================
File: VoiceInk/Whisper/WhisperState.swift
================
import Foundation
import SwiftUI
import AVFoundation
import SwiftData
import AppKit
import KeyboardShortcuts
import os

@MainActor
class WhisperState: NSObject, ObservableObject, AVAudioRecorderDelegate {
    @Published var isModelLoaded = false
    @Published var messageLog = ""
    @Published var canTranscribe = false
    @Published var isRecording = false
    @Published var currentModel: WhisperModel?
    @Published var isModelLoading = false
    @Published var availableModels: [WhisperModel] = []
    @Published var predefinedModels: [PredefinedModel] = PredefinedModels.models
    @Published var clipboardMessage = ""
    @Published var miniRecorderError: String?
    @Published var isProcessing = false
    @Published var shouldCancelRecording = false
    @Published var isTranscribing = false
    @Published var isAutoCopyEnabled: Bool = UserDefaults.standard.object(forKey: "IsAutoCopyEnabled") as? Bool ?? true {
        didSet {
            UserDefaults.standard.set(isAutoCopyEnabled, forKey: "IsAutoCopyEnabled")
        }
    }
    @Published var recorderType: String = UserDefaults.standard.string(forKey: "RecorderType") ?? "mini" {
        didSet {
            UserDefaults.standard.set(recorderType, forKey: "RecorderType")
        }
    }
    
    private var whisperContext: WhisperContext?
    private let recorder = Recorder()
    private var recordedFile: URL? = nil
    let whisperPrompt = WhisperPrompt()
    
    let modelContext: ModelContext
    
    private var modelUrl: URL? {
        let possibleURLs = [
            Bundle.main.url(forResource: "ggml-base.en", withExtension: "bin", subdirectory: "Models"),
            Bundle.main.url(forResource: "ggml-base.en", withExtension: "bin"),
            Bundle.main.bundleURL.appendingPathComponent("Models/ggml-base.en.bin")
        ]
        
        for url in possibleURLs {
            if let url = url, FileManager.default.fileExists(atPath: url.path) {
                return url
            }
        }
        return nil
    }
    
    private enum LoadError: Error {
        case couldNotLocateModel
    }
    
    let modelsDirectory: URL
    let recordingsDirectory: URL
    let enhancementService: AIEnhancementService?
    private var licenseViewModel: LicenseViewModel
    private let logger = Logger(subsystem: "com.prakashjoshipax.voiceink", category: "WhisperState")
    private var transcriptionStartTime: Date?
    private var notchWindowManager: NotchWindowManager?
    private var miniWindowManager: MiniWindowManager?
    
    init(modelContext: ModelContext, enhancementService: AIEnhancementService? = nil) {
        self.modelContext = modelContext
        self.modelsDirectory = FileManager.default.urls(for: .applicationSupportDirectory, in: .userDomainMask)[0]
            .appendingPathComponent("com.prakashjoshipax.VoiceInk")
            .appendingPathComponent("WhisperModels")
        self.recordingsDirectory = FileManager.default.urls(for: .applicationSupportDirectory, in: .userDomainMask)[0]
            .appendingPathComponent("com.prakashjoshipax.VoiceInk")
            .appendingPathComponent("Recordings")
        self.enhancementService = enhancementService
        self.licenseViewModel = LicenseViewModel()
        
        super.init()
        
        setupNotifications()
        createModelsDirectoryIfNeeded()
        createRecordingsDirectoryIfNeeded()
        loadAvailableModels()
        
        if let savedModelName = UserDefaults.standard.string(forKey: "CurrentModel"),
           let savedModel = availableModels.first(where: { $0.name == savedModelName }) {
            currentModel = savedModel
        }
    }
    
    private func createModelsDirectoryIfNeeded() {
        do {
            try FileManager.default.createDirectory(at: modelsDirectory, withIntermediateDirectories: true, attributes: nil)
        } catch {
            messageLog += "Error creating models directory: \(error.localizedDescription)\n"
        }
    }
    
    private func createRecordingsDirectoryIfNeeded() {
        do {
            try FileManager.default.createDirectory(at: recordingsDirectory, withIntermediateDirectories: true, attributes: nil)
        } catch {
            messageLog += "Error creating recordings directory: \(error.localizedDescription)\n"
        }
    }
    
    private func loadAvailableModels() {
        do {
            let fileURLs = try FileManager.default.contentsOfDirectory(at: modelsDirectory, includingPropertiesForKeys: nil)
            availableModels = fileURLs.compactMap { url in
                guard url.pathExtension == "bin" else { return nil }
                return WhisperModel(name: url.deletingPathExtension().lastPathComponent, url: url)
            }
        } catch {
            messageLog += "Error loading available models: \(error.localizedDescription)\n"
        }
    }
    
    private func loadModel(_ model: WhisperModel) async throws {
        guard whisperContext == nil else { return }
        
        logger.notice("üîÑ Loading Whisper model: \(model.name)")
        isModelLoading = true
        defer { isModelLoading = false }
        
        do {
            whisperContext = try await WhisperContext.createContext(path: model.url.path)
            isModelLoaded = true
            currentModel = model
            logger.notice("‚úÖ Successfully loaded model: \(model.name)")
        } catch {
            logger.error("‚ùå Failed to load model: \(model.name) - \(error.localizedDescription)")
            throw WhisperStateError.modelLoadFailed
        }
    }
    
    func setDefaultModel(_ model: WhisperModel) async {
        do {
            currentModel = model
            UserDefaults.standard.set(model.name, forKey: "CurrentModel")
            canTranscribe = true
        } catch {
            currentError = error as? WhisperStateError ?? .unknownError
            canTranscribe = false
        }
    }

    func toggleRecord() async {
        if isRecording {
            logger.notice("üõë Stopping recording")
            await recorder.stopRecording()
            isRecording = false
            isVisualizerActive = false
            if let recordedFile {
                let duration = Date().timeIntervalSince(transcriptionStartTime ?? Date())
                await transcribeAudio(recordedFile, duration: duration)
            } else {
                logger.error("‚ùå No recorded file found after stopping recording")
            }
        } else {
            logger.notice("üéôÔ∏è Starting recording")
            requestRecordPermission { [self] granted in
                if granted {
                    Task {
                        do {
                            // Start window configuration in parallel with recording setup
                            async let windowConfigTask = ActiveWindowService.shared.applyConfigurationForCurrentApp()
                            
                            let file = try FileManager.default.url(for: .documentDirectory,
                                in: .userDomainMask,
                                appropriateFor: nil,
                                create: true)
                                .appending(path: "output.wav")
                            
                            try await self.recorder.startRecording(toOutputFile: file, delegate: self)
                            
                            self.isRecording = true
                            self.isVisualizerActive = true
                            self.recordedFile = file
                            self.transcriptionStartTime = Date()
                            
                            // Wait for window configuration to complete
                            await windowConfigTask
                            
                            // Start background tasks for model loading and screen capture
                            Task.detached(priority: .background) {
                                await self.performBackgroundTasks()
                            }
                            
                        } catch {
                            self.messageLog += "\(error.localizedDescription)\n"
                            self.isRecording = false
                            self.isVisualizerActive = false
                        }
                    }
                } else {
                    self.messageLog += "Recording permission denied\n"
                }
            }
        }
    }
    
    private func performBackgroundTasks() async {
        if let currentModel = self.currentModel, self.whisperContext == nil {
            logger.notice("üîÑ Preloading model in background: \(currentModel.name)")
            do {
                try await self.loadModel(currentModel)
            } catch {
                logger.error("‚ùå Background model preloading failed: \(error.localizedDescription)")
                await MainActor.run {
                    self.messageLog += "Error preloading model: \(error.localizedDescription)\n"
                }
            }
        }
        
        if let enhancementService = self.enhancementService,
           enhancementService.isEnhancementEnabled && 
           enhancementService.useScreenCaptureContext {
            await enhancementService.captureScreenContext()
        }
    }
    
    private func requestRecordPermission(response: @escaping (Bool) -> Void) {
#if os(macOS)
        response(true)
#else
        AVAudioSession.sharedInstance().requestRecordPermission { granted in
            response(granted)
        }
#endif
    }
    
    // MARK: AVAudioRecorderDelegate
    
    nonisolated func audioRecorderEncodeErrorDidOccur(_ recorder: AVAudioRecorder, error: Error?) {
        if let error {
            Task {
                await handleRecError(error)
            }
        }
    }
    
    private func handleRecError(_ error: Error) {
        messageLog += "\(error.localizedDescription)\n"
        isRecording = false
    }
    
    nonisolated func audioRecorderDidFinishRecording(_ recorder: AVAudioRecorder, successfully flag: Bool) {
        Task {
            await onDidFinishRecording(success: flag)
        }
    }
    
    private func onDidFinishRecording(success: Bool) {
        isRecording = false
    }
    
    @Published var downloadProgress: [String: Double] = [:]

    func downloadModel(_ model: PredefinedModel) async {
        guard let url = URL(string: model.downloadURL) else { return }

        logger.notice("üîΩ Downloading model: \(model.name)")
        do {
            let (data, response) = try await withCheckedThrowingContinuation { (continuation: CheckedContinuation<(Data, URLResponse), Error>) in
                let task = URLSession.shared.dataTask(with: url) { data, response, error in
                    if let error = error {
                        continuation.resume(throwing: error)
                        return
                    }
                    guard let httpResponse = response as? HTTPURLResponse,
                          (200...299).contains(httpResponse.statusCode),
                          let data = data else {
                        continuation.resume(throwing: URLError(.badServerResponse))
                        return
                    }
                    continuation.resume(returning: (data, httpResponse))
                }
                
                task.resume()
                
                let observation = task.progress.observe(\.fractionCompleted) { progress, _ in
                    DispatchQueue.main.async {
                        self.downloadProgress[model.name] = progress.fractionCompleted
                    }
                }
                
                Task {
                    await withTaskCancellationHandler {
                        observation.invalidate()
                    } operation: {
                        await withCheckedContinuation { (_: CheckedContinuation<Void, Never>) in }
                    }
                }
            }

            let destinationURL = modelsDirectory.appendingPathComponent(model.filename)
            try data.write(to: destinationURL)

            availableModels.append(WhisperModel(name: model.name, url: destinationURL))
            self.downloadProgress.removeValue(forKey: model.name)
            logger.notice("‚úÖ Successfully downloaded model: \(model.name)")
        } catch {
            logger.error("‚ùå Failed to download model: \(model.name) - \(error.localizedDescription)")
            currentError = .modelDownloadFailed
            self.downloadProgress.removeValue(forKey: model.name)
        }
    }

    private func transcribeAudio(_ url: URL, duration: TimeInterval) async {
        if shouldCancelRecording { return }

        guard let currentModel = currentModel else {
            logger.error("‚ùå Cannot transcribe: No model selected")
            messageLog += "Cannot transcribe: No model selected.\n"
            currentError = .modelLoadFailed
            return
        }

        if whisperContext == nil {
            logger.notice("üîÑ Model not loaded yet, attempting to load now: \(currentModel.name)")
            do {
                try await loadModel(currentModel)
            } catch {
                logger.error("‚ùå Failed to load model: \(currentModel.name) - \(error.localizedDescription)")
                messageLog += "Failed to load transcription model. Please try again.\n"
                currentError = .modelLoadFailed
                await cleanupResources()
                return
            }
        }

        guard let whisperContext = whisperContext else {
            logger.error("‚ùå Cannot transcribe: Model could not be loaded")
            messageLog += "Cannot transcribe: Model could not be loaded after retry.\n"
            currentError = .modelLoadFailed
            return
        }

        logger.notice("üîÑ Starting transcription with model: \(currentModel.name)")
        do {
            isProcessing = true
            isTranscribing = true
            canTranscribe = false

            let permanentURL = try saveRecordingPermanently(url)
            let permanentURLString = permanentURL.absoluteString

            if shouldCancelRecording {
                await cleanupResources()
                return
            }

            messageLog += "Reading wave samples...\n"
            let data = try readAudioSamples(url)
            
            if shouldCancelRecording {
                await cleanupResources()
                return
            }
            
            messageLog += "Transcribing data using \(currentModel.name) model...\n"
            messageLog += "Setting prompt: \(whisperPrompt.transcriptionPrompt)\n"
            await whisperContext.setPrompt(whisperPrompt.transcriptionPrompt)
            
            if shouldCancelRecording {
                await cleanupResources()
                return
            }
            
            await whisperContext.fullTranscribe(samples: data)
            
            if shouldCancelRecording {
                await cleanupResources()
                return
            }
            
            var text = await whisperContext.getTranscription()
            text = text.trimmingCharacters(in: .whitespacesAndNewlines)
            logger.notice("‚úÖ Transcription completed successfully, length: \(text.count) characters")
            
            // Apply word replacements if enabled
            if UserDefaults.standard.bool(forKey: "IsWordReplacementEnabled") {
                text = WordReplacementService.shared.applyReplacements(to: text)
                logger.notice("‚úÖ Word replacements applied")
            }
            
            if let enhancementService = enhancementService,
               enhancementService.isEnhancementEnabled,
               enhancementService.isConfigured {
                do {
                    if shouldCancelRecording {
                        await cleanupResources()
                        return
                    }
                    
                    messageLog += "Enhancing transcription with AI...\n"
                    let enhancedText = try await enhancementService.enhance(text)
                    messageLog += "Enhancement completed.\n"
                    
                    let newTranscription = Transcription(
                        text: text,
                        duration: duration,
                        enhancedText: enhancedText,
                        audioFileURL: permanentURLString
                    )
                    modelContext.insert(newTranscription)
                    try? modelContext.save()
                    
                    text = enhancedText
                } catch {
                    messageLog += "Enhancement failed: \(error.localizedDescription). Using original transcription.\n"
                    let newTranscription = Transcription(
                        text: text,
                        duration: duration,
                        audioFileURL: permanentURLString
                    )
                    modelContext.insert(newTranscription)
                    try? modelContext.save()
                }
            } else {
                let newTranscription = Transcription(
                    text: text,
                    duration: duration,
                    audioFileURL: permanentURLString
                )
                modelContext.insert(newTranscription)
                try? modelContext.save()
            }
            
            if case .trialExpired = licenseViewModel.licenseState {
                text = """
                    Your trial has expired. Upgrade to VoiceInk Pro at tryvoiceink.com/buy
                    
                    \(text)
                    """
            }
            
            messageLog += "Done: \(text)\n"
            
            SoundManager.shared.playStopSound()
            
            if AXIsProcessTrusted() {
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.3) {
                    CursorPaster.pasteAtCursor(text)
                }
            } else {
                messageLog += "Accessibility permissions not granted. Transcription not pasted automatically.\n"
            }
            
            if isAutoCopyEnabled {
                let success = ClipboardManager.copyToClipboard(text)
                if success {
                    clipboardMessage = "Transcription copied to clipboard"
                } else {
                    clipboardMessage = "Failed to copy to clipboard"
                    messageLog += "Failed to copy transcription to clipboard\n"
                }
            }
            
            await cleanupResources()
            await dismissMiniRecorder()
            
        } catch {
            messageLog += "\(error.localizedDescription)\n"
            currentError = .transcriptionFailed
            
            await cleanupResources()
            await dismissMiniRecorder()
        }
    }

    private func readAudioSamples(_ url: URL) throws -> [Float] {
        return try decodeWaveFile(url)
    }

    private func decodeWaveFile(_ url: URL) throws -> [Float] {
        let data = try Data(contentsOf: url)
        let floats = stride(from: 44, to: data.count, by: 2).map {
            return data[$0..<$0 + 2].withUnsafeBytes {
                let short = Int16(littleEndian: $0.load(as: Int16.self))
                return max(-1.0, min(Float(short) / 32767.0, 1.0))
            }
        }
        return floats
    }

    func deleteModel(_ model: WhisperModel) async {
        do {
            try FileManager.default.removeItem(at: model.url)
            availableModels.removeAll { $0.id == model.id }
            if currentModel?.id == model.id {
                currentModel = nil
                canTranscribe = false
            }
        } catch {
            messageLog += "Error deleting model: \(error.localizedDescription)\n"
            currentError = .modelDeletionFailed
        }
    }

    @Published var isVisualizerActive = false
    
    @Published var isMiniRecorderVisible = false {
        didSet {
            if isMiniRecorderVisible {
                showRecorderPanel()
            } else {
                hideRecorderPanel()
            }
        }
    }
    
    private func setupNotifications() {
        NotificationCenter.default.addObserver(self, selector: #selector(handleToggleMiniRecorder), name: .toggleMiniRecorder, object: nil)
        NotificationCenter.default.addObserver(self, selector: #selector(handleLicenseStatusChanged), name: .licenseStatusChanged, object: nil)
    }
    
    @objc public func handleToggleMiniRecorder() {
        if isMiniRecorderVisible {
            Task {
                await toggleRecord()
            }
        } else {
            Task {
                await toggleRecord()
                
                SoundManager.shared.playStartSound()
                
                await MainActor.run {
                    showRecorderPanel()
                    isMiniRecorderVisible = true
                }
            }
        }
    }

    @objc private func handleLicenseStatusChanged() {
        // This will refresh the license state when it changes elsewhere in the app
        self.licenseViewModel = LicenseViewModel()
    }

    private func showRecorderPanel() {
        logger.notice("üì± Showing \(self.recorderType) recorder")
        if recorderType == "notch" {
            if notchWindowManager == nil {
                notchWindowManager = NotchWindowManager(whisperState: self, recorder: recorder)
                logger.info("Created new notch window manager")
            }
            notchWindowManager?.show()
        } else {
            if miniWindowManager == nil {
                miniWindowManager = MiniWindowManager(whisperState: self, recorder: recorder)
                logger.info("Created new mini window manager")
            }
            miniWindowManager?.show()
        }
    }

    private func hideRecorderPanel() {
        if isRecording {
            Task {
                await toggleRecord()
            }
        }
    }

    func toggleMiniRecorder() async {
        if isMiniRecorderVisible {
            await dismissMiniRecorder()
        } else {
            Task {
                await toggleRecord()
                
                SoundManager.shared.playStartSound()
                
                await MainActor.run {
                    showRecorderPanel()
                    isMiniRecorderVisible = true
                }
            }
        }
    }

    private func cleanupResources() async {
        if !isRecording && !isProcessing {
            logger.notice("üßπ Cleaning up Whisper resources")
            await whisperContext?.releaseResources()
            whisperContext = nil
            isModelLoaded = false
        }
    }

    func dismissMiniRecorder() async {
        logger.notice("üì± Dismissing \(self.recorderType) recorder")
        shouldCancelRecording = true
        if isRecording {
            await recorder.stopRecording()
        }
        
        if recorderType == "notch" {
            notchWindowManager?.hide()
        } else {
            miniWindowManager?.hide()
        }
        
        await MainActor.run {
            isRecording = false
            isVisualizerActive = false
            isProcessing = false
            isTranscribing = false
            canTranscribe = true
            isMiniRecorderVisible = false
            shouldCancelRecording = false
        }
        
        try? await Task.sleep(nanoseconds: 150_000_000)
        await cleanupResources()
    }

    func cancelRecording() async {
        shouldCancelRecording = true
        SoundManager.shared.playEscSound()
        if isRecording {
            await recorder.stopRecording()
        }
        await dismissMiniRecorder()
    }

    @Published var currentError: WhisperStateError?

    func unloadModel() {
        Task {
            await whisperContext?.releaseResources()
            whisperContext = nil
            isModelLoaded = false
            
            if let recordedFile = recordedFile {
                try? FileManager.default.removeItem(at: recordedFile)
                self.recordedFile = nil
            }
        }
    }

    private func clearDownloadedModels() async {
        for model in availableModels {
            do {
                try FileManager.default.removeItem(at: model.url)
            } catch {
                messageLog += "Error deleting model: \(error.localizedDescription)\n"
            }
        }
        availableModels.removeAll()
    }

    func getEnhancementService() -> AIEnhancementService? {
        return enhancementService
    }

    private func saveRecordingPermanently(_ tempURL: URL) throws -> URL {
        let fileName = "\(UUID().uuidString).wav"
        let permanentURL = recordingsDirectory.appendingPathComponent(fileName)
        try FileManager.default.copyItem(at: tempURL, to: permanentURL)
        return permanentURL
    }
}

struct WhisperModel: Identifiable {
    let id = UUID()
    let name: String
    let url: URL
    var downloadURL: String {
        "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/\(filename)"
    }
    var filename: String {
        "\(name).bin"
    }
}

private class TaskDelegate: NSObject, URLSessionTaskDelegate {
    private let continuation: CheckedContinuation<Void, Never>
    
    init(_ continuation: CheckedContinuation<Void, Never>) {
        self.continuation = continuation
    }
    
    func urlSession(_ session: URLSession, task: URLSessionTask, didCompleteWithError error: Error?) {
        continuation.resume()
    }
}

extension Notification.Name {
    static let toggleMiniRecorder = Notification.Name("toggleMiniRecorder")
}

================
File: VoiceInk/AppDelegate.swift
================
import Cocoa
import SwiftUI

class AppDelegate: NSObject, NSApplicationDelegate {
    func applicationDidFinishLaunching(_ notification: Notification) {
        updateActivationPolicy()
    }

    func applicationShouldHandleReopen(_ sender: NSApplication, hasVisibleWindows flag: Bool) -> Bool {
        if !flag {
            createMainWindowIfNeeded()
        }
        return true
    }
    
    func applicationShouldTerminateAfterLastWindowClosed(_ sender: NSApplication) -> Bool {
        return false
    }
    
    private func updateActivationPolicy() {
        let isMenuBarOnly = UserDefaults.standard.bool(forKey: "IsMenuBarOnly")
        if isMenuBarOnly {
            NSApp.setActivationPolicy(.accessory)
        } else {
            NSApp.setActivationPolicy(.regular)
        }
    }
    
    private func createMainWindowIfNeeded() {
        if NSApp.windows.isEmpty {
            let contentView = ContentView()
            let hostingView = NSHostingView(rootView: contentView)
            let window = WindowManager.shared.createMainWindow(contentView: hostingView)
            window.makeKeyAndOrderFront(nil)
        } else {
            NSApp.windows.first?.makeKeyAndOrderFront(nil)
        }
    }
}

================
File: VoiceInk/ClipboardManager.swift
================
import SwiftUI
import AppKit

struct ClipboardManager {
    enum ClipboardError: Error {
        case copyFailed
        case accessDenied
    }
    
    static func copyToClipboard(_ text: String) -> Bool {
        let pasteboard = NSPasteboard.general
        pasteboard.clearContents()
        return pasteboard.setString(text, forType: .string)
    }
    
    static func getClipboardContent() -> String? {
        return NSPasteboard.general.string(forType: .string)
    }
}

struct ClipboardMessageModifier: ViewModifier {
    @Binding var message: String
    
    func body(content: Content) -> some View {
        content
            .overlay(
                Group {
                    if !message.isEmpty {
                        Text(message)
                            .font(.caption)
                            .foregroundColor(.green)
                            .padding(.horizontal, 8)
                            .padding(.vertical, 4)
                            .background(Color.green.opacity(0.1))
                            .cornerRadius(4)
                            .transition(.opacity)
                            .animation(.easeInOut, value: message)
                    }
                }
                .frame(maxWidth: .infinity, maxHeight: .infinity, alignment: .topTrailing)
                .padding()
            )
    }
}

extension View {
    func clipboardMessage(_ message: Binding<String>) -> some View {
        self.modifier(ClipboardMessageModifier(message: message))
    }
}

================
File: VoiceInk/CursorPaster.swift
================
import Foundation
import AppKit
import OSLog

class CursorPaster {
    private static let pasteCompletionDelay: TimeInterval = 0.3
    private static let logger = Logger(subsystem: "com.voiceink", category: "CursorPaster")
    
    static func pasteAtCursor(_ text: String) {
        guard AXIsProcessTrusted() else {
            print("Accessibility permissions not granted. Cannot paste at cursor.")
            return
        }
        
        // Save the current pasteboard contents
        let pasteboard = NSPasteboard.general
        let oldContents = pasteboard.string(forType: .string)
        
        // Set the new text to paste
        pasteboard.clearContents()
        pasteboard.setString(text, forType: .string)
        
        // Use the preferred paste method based on user settings
        if UserDefaults.standard.bool(forKey: "UseAppleScriptPaste") {
            pasteUsingAppleScript()
        } else {
            pasteUsingCommandV()
        }
        
        // Restore the original pasteboard content
        DispatchQueue.global(qos: .userInitiated).asyncAfter(deadline: .now() + pasteCompletionDelay) {
            pasteboard.clearContents()
            if let oldContents = oldContents {
                pasteboard.setString(oldContents, forType: .string)
            }
        }
    }
    
    private static func pasteUsingAppleScript() -> Bool {
        let script = """
        tell application "System Events"
            keystroke "v" using command down
        end tell
        """
        
        var error: NSDictionary?
        if let scriptObject = NSAppleScript(source: script) {
            let output = scriptObject.executeAndReturnError(&error)
            if error != nil {
                print("AppleScript paste failed: \(error?.description ?? "Unknown error")")
                logger.notice("AppleScript paste failed with error: \(error?.description ?? "Unknown error")")
                return false
            }
            logger.notice("AppleScript paste completed successfully")
            return true
        }
        return false
    }
    
    private static func pasteUsingCommandV() {
        let source = CGEventSource(stateID: .hidSystemState)
        
        let cmdDown = CGEvent(keyboardEventSource: source, virtualKey: 0x37, keyDown: true)
        let vDown = CGEvent(keyboardEventSource: source, virtualKey: 0x09, keyDown: true)
        let vUp = CGEvent(keyboardEventSource: source, virtualKey: 0x09, keyDown: false)
        let cmdUp = CGEvent(keyboardEventSource: source, virtualKey: 0x37, keyDown: false)
        
        cmdDown?.flags = .maskCommand
        vDown?.flags = .maskCommand
        vUp?.flags = .maskCommand
        
        cmdDown?.post(tap: .cghidEventTap)
        vDown?.post(tap: .cghidEventTap)
        vUp?.post(tap: .cghidEventTap)
        cmdUp?.post(tap: .cghidEventTap)
        
        logger.notice("Command+V paste completed")
    }
}

================
File: VoiceInk/HotkeyManager.swift
================
import Foundation
import KeyboardShortcuts
import Carbon
import AppKit

extension KeyboardShortcuts.Name {
    static let toggleMiniRecorder = Self("toggleMiniRecorder")
    static let escapeRecorder = Self("escapeRecorder")
    static let toggleEnhancement = Self("toggleEnhancement")
    // Prompt selection shortcuts
    static let selectPrompt1 = Self("selectPrompt1")
    static let selectPrompt2 = Self("selectPrompt2")
    static let selectPrompt3 = Self("selectPrompt3")
    static let selectPrompt4 = Self("selectPrompt4")
    static let selectPrompt5 = Self("selectPrompt5")
    static let selectPrompt6 = Self("selectPrompt6")
    static let selectPrompt7 = Self("selectPrompt7")
    static let selectPrompt8 = Self("selectPrompt8")
    static let selectPrompt9 = Self("selectPrompt9")
}

@MainActor
class HotkeyManager: ObservableObject {
    @Published var isListening = false
    @Published var isShortcutConfigured = false
    @Published var isPushToTalkEnabled: Bool {
        didSet {
            UserDefaults.standard.set(isPushToTalkEnabled, forKey: "isPushToTalkEnabled")
            if !isPushToTalkEnabled {
                isRightOptionKeyPressed = false
                isFnKeyPressed = false
                isRightCommandKeyPressed = false
                isRightShiftKeyPressed = false
                keyPressStartTime = nil
            }
            setupKeyMonitors()
        }
    }
    @Published var pushToTalkKey: PushToTalkKey {
        didSet {
            UserDefaults.standard.set(pushToTalkKey.rawValue, forKey: "pushToTalkKey")
            isRightOptionKeyPressed = false
            isFnKeyPressed = false
            isRightCommandKeyPressed = false
            isRightShiftKeyPressed = false
            keyPressStartTime = nil
        }
    }
    
    private var whisperState: WhisperState
    private var isRightOptionKeyPressed = false
    private var isFnKeyPressed = false
    private var isRightCommandKeyPressed = false
    private var isRightShiftKeyPressed = false
    private var localKeyMonitor: Any?
    private var globalKeyMonitor: Any?
    private var visibilityTask: Task<Void, Never>?
    private var keyPressStartTime: Date?
    private let shortPressDuration: TimeInterval = 0.5 // 300ms threshold
    
    // Add cooldown management
    private var lastShortcutTriggerTime: Date?
    private let shortcutCooldownInterval: TimeInterval = 0.5 // 500ms cooldown
    
    enum PushToTalkKey: String, CaseIterable {
        case rightOption = "rightOption"
        case fn = "fn"
        case rightCommand = "rightCommand"
        case rightShift = "rightShift"
        
        var displayName: String {
            switch self {
            case .rightOption: return "Right Option (‚å•)"
            case .fn: return "Fn"
            case .rightCommand: return "Right Command (‚åò)"
            case .rightShift: return "Right Shift (‚áß)"
            }
        }
    }
    
    init(whisperState: WhisperState) {
        self.isPushToTalkEnabled = UserDefaults.standard.bool(forKey: "isPushToTalkEnabled")
        self.pushToTalkKey = PushToTalkKey(rawValue: UserDefaults.standard.string(forKey: "pushToTalkKey") ?? "") ?? .rightCommand
        self.whisperState = whisperState
        
        updateShortcutStatus()
        setupEnhancementShortcut()
        
        // Start observing mini recorder visibility
        setupVisibilityObserver()
    }
    
    private func setupVisibilityObserver() {
        visibilityTask = Task { @MainActor in
            for await isVisible in whisperState.$isMiniRecorderVisible.values {
                if isVisible {
                    setupEscapeShortcut()
                    // Set Command+E shortcut when visible
                    KeyboardShortcuts.setShortcut(.init(.e, modifiers: .command), for: .toggleEnhancement)
                    setupPromptShortcuts()
                } else {
                    removeEscapeShortcut()
                    // Remove Command+E shortcut when not visible
                    KeyboardShortcuts.setShortcut(nil, for: .toggleEnhancement)
                    removePromptShortcuts()
                }
            }
        }
    }
    
    private func setupEscapeShortcut() {
        // Set ESC as the shortcut using KeyboardShortcuts native approach
        KeyboardShortcuts.setShortcut(.init(.escape), for: .escapeRecorder)
        
        // Setup handler
        KeyboardShortcuts.onKeyDown(for: .escapeRecorder) { [weak self] in
            Task { @MainActor in
                guard let self = self,
                      await self.whisperState.isMiniRecorderVisible else { return }
                SoundManager.shared.playEscSound()
                await self.whisperState.dismissMiniRecorder()
            }
        }
    }
    
    private func removeEscapeShortcut() {
        KeyboardShortcuts.setShortcut(nil, for: .escapeRecorder)
    }
    
    private func setupEnhancementShortcut() {
        // Only setup the handler, don't set the shortcut here
        // The shortcut will be set/removed based on visibility
        KeyboardShortcuts.onKeyDown(for: .toggleEnhancement) { [weak self] in
            Task { @MainActor in
                guard let self = self,
                      await self.whisperState.isMiniRecorderVisible,
                      let enhancementService = await self.whisperState.getEnhancementService() else { return }
                enhancementService.isEnhancementEnabled.toggle()
            }
        }
    }
    
    private func removeEnhancementShortcut() {
        KeyboardShortcuts.setShortcut(nil, for: .toggleEnhancement)
    }
    
    private func setupPromptShortcuts() {
        // Set up Command+1 through Command+9 shortcuts with proper key definitions
        KeyboardShortcuts.setShortcut(.init(.one, modifiers: .command), for: .selectPrompt1)
        KeyboardShortcuts.setShortcut(.init(.two, modifiers: .command), for: .selectPrompt2)
        KeyboardShortcuts.setShortcut(.init(.three, modifiers: .command), for: .selectPrompt3)
        KeyboardShortcuts.setShortcut(.init(.four, modifiers: .command), for: .selectPrompt4)
        KeyboardShortcuts.setShortcut(.init(.five, modifiers: .command), for: .selectPrompt5)
        KeyboardShortcuts.setShortcut(.init(.six, modifiers: .command), for: .selectPrompt6)
        KeyboardShortcuts.setShortcut(.init(.seven, modifiers: .command), for: .selectPrompt7)
        KeyboardShortcuts.setShortcut(.init(.eight, modifiers: .command), for: .selectPrompt8)
        KeyboardShortcuts.setShortcut(.init(.nine, modifiers: .command), for: .selectPrompt9)
        
        // Setup handlers for each shortcut
        setupPromptHandler(for: .selectPrompt1, index: 0)
        setupPromptHandler(for: .selectPrompt2, index: 1)
        setupPromptHandler(for: .selectPrompt3, index: 2)
        setupPromptHandler(for: .selectPrompt4, index: 3)
        setupPromptHandler(for: .selectPrompt5, index: 4)
        setupPromptHandler(for: .selectPrompt6, index: 5)
        setupPromptHandler(for: .selectPrompt7, index: 6)
        setupPromptHandler(for: .selectPrompt8, index: 7)
        setupPromptHandler(for: .selectPrompt9, index: 8)
    }
    
    private func setupPromptHandler(for shortcutName: KeyboardShortcuts.Name, index: Int) {
        KeyboardShortcuts.onKeyDown(for: shortcutName) { [weak self] in
            Task { @MainActor in
                guard let self = self,
                      await self.whisperState.isMiniRecorderVisible,
                      let enhancementService = await self.whisperState.getEnhancementService() else { return }
                
                let prompts = enhancementService.allPrompts
                if index < prompts.count {
                    // Enable AI enhancement if it's not already enabled
                    if !enhancementService.isEnhancementEnabled {
                        enhancementService.isEnhancementEnabled = true
                    }
                    // Switch to the selected prompt
                    enhancementService.setActivePrompt(prompts[index])
                }
            }
        }
    }
    
    private func removePromptShortcuts() {
        // Remove Command+1 through Command+9 shortcuts
        KeyboardShortcuts.setShortcut(nil, for: .selectPrompt1)
        KeyboardShortcuts.setShortcut(nil, for: .selectPrompt2)
        KeyboardShortcuts.setShortcut(nil, for: .selectPrompt3)
        KeyboardShortcuts.setShortcut(nil, for: .selectPrompt4)
        KeyboardShortcuts.setShortcut(nil, for: .selectPrompt5)
        KeyboardShortcuts.setShortcut(nil, for: .selectPrompt6)
        KeyboardShortcuts.setShortcut(nil, for: .selectPrompt7)
        KeyboardShortcuts.setShortcut(nil, for: .selectPrompt8)
        KeyboardShortcuts.setShortcut(nil, for: .selectPrompt9)
    }
    
    func updateShortcutStatus() {
        isShortcutConfigured = KeyboardShortcuts.getShortcut(for: .toggleMiniRecorder) != nil
        
        if isShortcutConfigured {
            setupShortcutHandler()
            setupKeyMonitors()
        } else {
            removeKeyMonitors()
        }
    }
    
    private func setupShortcutHandler() {
        KeyboardShortcuts.onKeyUp(for: .toggleMiniRecorder) { [weak self] in
            Task { @MainActor in
                await self?.handleShortcutTriggered()
            }
        }
    }
    
    private func handleShortcutTriggered() async {
        // Check cooldown
        if let lastTrigger = lastShortcutTriggerTime,
           Date().timeIntervalSince(lastTrigger) < shortcutCooldownInterval {
            return // Still in cooldown period
        }
        
        // Update last trigger time
        lastShortcutTriggerTime = Date()
        
        // Handle the shortcut
        await whisperState.handleToggleMiniRecorder()
    }
    
    private func removeKeyMonitors() {
        if let monitor = localKeyMonitor {
            NSEvent.removeMonitor(monitor)
            localKeyMonitor = nil
        }
        if let monitor = globalKeyMonitor {
            NSEvent.removeMonitor(monitor)
            globalKeyMonitor = nil
        }
    }
    
    private func setupKeyMonitors() {
        guard isPushToTalkEnabled else {
            removeKeyMonitors()
            return
        }
        
        // Remove existing monitors first
        removeKeyMonitors()
        
        // Local monitor for when app is in foreground
        localKeyMonitor = NSEvent.addLocalMonitorForEvents(matching: .flagsChanged) { [weak self] event in
            Task { @MainActor in
                await self?.handlePushToTalkKey(event)
            }
            return event
        }
        
        // Global monitor for when app is in background
        globalKeyMonitor = NSEvent.addGlobalMonitorForEvents(matching: .flagsChanged) { [weak self] event in
            Task { @MainActor in
                await self?.handlePushToTalkKey(event)
            }
        }
    }
    
    private func handlePushToTalkKey(_ event: NSEvent) async {
        // Only handle push-to-talk if enabled and configured
        guard isPushToTalkEnabled && isShortcutConfigured else { return }
        
        let keyState: Bool
        switch pushToTalkKey {
        case .rightOption:
            keyState = event.modifierFlags.contains(.option) && event.keyCode == 0x3D
            guard keyState != isRightOptionKeyPressed else { return }
            isRightOptionKeyPressed = keyState
            
        case .fn:
            keyState = event.modifierFlags.contains(.function)
            guard keyState != isFnKeyPressed else { return }
            isFnKeyPressed = keyState
            
        case .rightCommand:
            keyState = event.modifierFlags.contains(.command) && event.keyCode == 0x36
            guard keyState != isRightCommandKeyPressed else { return }
            isRightCommandKeyPressed = keyState
            
        case .rightShift:
            keyState = event.modifierFlags.contains(.shift) && event.keyCode == 0x3C
            guard keyState != isRightShiftKeyPressed else { return }
            isRightShiftKeyPressed = keyState
        }
        
        if keyState {
            // Key pressed down - start recording and store timestamp
            if !whisperState.isMiniRecorderVisible {
                keyPressStartTime = Date()
                await whisperState.handleToggleMiniRecorder()
            }
        } else {
            // Key released
            if whisperState.isMiniRecorderVisible {
                // Check if the key was pressed for less than the threshold
                if let startTime = keyPressStartTime,
                   Date().timeIntervalSince(startTime) < shortPressDuration {
                    // Short press - don't stop recording
                    keyPressStartTime = nil
                    return
                }
                // Long press - stop recording
                await whisperState.handleToggleMiniRecorder()
            }
            keyPressStartTime = nil
        }
    }
    
    deinit {
        visibilityTask?.cancel()
        Task { @MainActor in
            removeKeyMonitors()
            removeEscapeShortcut()
            removeEnhancementShortcut()
        }
    }
}

================
File: VoiceInk/Info.plist
================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>SUEnableInstallerLauncherService</key>
	<true/>
	<key>SUFeedURL</key>
	<string>https://beingpax.github.io/VoiceInk/appcast.xml</string>
	<key>SUPublicEDKey</key>
	<string>rLRdZIjK3gHKfqNlAF9nT7FbjwSvwkJ8BVn0v2mD1Mo=</string>
	<key>LSUIElement</key>
	<false/>
	<key>SUEnableAutomaticChecks</key>
	<true/>
	<key>NSMicrophoneUsageDescription</key>
	<string>VoiceInk needs access to your microphone to record audio for transcription.</string>
	<key>NSAppleEventsUsageDescription</key>
	<string>VoiceInk needs to interact with your browser to detect the current website for applying website-specific configurations.</string>
	<key>NSScreenCaptureUsageDescription</key>
	<string>VoiceInk needs screen recording access to understand context from your screen for improved transcription accuracy.</string>
</dict>
</plist>

================
File: VoiceInk/MediaController.swift
================
import Foundation
import AppKit
import SwiftUI
import os
import Combine

/// Controls media playback detection and management during recording
class MediaController: ObservableObject {
    static let shared = MediaController()
    private var mediaRemoteHandle: UnsafeMutableRawPointer?
    private var mrNowPlayingIsPlaying: MRNowPlayingIsPlayingFunc?
    private var didPauseMedia = false
    
    private let logger = Logger(subsystem: "com.prakashjoshipax.voiceink", category: "MediaController")
    
    @Published var isMediaPauseEnabled: Bool = UserDefaults.standard.bool(forKey: "isMediaPauseEnabled") {
        didSet {
            UserDefaults.standard.set(isMediaPauseEnabled, forKey: "isMediaPauseEnabled")
        }
    }
    
    // Define function pointer types for MediaRemote functions
    typealias MRNowPlayingIsPlayingFunc = @convention(c) (DispatchQueue, @escaping (Bool) -> Void) -> Void
    typealias MRMediaRemoteCommandInfoFunc = @convention(c) () -> Void
    
    // Additional function pointers for direct control
    private var mrSendCommand: (@convention(c) (Int, [String: Any]?) -> Bool)?
    
    // MediaRemote command constantst
    private let kMRPlay = 0
    private let kMRPause = 1
    private let kMRTogglePlayPause = 2
    
    private init() {
        // Set default if not already set
        if !UserDefaults.standard.contains(key: "isMediaPauseEnabled") {
            UserDefaults.standard.set(true, forKey: "isMediaPauseEnabled")
        }
        setupMediaRemote()
    }
    
    private func setupMediaRemote() {
        // Open the private framework
        guard let handle = dlopen("/System/Library/PrivateFrameworks/MediaRemote.framework/MediaRemote", RTLD_NOW) else {
            logger.error("Unable to open MediaRemote framework")
            return
        }
        mediaRemoteHandle = handle
        
        // Get pointer for the "is playing" function
        guard let playingPtr = dlsym(handle, "MRMediaRemoteGetNowPlayingApplicationIsPlaying") else {
            logger.error("Unable to find MRMediaRemoteGetNowPlayingApplicationIsPlaying function")
            dlclose(handle)
            mediaRemoteHandle = nil
            return
        }
        
        mrNowPlayingIsPlaying = unsafeBitCast(playingPtr, to: MRNowPlayingIsPlayingFunc.self)
        
        // Get the send command function pointer
        if let sendCommandPtr = dlsym(handle, "MRMediaRemoteSendCommand") {
            mrSendCommand = unsafeBitCast(sendCommandPtr, to: (@convention(c) (Int, [String: Any]?) -> Bool).self)
            logger.info("Successfully loaded MRMediaRemoteSendCommand function")
        } else {
            logger.warning("Could not find MRMediaRemoteSendCommand function, fallback to key simulation")
        }
        
        logger.info("MediaRemote framework initialized successfully")
    }
    
    deinit {
        if let handle = mediaRemoteHandle {
            dlclose(handle)
        }
    }
    
    /// Checks if media is currently playing on the system
    func isMediaPlaying() async -> Bool {
        guard isMediaPauseEnabled, let mrNowPlayingIsPlaying = mrNowPlayingIsPlaying else {
            return false
        }
        
        return await withCheckedContinuation { continuation in
            mrNowPlayingIsPlaying(DispatchQueue.main) { isPlaying in
                continuation.resume(returning: isPlaying)
            }
        }
    }
    
    /// Pauses media if it's currently playing
    func pauseMediaIfPlaying() async -> Bool {
        guard isMediaPauseEnabled else {
            logger.info("Media pause feature is disabled")
            return false
        }
        
        if await isMediaPlaying() {
            logger.info("Media is playing, pausing it for recording")
            await MainActor.run {
                // Try direct command first, then fall back to key simulation
                if !sendMediaCommand(command: kMRPause) {
                    sendMediaKey()
                }
            }
            didPauseMedia = true
            return true
        }
        
        logger.info("No media playing, no need to pause")
        return false
    }
    
    /// Resumes media if it was paused by this controller
    func resumeMediaIfPaused() async {
        guard isMediaPauseEnabled, didPauseMedia else {
            return
        }
        
        logger.info("Resuming previously paused media")
        await MainActor.run {
            // Try direct command first, then fall back to key simulation
            if !sendMediaCommand(command: kMRPlay) {
                sendMediaKey()
            }
        }
        didPauseMedia = false
    }
    
    /// Sends a media command using the MediaRemote framework
    private func sendMediaCommand(command: Int) -> Bool {
        guard let sendCommand = mrSendCommand else {
            logger.warning("MRMediaRemoteSendCommand not available")
            return false
        }
        
        let result = sendCommand(command, nil)
        logger.info("Sent media command \(command) with result: \(result)")
        return result
    }
    
    /// Simulates a media key press (Play/Pause) by posting a system-defined NSEvent
    private func sendMediaKey() {
        let NX_KEYTYPE_PLAY: UInt32 = 16
        let keys = [NX_KEYTYPE_PLAY]
        
        logger.info("Simulating media key press using NSEvent")
        
        for key in keys {
            func postKeyEvent(down: Bool) {
                let flags: NSEvent.ModifierFlags = down ? .init(rawValue: 0xA00) : .init(rawValue: 0xB00)
                let data1 = Int((key << 16) | (down ? 0xA << 8 : 0xB << 8))
                
                if let event = NSEvent.otherEvent(
                    with: .systemDefined,
                    location: .zero,
                    modifierFlags: flags,
                    timestamp: 0,
                    windowNumber: 0,
                    context: nil,
                    subtype: 8,
                    data1: data1,
                    data2: -1
                ) {
                    // Attempt to post directly to all applications
                    let didPost = event.cgEvent?.post(tap: .cghidEventTap) != nil
                    logger.info("Posted key event (down: \(down)) with result: \(didPost ? "success" : "failure")")
                    
                    // Add a small delay to ensure the event is processed
                    usleep(10000) // 10ms delay
                }
            }
            
            // Perform the key down/up sequence
            postKeyEvent(down: true)
            postKeyEvent(down: false)
            
            // Allow some time for the system to process the key event
            usleep(50000) // 50ms delay
        }
        
        // As a fallback, try to use CGEvent directly
        createAndPostPlayPauseEvent()
    }
    
    /// Creates and posts a CGEvent for media control as a fallback method
    private func createAndPostPlayPauseEvent() {
        logger.info("Attempting fallback CGEvent for media control")
        
        // Media keys as defined in IOKit
        let NX_KEYTYPE_PLAY: Int64 = 16
        
        // Create a CGEvent for the media key
        guard let source = CGEventSource(stateID: .hidSystemState) else {
            logger.error("Failed to create CGEventSource")
            return
        }
        
        if let keyDownEvent = CGEvent(keyboardEventSource: source, virtualKey: UInt16(NX_KEYTYPE_PLAY), keyDown: true) {
            keyDownEvent.flags = .init(rawValue: 0xA00)
            keyDownEvent.post(tap: .cghidEventTap)
            logger.info("Posted play/pause key down event")
            
            // Small delay between down and up events
            usleep(10000) // 10ms
            
            if let keyUpEvent = CGEvent(keyboardEventSource: source, virtualKey: UInt16(NX_KEYTYPE_PLAY), keyDown: false) {
                keyUpEvent.flags = .init(rawValue: 0xB00)
                keyUpEvent.post(tap: .cghidEventTap)
                logger.info("Posted play/pause key up event")
            }
        }
    }
}

extension UserDefaults {
    func contains(key: String) -> Bool {
        return object(forKey: key) != nil
    }
}

================
File: VoiceInk/MenuBarManager.swift
================
import SwiftUI
import LaunchAtLogin
import SwiftData
import AppKit

class MenuBarManager: ObservableObject {
    @Published var isMenuBarOnly: Bool {
        didSet {
            UserDefaults.standard.set(isMenuBarOnly, forKey: "IsMenuBarOnly")
            updateAppActivationPolicy()
        }
    }
    
    private var updaterViewModel: UpdaterViewModel
    private var whisperState: WhisperState
    private var container: ModelContainer
    private var enhancementService: AIEnhancementService
    private var aiService: AIService
    private var hotkeyManager: HotkeyManager
    private var mainWindow: NSWindow?  // Store window reference
    
    init(updaterViewModel: UpdaterViewModel, 
         whisperState: WhisperState, 
         container: ModelContainer,
         enhancementService: AIEnhancementService,
         aiService: AIService,
         hotkeyManager: HotkeyManager) {
        self.isMenuBarOnly = UserDefaults.standard.bool(forKey: "IsMenuBarOnly")
        self.updaterViewModel = updaterViewModel
        self.whisperState = whisperState
        self.container = container
        self.enhancementService = enhancementService
        self.aiService = aiService
        self.hotkeyManager = hotkeyManager
        updateAppActivationPolicy()
    }
    
    func toggleMenuBarOnly() {
        isMenuBarOnly.toggle()
    }
    
    private func updateAppActivationPolicy() {
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }
            
            // Clean up existing window if switching to menu bar mode
            if self.isMenuBarOnly && self.mainWindow != nil {
                self.mainWindow?.close()
                self.mainWindow = nil
            }
            
            // Update activation policy
            if self.isMenuBarOnly {
                NSApp.setActivationPolicy(.accessory)
            } else {
                NSApp.setActivationPolicy(.regular)
            }
        }
    }
    
    func openMainWindowAndNavigate(to destination: String) {
        print("MenuBarManager: Navigating to \(destination)")
        
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }
            
            // Activate the app
            NSApp.activate(ignoringOtherApps: true)
            
            // Clean up existing window if it's no longer valid
            if let existingWindow = self.mainWindow, !existingWindow.isVisible {
                self.mainWindow = nil
            }
            
            // Get or create main window
            if self.mainWindow == nil {
                self.mainWindow = self.createMainWindow()
            }
            
            guard let window = self.mainWindow else { return }
            
            // Make the window key and order front
            window.makeKeyAndOrderFront(nil)
            window.center()  // Always center the window for consistent positioning
            
            // Post a notification to navigate to the desired destination
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) {
                NotificationCenter.default.post(
                    name: .navigateToDestination,
                    object: nil,
                    userInfo: ["destination": destination]
                )
                print("MenuBarManager: Posted navigation notification for \(destination)")
            }
        }
    }
    
    private func createMainWindow() -> NSWindow {
        print("MenuBarManager: Creating new main window")
        
        // Create the content view with all required environment objects
        let contentView = ContentView()
            .environmentObject(whisperState)
            .environmentObject(hotkeyManager)
            .environmentObject(self)
            .environmentObject(updaterViewModel)
            .environmentObject(enhancementService)
            .environmentObject(aiService)
            .environment(\.modelContext, ModelContext(container))
        
        // Create window using WindowManager
        let hostingView = NSHostingView(rootView: contentView)
        let window = WindowManager.shared.createMainWindow(contentView: hostingView)
        
        // Set window delegate to handle window closing
        let delegate = WindowDelegate { [weak self] in
            self?.mainWindow = nil
        }
        window.delegate = delegate
        
        print("MenuBarManager: Window setup complete")
        
        return window
    }
}

// Window delegate to handle window closing
class WindowDelegate: NSObject, NSWindowDelegate {
    let onClose: () -> Void
    
    init(onClose: @escaping () -> Void) {
        self.onClose = onClose
        super.init()
    }
    
    func windowWillClose(_ notification: Notification) {
        onClose()
    }
}

extension Notification.Name {
    static let navigateToDestination = Notification.Name("navigateToDestination")
}

================
File: VoiceInk/Recorder.swift
================
import Foundation
import AVFoundation
import CoreAudio
import os

@MainActor // Change to MainActor since we need to interact with UI
class Recorder: ObservableObject {
    private var recorder: AVAudioRecorder?
    private let logger = Logger(subsystem: "com.prakashjoshipax.voiceink", category: "Recorder")
    private let deviceManager = AudioDeviceManager.shared
    private var deviceObserver: NSObjectProtocol?
    private var isReconfiguring = false
    private let mediaController = MediaController.shared
    @Published var audioMeter = AudioMeter(averagePower: 0, peakPower: 0)
    private var levelMonitorTimer: Timer?
    
    enum RecorderError: Error {
        case couldNotStartRecording
        case deviceConfigurationFailed
    }
    
    init() {
        logger.info("Initializing Recorder")
        setupDeviceChangeObserver()
    }
    
    private func setupDeviceChangeObserver() {
        logger.info("Setting up device change observer")
        deviceObserver = AudioDeviceConfiguration.createDeviceChangeObserver { [weak self] in
            Task {
                await self?.handleDeviceChange()
            }
        }
    }
    
    private func handleDeviceChange() async {
        guard !isReconfiguring else {
            logger.warning("Device change already in progress, skipping")
            return
        }
        
        logger.info("Handling device change")
        isReconfiguring = true
        
        // If we're recording, we need to stop and restart with new device
        if recorder != nil {
            logger.info("Active recording detected during device change")
            let currentURL = recorder?.url
            let currentDelegate = recorder?.delegate
            
            stopRecording()
            
            // Wait briefly for the device change to take effect
            logger.info("Waiting for device change to take effect")
            try? await Task.sleep(nanoseconds: 100_000_000) // 0.1 seconds
            
            if let url = currentURL {
                do {
                    logger.info("Attempting to restart recording with new device")
                    try await startRecording(toOutputFile: url, delegate: currentDelegate)
                    logger.info("Successfully reconfigured recording with new device")
                } catch {
                    logger.error("Failed to restart recording after device change: \(error.localizedDescription)")
                }
            }
        }
        
        isReconfiguring = false
        logger.info("Device change handling completed")
    }
    
    private func configureAudioSession(with deviceID: AudioDeviceID) async throws {
        logger.info("Starting audio session configuration for device ID: \(deviceID)")
        
        // Add a small delay to ensure device is ready after system changes
        try? await Task.sleep(nanoseconds: 50_000_000) // 0.05 seconds
        
        do {
            // Get the audio format from the selected device
            let format = try AudioDeviceConfiguration.configureAudioSession(with: deviceID)
            logger.info("Got audio format - Sample rate: \(format.mSampleRate), Channels: \(format.mChannelsPerFrame)")
            
            // Configure the device for recording
            try AudioDeviceConfiguration.setDefaultInputDevice(deviceID)
            logger.info("Successfully set default input device")
        } catch {
            logger.error("Audio session configuration failed: \(error.localizedDescription)")
            logger.error("Device ID: \(deviceID)")
            if let deviceName = deviceManager.getDeviceName(deviceID: deviceID) {
                logger.error("Failed device name: \(deviceName)")
            }
            throw error
        }
        
        // Add another small delay to allow configuration to settle
        try? await Task.sleep(nanoseconds: 50_000_000) // 0.05 seconds
        
        if let deviceName = deviceManager.getDeviceName(deviceID: deviceID) {
            logger.info("Successfully configured recorder with device: \(deviceName) (ID: \(deviceID))")
        }
    }
    
    func startRecording(toOutputFile url: URL, delegate: AVAudioRecorderDelegate?) async throws {
        logger.info("Starting recording process")
        
        // Check if media is playing and pause it if needed
        let wasPaused = await mediaController.pauseMediaIfPlaying()
        if wasPaused {
            logger.info("Media playback paused for recording")
        }
        
        // Get the current selected device
        let deviceID = deviceManager.getCurrentDevice()
        if deviceID != 0 {
            do {
                logger.info("Configuring audio session with device ID: \(deviceID)")
                if let deviceName = deviceManager.getDeviceName(deviceID: deviceID) {
                    logger.info("Attempting to configure device: \(deviceName)")
                }
                try await configureAudioSession(with: deviceID)
                logger.info("Successfully configured audio session")
            } catch {
                logger.error("Failed to configure audio device: \(error.localizedDescription), Device ID: \(deviceID)")
                if let deviceName = deviceManager.getDeviceName(deviceID: deviceID) {
                    logger.error("Failed device name: \(deviceName)")
                }
                logger.info("Falling back to default device")
            }
        } else {
            logger.info("Using default audio device (no custom device selected)")
        }
        
        logger.info("Setting up recording with settings: 16000Hz, 1 channel, PCM format")
        let recordSettings: [String : Any] = [
            AVFormatIDKey: Int(kAudioFormatLinearPCM),
            AVSampleRateKey: 16000.0,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]
        
        do {
            logger.info("Initializing AVAudioRecorder with URL: \(url.path)")
            let recorder = try AVAudioRecorder(url: url, settings: recordSettings)
            recorder.delegate = delegate
            recorder.isMeteringEnabled = true // Enable metering
            
            logger.info("Attempting to start recording...")
            if recorder.record() {
                logger.info("Recording started successfully")
                self.recorder = recorder
                startLevelMonitoring()
            } else {
                logger.error("Failed to start recording - recorder.record() returned false")
                logger.error("Current device ID: \(deviceID)")
                if let deviceName = deviceManager.getDeviceName(deviceID: deviceID) {
                    logger.error("Current device name: \(deviceName)")
                }
                
                // Resume media if we paused it but failed to start recording
                await mediaController.resumeMediaIfPaused()
                
                throw RecorderError.couldNotStartRecording
            }
        } catch {
            logger.error("Error creating AVAudioRecorder: \(error.localizedDescription)")
            logger.error("Recording settings used: \(recordSettings)")
            logger.error("Output URL: \(url.path)")
            
            // Resume media if we paused it but failed to start recording
            await mediaController.resumeMediaIfPaused()
            
            throw error
        }
    }
    
    func stopRecording() {
        logger.info("Stopping recording")
        stopLevelMonitoring()
        recorder?.stop()
        recorder?.delegate = nil // Remove delegate
        recorder = nil
        
        // Force a device change notification to trigger system audio profile reset
        logger.info("Triggering audio device change notification")
        NotificationCenter.default.post(name: NSNotification.Name("AudioDeviceChanged"), object: nil)
        
        // Resume media if we paused it
        Task {
            await mediaController.resumeMediaIfPaused()
        }
        
        logger.info("Recording stopped successfully")
    }
    
    private func startLevelMonitoring() {
        levelMonitorTimer = Timer.scheduledTimer(withTimeInterval: 0.05, repeats: true) { [weak self] _ in
            guard let self = self else { return }
            self.updateAudioLevel()
        }
    }
    
    private func stopLevelMonitoring() {
        levelMonitorTimer?.invalidate()
        levelMonitorTimer = nil
        audioMeter = AudioMeter(averagePower: 0, peakPower: 0)
    }
    
    private func updateAudioLevel() {
        guard let recorder = recorder else { return }
        recorder.updateMeters()
        
        // Get the power values in decibels
        let averagePowerDb = recorder.averagePower(forChannel: 0)
        let peakPowerDb = recorder.peakPower(forChannel: 0)
        
        // Convert from dB to linear scale using proper conversion
        let normalizedAverage = pow(10, Double(averagePowerDb) / 30)
        let normalizedPeak = pow(10, Double(peakPowerDb) / 30)
        
        // Apply standard scaling factor for all devices
        let scalingFactor = 2.5
        
        // Update the audio meter with scaled values
        let scaledAverage = min(normalizedAverage * scalingFactor, 1.0)
        let scaledPeak = min(normalizedPeak * scalingFactor, 1.0)
        
        audioMeter = AudioMeter(
            averagePower: scaledAverage,
            peakPower: scaledPeak
        )
    }
    
    deinit {
        logger.info("Deinitializing Recorder")
        if let observer = deviceObserver {
            NotificationCenter.default.removeObserver(observer)
        }
        Task { @MainActor in
            stopLevelMonitoring()
        }
    }
}

struct AudioMeter: Equatable {
    let averagePower: Double
    let peakPower: Double
}

================
File: VoiceInk/repomix.config.json
================
{
    "ignore": {
        "customPatterns": [

        ]
    }
}

================
File: VoiceInk/SoundManager.swift
================
import Foundation
import AVFoundation
import SwiftUI

class SoundManager {
    static let shared = SoundManager()
    
    private var startSound: AVAudioPlayer?
    private var stopSound: AVAudioPlayer?
    private var escSound: AVAudioPlayer?
    
    @AppStorage("isSoundFeedbackEnabled") private var isSoundFeedbackEnabled = true
    
    private init() {
        setupSounds()
    }
    
    private func setupSounds() {
        print("Attempting to load sound files...")
        
        // Try loading directly from the main bundle
        if let startSoundURL = Bundle.main.url(forResource: "recstart", withExtension: "mp3"),
           let stopSoundURL = Bundle.main.url(forResource: "pastes", withExtension: "mp3"),
           let escSoundURL = Bundle.main.url(forResource: "esc", withExtension: "wav") {
            print("Found sounds in main bundle")
            try? loadSounds(start: startSoundURL, stop: stopSoundURL, esc: escSoundURL)
            return
        }
        
        print("‚ö†Ô∏è Could not find sound files in the main bundle")
        print("Bundle path: \(Bundle.main.bundlePath)")
        
        // List contents of the bundle for debugging
        if let bundleURL = Bundle.main.resourceURL {
            do {
                let contents = try FileManager.default.contentsOfDirectory(at: bundleURL, includingPropertiesForKeys: nil)
                print("Contents of bundle resource directory:")
                contents.forEach { print($0.lastPathComponent) }
            } catch {
                print("Error listing bundle contents: \(error)")
            }
        }
    }
    
    private func loadSounds(start startURL: URL, stop stopURL: URL, esc escURL: URL) throws {
        do {
            startSound = try AVAudioPlayer(contentsOf: startURL)
            stopSound = try AVAudioPlayer(contentsOf: stopURL)
            escSound = try AVAudioPlayer(contentsOf: escURL)
            
            // Set lower volume for all sounds
            startSound?.volume = 0.7
            stopSound?.volume = 0.7
            escSound?.volume = 0.3
            
            // Prepare sounds for instant playback
            startSound?.prepareToPlay()
            stopSound?.prepareToPlay()
            escSound?.prepareToPlay()
            
            print("‚úÖ Successfully loaded all sound files")
        } catch {
            print("‚ùå Error loading sounds: \(error.localizedDescription)")
            throw error
        }
    }
    
    func playStartSound() {
        guard isSoundFeedbackEnabled else { return }
        startSound?.play()
    }
    
    func playStopSound() {
        guard isSoundFeedbackEnabled else { return }
        stopSound?.play()
    }
    
    func playEscSound() {
        guard isSoundFeedbackEnabled else { return }
        escSound?.play()
    }
    
    var isEnabled: Bool {
        get { isSoundFeedbackEnabled }
        set { isSoundFeedbackEnabled = newValue }
    }
}

================
File: VoiceInk/VisualizerView.swift
================
import SwiftUI

struct VisualizerView: View {
    @ObservedObject var recorder: Recorder
    private let barCount = 50
    @State private var levels: [BarLevel] = []
    private let smoothingFactor: Double = 0.3
    
    struct BarLevel: Equatable {
        var average: CGFloat
        var peak: CGFloat
    }
    
    var body: some View {
        GeometryReader { geometry in
            HStack(alignment: .center, spacing: 4) {
                ForEach(0..<barCount, id: \.self) { index in
                    VisualizerBar(level: levels.isEmpty ? BarLevel(average: 0, peak: 0) : levels[index])
                        .frame(width: (geometry.size.width - CGFloat(barCount - 1) * 4) / CGFloat(barCount))
                }
            }
            .frame(width: geometry.size.width, height: geometry.size.height)
            .background(Color.black.opacity(0.1))
            .cornerRadius(10)
            .onAppear {
                levels = Array(repeating: BarLevel(average: 0, peak: 0), count: barCount)
            }
            .onReceive(recorder.$audioMeter) { newMeter in
                updateLevels(with: newMeter)
            }
        }
    }
    
    private func updateLevels(with meter: AudioMeter) {
        // Create new levels with randomization for visual interest
        var newLevels: [BarLevel] = []
        for i in 0..<barCount {
            let randomFactor = Double.random(in: 0.8...1.2)
            let targetAverage = min(max(meter.averagePower * randomFactor, 0), 1)
            let targetPeak = min(max(meter.peakPower * randomFactor, 0), 1)
            
            let currentLevel = levels[i]
            let smoothedAverage = currentLevel.average + (CGFloat(targetAverage) - currentLevel.average) * CGFloat(smoothingFactor)
            let smoothedPeak = currentLevel.peak + (CGFloat(targetPeak) - currentLevel.peak) * CGFloat(smoothingFactor)
            
            newLevels.append(BarLevel(
                average: smoothedAverage,
                peak: smoothedPeak
            ))
        }
        
        withAnimation(.easeInOut(duration: 0.15)) {
            levels = newLevels
        }
    }
}

struct VisualizerBar: View {
    let level: VisualizerView.BarLevel
    
    var body: some View {
        GeometryReader { geometry in
            ZStack(alignment: .bottom) {
                // Average level bar
                RoundedRectangle(cornerRadius: 2)
                    .fill(
                        LinearGradient(
                            gradient: Gradient(colors: [.blue.opacity(0.7), .purple.opacity(0.7)]),
                            startPoint: .bottom,
                            endPoint: .top
                        )
                    )
                    .frame(height: level.average * geometry.size.height)
                
                // Peak level indicator
                RoundedRectangle(cornerRadius: 2)
                    .fill(
                        LinearGradient(
                            gradient: Gradient(colors: [.blue, .purple]),
                            startPoint: .bottom,
                            endPoint: .top
                        )
                    )
                    .frame(height: 2)
                    .offset(y: -level.peak * geometry.size.height + 1)
                    .opacity(level.peak > 0.01 ? 1 : 0)
            }
            .frame(maxHeight: geometry.size.height, alignment: .bottom)
        }
    }
}

================
File: VoiceInk/VoiceInk.entitlements
================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>com.apple.security.app-sandbox</key>
	<false/>
	<key>com.apple.security.automation.apple-events</key>
	<true/>
	<key>com.apple.security.device.audio-input</key>
	<true/>
	<key>com.apple.security.screen-capture</key>
	<true/>
	<key>com.apple.security.files.user-selected.read-only</key>
	<true/>
	<key>com.apple.security.network.client</key>
	<true/>
	<key>com.apple.security.network.server</key>
	<true/>
	<key>com.apple.security.temporary-exception.mach-lookup.global-name</key>
	<array>
		<string>$(PRODUCT_BUNDLE_IDENTIFIER)-spks</string>
		<string>$(PRODUCT_BUNDLE_IDENTIFIER)-spki</string>
	</array>
	<key>keychain-access-groups</key>
	<array>
		<string>$(AppIdentifierPrefix)com.prakashjoshipax.VoiceInk</string>
	</array>
</dict>
</plist>

================
File: VoiceInk/VoiceInk.swift
================
import SwiftUI
import SwiftData
import Sparkle
import AppKit
import OSLog

@main
struct VoiceInkApp: App {
    @NSApplicationDelegateAdaptor(AppDelegate.self) var appDelegate
    let container: ModelContainer
    
    @StateObject private var whisperState: WhisperState
    @StateObject private var hotkeyManager: HotkeyManager
    @StateObject private var updaterViewModel: UpdaterViewModel
    @StateObject private var menuBarManager: MenuBarManager
    @StateObject private var aiService = AIService()
    @StateObject private var enhancementService: AIEnhancementService
    @StateObject private var activeWindowService = ActiveWindowService.shared
    @AppStorage("hasCompletedOnboarding") private var hasCompletedOnboarding = false
    
    // Audio cleanup manager for automatic deletion of old audio files
    private let audioCleanupManager = AudioCleanupManager.shared
    
    init() {
        do {
            let schema = Schema([
                Transcription.self
            ])
            
            // Create app-specific Application Support directory URL
            let appSupportURL = FileManager.default.urls(for: .applicationSupportDirectory, in: .userDomainMask)[0]
                .appendingPathComponent("com.prakashjoshipax.VoiceInk", isDirectory: true)
            
            // Create the directory if it doesn't exist
            try? FileManager.default.createDirectory(at: appSupportURL, withIntermediateDirectories: true)
            
            // Configure SwiftData to use the conventional location
            let storeURL = appSupportURL.appendingPathComponent("default.store")
            let modelConfiguration = ModelConfiguration(schema: schema, url: storeURL)
            
            container = try ModelContainer(for: schema, configurations: [modelConfiguration])
            
            // Print SwiftData storage location
            if let url = container.mainContext.container.configurations.first?.url {
                print("üíæ SwiftData storage location: \(url.path)")
            }
            
        } catch {
            fatalError("Failed to create ModelContainer for Transcription: \(error.localizedDescription)")
        }
        
        // Initialize services with proper sharing of instances
        let aiService = AIService()
        _aiService = StateObject(wrappedValue: aiService)
        
        let updaterViewModel = UpdaterViewModel()
        _updaterViewModel = StateObject(wrappedValue: updaterViewModel)
        
        let enhancementService = AIEnhancementService(aiService: aiService, modelContext: container.mainContext)
        _enhancementService = StateObject(wrappedValue: enhancementService)
        
        let whisperState = WhisperState(modelContext: container.mainContext, enhancementService: enhancementService)
        _whisperState = StateObject(wrappedValue: whisperState)
        
        let hotkeyManager = HotkeyManager(whisperState: whisperState)
        _hotkeyManager = StateObject(wrappedValue: hotkeyManager)
        
        let menuBarManager = MenuBarManager(
            updaterViewModel: updaterViewModel,
            whisperState: whisperState,
            container: container,
            enhancementService: enhancementService,
            aiService: aiService,
            hotkeyManager: hotkeyManager
        )
        _menuBarManager = StateObject(wrappedValue: menuBarManager)
        
        // Configure ActiveWindowService with enhancementService
        let activeWindowService = ActiveWindowService.shared
        activeWindowService.configure(with: enhancementService)
        _activeWindowService = StateObject(wrappedValue: activeWindowService)
    }
    
    var body: some Scene {
        WindowGroup {
            if hasCompletedOnboarding {
                ContentView()
                    .environmentObject(whisperState)
                    .environmentObject(hotkeyManager)
                    .environmentObject(updaterViewModel)
                    .environmentObject(menuBarManager)
                    .environmentObject(aiService)
                    .environmentObject(enhancementService)
                    .modelContainer(container)
                    .onAppear {
                        updaterViewModel.silentlyCheckForUpdates()
                        
                        // Start the automatic audio cleanup process
                        audioCleanupManager.startAutomaticCleanup(modelContext: container.mainContext)
                    }
                    .background(WindowAccessor { window in
                        WindowManager.shared.configureWindow(window)
                    })
                    .onDisappear {
                        whisperState.unloadModel()
                        
                        // Stop the automatic audio cleanup process
                        audioCleanupManager.stopAutomaticCleanup()
                    }
            } else {
                OnboardingView(hasCompletedOnboarding: $hasCompletedOnboarding)
                    .environmentObject(hotkeyManager)
                    .environmentObject(whisperState)
                    .environmentObject(aiService)
                    .environmentObject(enhancementService)
                    .frame(minWidth: 1200, minHeight: 800)
                   
            }
        }
        .commands {
            CommandGroup(after: .appInfo) {
                CheckForUpdatesView(updaterViewModel: updaterViewModel)
            }
        }
        
        MenuBarExtra {
            MenuBarView()
                .environmentObject(whisperState)
                .environmentObject(hotkeyManager)
                .environmentObject(menuBarManager)
                .environmentObject(updaterViewModel)
                .environmentObject(aiService)
                .environmentObject(enhancementService)
        } label: {
            let image: NSImage = {
                let ratio = $0.size.height / $0.size.width
                $0.size.height = 22
                $0.size.width = 22 / ratio
                return $0
            }(NSImage(named: "menuBarIcon")!)

            Image(nsImage: image)
        }
        .menuBarExtraStyle(.menu)
        
        #if DEBUG
        WindowGroup("Debug") {
            Button("Toggle Menu Bar Only") {
                menuBarManager.isMenuBarOnly.toggle()
            }
        }
        #endif
    }
}

class UpdaterViewModel: ObservableObject {
    private let updaterController: SPUStandardUpdaterController
    
    @Published var canCheckForUpdates = false
    
    init() {
        updaterController = SPUStandardUpdaterController(startingUpdater: true, updaterDelegate: nil, userDriverDelegate: nil)
        
        // Enable automatic update checking
        updaterController.updater.automaticallyChecksForUpdates = true
        updaterController.updater.updateCheckInterval = 24 * 60 * 60
        
        updaterController.updater.publisher(for: \.canCheckForUpdates)
            .assign(to: &$canCheckForUpdates)
    }
    
    func checkForUpdates() {
        // This is for manual checks - will show UI
        updaterController.checkForUpdates(nil)
    }
    
    func silentlyCheckForUpdates() {
        // This checks for updates in the background without showing UI unless an update is found
        updaterController.updater.checkForUpdatesInBackground()
    }
}

struct CheckForUpdatesView: View {
    @ObservedObject var updaterViewModel: UpdaterViewModel
    
    var body: some View {
        Button("Check for Updates‚Ä¶", action: updaterViewModel.checkForUpdates)
            .disabled(!updaterViewModel.canCheckForUpdates)
    }
}

struct WindowAccessor: NSViewRepresentable {
    let callback: (NSWindow) -> Void
    
    func makeNSView(context: Context) -> NSView {
        let view = NSView()
        DispatchQueue.main.async {
            if let window = view.window {
                callback(window)
            }
        }
        return view
    }
    
    func updateNSView(_ nsView: NSView, context: Context) {}
}

================
File: VoiceInk/WindowManager.swift
================
import SwiftUI
import AppKit

class WindowManager {
    static let shared = WindowManager()
    
    private init() {}
    
    func configureWindow(_ window: NSWindow) {
        window.titlebarAppearsTransparent = true
        window.titleVisibility = .hidden
        window.styleMask.insert(.fullSizeContentView)
        window.backgroundColor = .windowBackgroundColor
        window.isReleasedWhenClosed = false
        window.title = "VoiceInk"
        
        // Add additional window configuration for better state management
        window.collectionBehavior = [.fullScreenPrimary]
        
        // Ensure proper window level and ordering
        window.level = .normal
        window.orderFrontRegardless()
    }
    
    func createMainWindow(contentView: NSView) -> NSWindow {
        // Use a standard size that fits well on most displays
        let defaultSize = NSSize(width: 1200, height: 800)
        
        // Get the main screen frame to help with centering
        let screenFrame = NSScreen.main?.visibleFrame ?? NSRect(x: 0, y: 0, width: 1200, height: 800)
        
        // Create window with centered position
        let xPosition = (screenFrame.width - defaultSize.width) / 2 + screenFrame.minX
        let yPosition = (screenFrame.height - defaultSize.height) / 2 + screenFrame.minY
        
        let window = NSWindow(
            contentRect: NSRect(x: xPosition, y: yPosition, width: defaultSize.width, height: defaultSize.height),
            styleMask: [.titled, .closable, .miniaturizable, .resizable, .fullSizeContentView],
            backing: .buffered,
            defer: false
        )
        
        configureWindow(window)
        window.contentView = contentView
        
        // Set up window delegate to handle window state changes
        let delegate = WindowStateDelegate()
        window.delegate = delegate
        
        return window
    }
}

// Add window delegate to handle window state changes
class WindowStateDelegate: NSObject, NSWindowDelegate {
    func windowWillClose(_ notification: Notification) {
        guard let window = notification.object as? NSWindow else { return }
        // Ensure window is properly hidden when closed
        window.orderOut(nil)
    }
    
    func windowDidBecomeKey(_ notification: Notification) {
        // Ensure window is properly activated
        guard let window = notification.object as? NSWindow else { return }
        NSApp.activate(ignoringOtherApps: true)
    }
}

================
File: VoiceInk.xcodeproj/project.xcworkspace/xcshareddata/swiftpm/Package.resolved
================
{
  "object": {
    "pins": [
      {
        "package": "KeyboardShortcuts",
        "repositoryURL": "https://github.com/sindresorhus/KeyboardShortcuts",
        "state": {
          "branch": null,
          "revision": "7ecc38bb6edf7d087d30e737057b8d8a9b7f51eb",
          "version": "2.2.4"
        }
      },
      {
        "package": "LaunchAtLogin",
        "repositoryURL": "https://github.com/sindresorhus/LaunchAtLogin-Modern",
        "state": {
          "branch": "main",
          "revision": "a04ec1c363be3627734f6dad757d82f5d4fa8fcc",
          "version": null
        }
      },
      {
        "package": "Sparkle",
        "repositoryURL": "https://github.com/sparkle-project/Sparkle",
        "state": {
          "branch": null,
          "revision": "0ef1ee0220239b3776f433314515fd849025673f",
          "version": "2.6.4"
        }
      }
    ]
  },
  "version": 1
}

================
File: VoiceInk.xcodeproj/project.xcworkspace/xcshareddata/IDEWorkspaceChecks.plist
================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>IDEDidComputeMac32BitWarning</key>
	<true/>
</dict>
</plist>

================
File: VoiceInk.xcodeproj/project.xcworkspace/contents.xcworkspacedata
================
<?xml version="1.0" encoding="UTF-8"?>
<Workspace
   version = "1.0">
   <FileRef
      location = "self:">
   </FileRef>
</Workspace>

================
File: VoiceInk.xcodeproj/project.pbxproj
================
// !$*UTF8*$!
{
	archiveVersion = 1;
	classes = {
	};
	objectVersion = 56;
	objects = {

/* Begin PBXBuildFile section */
		E1A261122CC143AC00B233D1 /* KeyboardShortcuts in Frameworks */ = {isa = PBXBuildFile; productRef = E1A261112CC143AC00B233D1 /* KeyboardShortcuts */; };
		E1ADD45A2CC5352A00303ECB /* LaunchAtLogin in Frameworks */ = {isa = PBXBuildFile; productRef = E1ADD4592CC5352A00303ECB /* LaunchAtLogin */; };
		E1ADD45F2CC544F100303ECB /* Sparkle in Frameworks */ = {isa = PBXBuildFile; productRef = E1ADD45E2CC544F100303ECB /* Sparkle */; };
		E1B1FDBE2D8C403100ADD08E /* whisper.xcframework in Frameworks */ = {isa = PBXBuildFile; fileRef = E1B1FDBD2D8C403100ADD08E /* whisper.xcframework */; };
		E1B1FDBF2D8C403100ADD08E /* whisper.xcframework in Embed Frameworks */ = {isa = PBXBuildFile; fileRef = E1B1FDBD2D8C403100ADD08E /* whisper.xcframework */; settings = {ATTRIBUTES = (CodeSignOnCopy, RemoveHeadersOnCopy, ); }; };
/* End PBXBuildFile section */

/* Begin PBXContainerItemProxy section */
		E11473C42CBE0F0B00318EE4 /* PBXContainerItemProxy */ = {
			isa = PBXContainerItemProxy;
			containerPortal = E11473A82CBE0F0A00318EE4 /* Project object */;
			proxyType = 1;
			remoteGlobalIDString = E11473AF2CBE0F0A00318EE4;
			remoteInfo = VoiceInk;
		};
		E11473CE2CBE0F0B00318EE4 /* PBXContainerItemProxy */ = {
			isa = PBXContainerItemProxy;
			containerPortal = E11473A82CBE0F0A00318EE4 /* Project object */;
			proxyType = 1;
			remoteGlobalIDString = E11473AF2CBE0F0A00318EE4;
			remoteInfo = VoiceInk;
		};
/* End PBXContainerItemProxy section */

/* Begin PBXCopyFilesBuildPhase section */
		E1B1FDC02D8C403100ADD08E /* Embed Frameworks */ = {
			isa = PBXCopyFilesBuildPhase;
			buildActionMask = 2147483647;
			dstPath = "";
			dstSubfolderSpec = 10;
			files = (
				E1B1FDBF2D8C403100ADD08E /* whisper.xcframework in Embed Frameworks */,
			);
			name = "Embed Frameworks";
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXCopyFilesBuildPhase section */

/* Begin PBXFileReference section */
		E11473B02CBE0F0A00318EE4 /* VoiceInk.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = VoiceInk.app; sourceTree = BUILT_PRODUCTS_DIR; };
		E11473C32CBE0F0B00318EE4 /* VoiceInkTests.xctest */ = {isa = PBXFileReference; explicitFileType = wrapper.cfbundle; includeInIndex = 0; path = VoiceInkTests.xctest; sourceTree = BUILT_PRODUCTS_DIR; };
		E11473CD2CBE0F0B00318EE4 /* VoiceInkUITests.xctest */ = {isa = PBXFileReference; explicitFileType = wrapper.cfbundle; includeInIndex = 0; path = VoiceInkUITests.xctest; sourceTree = BUILT_PRODUCTS_DIR; };
		E1B1FDBD2D8C403100ADD08E /* whisper.xcframework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.xcframework; name = whisper.xcframework; path = "../../whisper.cpp/build-apple/whisper.xcframework"; sourceTree = "<group>"; };
/* End PBXFileReference section */

/* Begin PBXFileSystemSynchronizedRootGroup section */
		E11473B22CBE0F0A00318EE4 /* VoiceInk */ = {
			isa = PBXGroup;
			path = VoiceInk;
			sourceTree = "<group>";
		};
		E11473C62CBE0F0B00318EE4 /* VoiceInkTests */ = {
			isa = PBXGroup;
			path = VoiceInkTests;
			sourceTree = "<group>";
		};
		E11473D02CBE0F0B00318EE4 /* VoiceInkUITests */ = {
			isa = PBXGroup;
			path = VoiceInkUITests;
			sourceTree = "<group>";
		};
/* End PBXFileSystemSynchronizedRootGroup section */

/* Begin PBXFrameworksBuildPhase section */
		E11473AD2CBE0F0A00318EE4 /* Frameworks */ = {
			isa = PBXFrameworksBuildPhase;
			buildActionMask = 2147483647;
			files = (
				E1B1FDBE2D8C403100ADD08E /* whisper.xcframework in Frameworks */,
				E1ADD45A2CC5352A00303ECB /* LaunchAtLogin in Frameworks */,
				E1ADD45F2CC544F100303ECB /* Sparkle in Frameworks */,
				E1A261122CC143AC00B233D1 /* KeyboardShortcuts in Frameworks */,
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
		E11473C02CBE0F0B00318EE4 /* Frameworks */ = {
			isa = PBXFrameworksBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
		E11473CA2CBE0F0B00318EE4 /* Frameworks */ = {
			isa = PBXFrameworksBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXFrameworksBuildPhase section */

/* Begin PBXGroup section */
		E11473A72CBE0F0A00318EE4 = {
			isa = PBXGroup;
			children = (
				E11473B22CBE0F0A00318EE4 /* VoiceInk */,
				E11473C62CBE0F0B00318EE4 /* VoiceInkTests */,
				E11473D02CBE0F0B00318EE4 /* VoiceInkUITests */,
				E114741C2CBE1DE200318EE4 /* Frameworks */,
				E11473B12CBE0F0A00318EE4 /* Products */,
			);
			sourceTree = "<group>";
		};
		E11473B12CBE0F0A00318EE4 /* Products */ = {
			isa = PBXGroup;
			children = (
				E11473B02CBE0F0A00318EE4 /* VoiceInk.app */,
				E11473C32CBE0F0B00318EE4 /* VoiceInkTests.xctest */,
				E11473CD2CBE0F0B00318EE4 /* VoiceInkUITests.xctest */,
			);
			name = Products;
			sourceTree = "<group>";
		};
		E114741C2CBE1DE200318EE4 /* Frameworks */ = {
			isa = PBXGroup;
			children = (
				E1B1FDBD2D8C403100ADD08E /* whisper.xcframework */,
			);
			name = Frameworks;
			sourceTree = "<group>";
		};
/* End PBXGroup section */

/* Begin PBXNativeTarget section */
		E11473AF2CBE0F0A00318EE4 /* VoiceInk */ = {
			isa = PBXNativeTarget;
			buildConfigurationList = E11473D72CBE0F0B00318EE4 /* Build configuration list for PBXNativeTarget "VoiceInk" */;
			buildPhases = (
				E11473AC2CBE0F0A00318EE4 /* Sources */,
				E11473AD2CBE0F0A00318EE4 /* Frameworks */,
				E11473AE2CBE0F0A00318EE4 /* Resources */,
				E1B1FDC02D8C403100ADD08E /* Embed Frameworks */,
			);
			buildRules = (
			);
			dependencies = (
			);
			name = VoiceInk;
			packageProductDependencies = (
				E1A261112CC143AC00B233D1 /* KeyboardShortcuts */,
				E1ADD4592CC5352A00303ECB /* LaunchAtLogin */,
				E1ADD45E2CC544F100303ECB /* Sparkle */,
			);
			productName = VoiceInk;
			productReference = E11473B02CBE0F0A00318EE4 /* VoiceInk.app */;
			productType = "com.apple.product-type.application";
		};
		E11473C22CBE0F0B00318EE4 /* VoiceInkTests */ = {
			isa = PBXNativeTarget;
			buildConfigurationList = E11473DA2CBE0F0B00318EE4 /* Build configuration list for PBXNativeTarget "VoiceInkTests" */;
			buildPhases = (
				E11473BF2CBE0F0B00318EE4 /* Sources */,
				E11473C02CBE0F0B00318EE4 /* Frameworks */,
				E11473C12CBE0F0B00318EE4 /* Resources */,
			);
			buildRules = (
			);
			dependencies = (
				E11473C52CBE0F0B00318EE4 /* PBXTargetDependency */,
			);
			name = VoiceInkTests;
			packageProductDependencies = (
			);
			productName = VoiceInkTests;
			productReference = E11473C32CBE0F0B00318EE4 /* VoiceInkTests.xctest */;
			productType = "com.apple.product-type.bundle.unit-test";
		};
		E11473CC2CBE0F0B00318EE4 /* VoiceInkUITests */ = {
			isa = PBXNativeTarget;
			buildConfigurationList = E11473DD2CBE0F0B00318EE4 /* Build configuration list for PBXNativeTarget "VoiceInkUITests" */;
			buildPhases = (
				E11473C92CBE0F0B00318EE4 /* Sources */,
				E11473CA2CBE0F0B00318EE4 /* Frameworks */,
				E11473CB2CBE0F0B00318EE4 /* Resources */,
			);
			buildRules = (
			);
			dependencies = (
				E11473CF2CBE0F0B00318EE4 /* PBXTargetDependency */,
			);
			name = VoiceInkUITests;
			packageProductDependencies = (
			);
			productName = VoiceInkUITests;
			productReference = E11473CD2CBE0F0B00318EE4 /* VoiceInkUITests.xctest */;
			productType = "com.apple.product-type.bundle.ui-testing";
		};
/* End PBXNativeTarget section */

/* Begin PBXProject section */
		E11473A82CBE0F0A00318EE4 /* Project object */ = {
			isa = PBXProject;
			attributes = {
				BuildIndependentTargetsInParallel = 1;
				LastSwiftUpdateCheck = 1600;
				LastUpgradeCheck = 1540;
				TargetAttributes = {
					E11473AF2CBE0F0A00318EE4 = {
						CreatedOnToolsVersion = 16.0;
					};
					E11473C22CBE0F0B00318EE4 = {
						CreatedOnToolsVersion = 16.0;
						TestTargetID = E11473AF2CBE0F0A00318EE4;
					};
					E11473CC2CBE0F0B00318EE4 = {
						CreatedOnToolsVersion = 16.0;
						TestTargetID = E11473AF2CBE0F0A00318EE4;
					};
				};
			};
			buildConfigurationList = E11473AB2CBE0F0A00318EE4 /* Build configuration list for PBXProject "VoiceInk" */;
			developmentRegion = en;
			hasScannedForEncodings = 0;
			knownRegions = (
				en,
				Base,
			);
			mainGroup = E11473A72CBE0F0A00318EE4;
			minimizedProjectReferenceProxies = 1;
			packageReferences = (
				E1A261102CC143AC00B233D1 /* XCRemoteSwiftPackageReference "KeyboardShortcuts" */,
				E1ADD4582CC5352A00303ECB /* XCRemoteSwiftPackageReference "LaunchAtLogin-Modern" */,
				E1ADD45D2CC544F100303ECB /* XCRemoteSwiftPackageReference "Sparkle" */,
			);
			preferredProjectObjectVersion = 56;
			productRefGroup = E11473B12CBE0F0A00318EE4 /* Products */;
			projectDirPath = "";
			projectRoot = "";
			targets = (
				E11473AF2CBE0F0A00318EE4 /* VoiceInk */,
				E11473C22CBE0F0B00318EE4 /* VoiceInkTests */,
				E11473CC2CBE0F0B00318EE4 /* VoiceInkUITests */,
			);
		};
/* End PBXProject section */

/* Begin PBXResourcesBuildPhase section */
		E11473AE2CBE0F0A00318EE4 /* Resources */ = {
			isa = PBXResourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
		E11473C12CBE0F0B00318EE4 /* Resources */ = {
			isa = PBXResourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
		E11473CB2CBE0F0B00318EE4 /* Resources */ = {
			isa = PBXResourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXResourcesBuildPhase section */

/* Begin PBXSourcesBuildPhase section */
		E11473AC2CBE0F0A00318EE4 /* Sources */ = {
			isa = PBXSourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
		E11473BF2CBE0F0B00318EE4 /* Sources */ = {
			isa = PBXSourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
		E11473C92CBE0F0B00318EE4 /* Sources */ = {
			isa = PBXSourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXSourcesBuildPhase section */

/* Begin PBXTargetDependency section */
		E11473C52CBE0F0B00318EE4 /* PBXTargetDependency */ = {
			isa = PBXTargetDependency;
			target = E11473AF2CBE0F0A00318EE4 /* VoiceInk */;
			targetProxy = E11473C42CBE0F0B00318EE4 /* PBXContainerItemProxy */;
		};
		E11473CF2CBE0F0B00318EE4 /* PBXTargetDependency */ = {
			isa = PBXTargetDependency;
			target = E11473AF2CBE0F0A00318EE4 /* VoiceInk */;
			targetProxy = E11473CE2CBE0F0B00318EE4 /* PBXContainerItemProxy */;
		};
/* End PBXTargetDependency section */

/* Begin XCBuildConfiguration section */
		E11473D52CBE0F0B00318EE4 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ALWAYS_SEARCH_USER_PATHS = NO;
				ASSETCATALOG_COMPILER_GENERATE_SWIFT_ASSET_SYMBOL_EXTENSIONS = YES;
				CLANG_ANALYZER_NONNULL = YES;
				CLANG_ANALYZER_NUMBER_OBJECT_CONVERSION = YES_AGGRESSIVE;
				CLANG_CXX_LANGUAGE_STANDARD = "gnu++20";
				CLANG_ENABLE_MODULES = YES;
				CLANG_ENABLE_OBJC_ARC = YES;
				CLANG_ENABLE_OBJC_WEAK = YES;
				CLANG_WARN_BLOCK_CAPTURE_AUTORELEASING = YES;
				CLANG_WARN_BOOL_CONVERSION = YES;
				CLANG_WARN_COMMA = YES;
				CLANG_WARN_CONSTANT_CONVERSION = YES;
				CLANG_WARN_DEPRECATED_OBJC_IMPLEMENTATIONS = YES;
				CLANG_WARN_DIRECT_OBJC_ISA_USAGE = YES_ERROR;
				CLANG_WARN_DOCUMENTATION_COMMENTS = YES;
				CLANG_WARN_EMPTY_BODY = YES;
				CLANG_WARN_ENUM_CONVERSION = YES;
				CLANG_WARN_INFINITE_RECURSION = YES;
				CLANG_WARN_INT_CONVERSION = YES;
				CLANG_WARN_NON_LITERAL_NULL_CONVERSION = YES;
				CLANG_WARN_OBJC_IMPLICIT_RETAIN_SELF = YES;
				CLANG_WARN_OBJC_LITERAL_CONVERSION = YES;
				CLANG_WARN_OBJC_ROOT_CLASS = YES_ERROR;
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = YES;
				CLANG_WARN_RANGE_LOOP_ANALYSIS = YES;
				CLANG_WARN_STRICT_PROTOTYPES = YES;
				CLANG_WARN_SUSPICIOUS_MOVE = YES;
				CLANG_WARN_UNGUARDED_AVAILABILITY = YES_AGGRESSIVE;
				CLANG_WARN_UNREACHABLE_CODE = YES;
				CLANG_WARN__DUPLICATE_METHOD_MATCH = YES;
				COPY_PHASE_STRIP = NO;
				DEBUG_INFORMATION_FORMAT = dwarf;
				ENABLE_STRICT_OBJC_MSGSEND = YES;
				ENABLE_TESTABILITY = YES;
				ENABLE_USER_SCRIPT_SANDBOXING = YES;
				GCC_C_LANGUAGE_STANDARD = gnu17;
				GCC_DYNAMIC_NO_PIC = NO;
				GCC_NO_COMMON_BLOCKS = YES;
				GCC_OPTIMIZATION_LEVEL = 0;
				GCC_PREPROCESSOR_DEFINITIONS = (
					"DEBUG=1",
					"$(inherited)",
				);
				GCC_WARN_64_TO_32_BIT_CONVERSION = YES;
				GCC_WARN_ABOUT_RETURN_TYPE = YES_ERROR;
				GCC_WARN_UNDECLARED_SELECTOR = YES;
				GCC_WARN_UNINITIALIZED_AUTOS = YES_AGGRESSIVE;
				GCC_WARN_UNUSED_FUNCTION = YES;
				GCC_WARN_UNUSED_VARIABLE = YES;
				LOCALIZATION_PREFERS_STRING_CATALOGS = YES;
				MACOSX_DEPLOYMENT_TARGET = 15.0;
				MTL_ENABLE_DEBUG_INFO = INCLUDE_SOURCE;
				MTL_FAST_MATH = YES;
				ONLY_ACTIVE_ARCH = YES;
				SDKROOT = macosx;
				SWIFT_ACTIVE_COMPILATION_CONDITIONS = "DEBUG $(inherited)";
				SWIFT_OPTIMIZATION_LEVEL = "-Onone";
			};
			name = Debug;
		};
		E11473D62CBE0F0B00318EE4 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ALWAYS_SEARCH_USER_PATHS = NO;
				ASSETCATALOG_COMPILER_GENERATE_SWIFT_ASSET_SYMBOL_EXTENSIONS = YES;
				CLANG_ANALYZER_NONNULL = YES;
				CLANG_ANALYZER_NUMBER_OBJECT_CONVERSION = YES_AGGRESSIVE;
				CLANG_CXX_LANGUAGE_STANDARD = "gnu++20";
				CLANG_ENABLE_MODULES = YES;
				CLANG_ENABLE_OBJC_ARC = YES;
				CLANG_ENABLE_OBJC_WEAK = YES;
				CLANG_WARN_BLOCK_CAPTURE_AUTORELEASING = YES;
				CLANG_WARN_BOOL_CONVERSION = YES;
				CLANG_WARN_COMMA = YES;
				CLANG_WARN_CONSTANT_CONVERSION = YES;
				CLANG_WARN_DEPRECATED_OBJC_IMPLEMENTATIONS = YES;
				CLANG_WARN_DIRECT_OBJC_ISA_USAGE = YES_ERROR;
				CLANG_WARN_DOCUMENTATION_COMMENTS = YES;
				CLANG_WARN_EMPTY_BODY = YES;
				CLANG_WARN_ENUM_CONVERSION = YES;
				CLANG_WARN_INFINITE_RECURSION = YES;
				CLANG_WARN_INT_CONVERSION = YES;
				CLANG_WARN_NON_LITERAL_NULL_CONVERSION = YES;
				CLANG_WARN_OBJC_IMPLICIT_RETAIN_SELF = YES;
				CLANG_WARN_OBJC_LITERAL_CONVERSION = YES;
				CLANG_WARN_OBJC_ROOT_CLASS = YES_ERROR;
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = YES;
				CLANG_WARN_RANGE_LOOP_ANALYSIS = YES;
				CLANG_WARN_STRICT_PROTOTYPES = YES;
				CLANG_WARN_SUSPICIOUS_MOVE = YES;
				CLANG_WARN_UNGUARDED_AVAILABILITY = YES_AGGRESSIVE;
				CLANG_WARN_UNREACHABLE_CODE = YES;
				CLANG_WARN__DUPLICATE_METHOD_MATCH = YES;
				COPY_PHASE_STRIP = NO;
				DEBUG_INFORMATION_FORMAT = "dwarf-with-dsym";
				ENABLE_NS_ASSERTIONS = NO;
				ENABLE_STRICT_OBJC_MSGSEND = YES;
				ENABLE_USER_SCRIPT_SANDBOXING = YES;
				GCC_C_LANGUAGE_STANDARD = gnu17;
				GCC_NO_COMMON_BLOCKS = YES;
				GCC_WARN_64_TO_32_BIT_CONVERSION = YES;
				GCC_WARN_ABOUT_RETURN_TYPE = YES_ERROR;
				GCC_WARN_UNDECLARED_SELECTOR = YES;
				GCC_WARN_UNINITIALIZED_AUTOS = YES_AGGRESSIVE;
				GCC_WARN_UNUSED_FUNCTION = YES;
				GCC_WARN_UNUSED_VARIABLE = YES;
				LOCALIZATION_PREFERS_STRING_CATALOGS = YES;
				MACOSX_DEPLOYMENT_TARGET = 15.0;
				MTL_ENABLE_DEBUG_INFO = NO;
				MTL_FAST_MATH = YES;
				SDKROOT = macosx;
				SWIFT_COMPILATION_MODE = wholemodule;
			};
			name = Release;
		};
		E11473D82CBE0F0B00318EE4 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ARCHS = "$(ARCHS_STANDARD)";
				ASSETCATALOG_COMPILER_APPICON_NAME = AppIcon;
				ASSETCATALOG_COMPILER_GLOBAL_ACCENT_COLOR_NAME = AccentColor;
				CODE_SIGN_ENTITLEMENTS = VoiceInk/VoiceInk.entitlements;
				"CODE_SIGN_IDENTITY[sdk=macosx*]" = "Apple Development";
				CODE_SIGN_STYLE = Automatic;
				COMBINE_HIDPI_IMAGES = YES;
				CURRENT_PROJECT_VERSION = 114;
				DEVELOPMENT_ASSET_PATHS = "\"VoiceInk/Preview Content\"";
				DEVELOPMENT_TEAM = V6J6A3VWY2;
				ENABLE_HARDENED_RUNTIME = YES;
				ENABLE_PREVIEWS = YES;
				GENERATE_INFOPLIST_FILE = YES;
				INFOPLIST_FILE = VoiceInk/Info.plist;
				INFOPLIST_KEY_CFBundleDisplayName = VoiceInk;
				INFOPLIST_KEY_LSApplicationCategoryType = "public.app-category.productivity";
				INFOPLIST_KEY_NSHumanReadableCopyright = "";
				LD_RUNPATH_SEARCH_PATHS = (
					"$(inherited)",
					"@executable_path/../Frameworks",
				);
				MACOSX_DEPLOYMENT_TARGET = 14.0;
				MARKETING_VERSION = 1.14;
				PRODUCT_BUNDLE_IDENTIFIER = com.prakashjoshipax.VoiceInk;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SWIFT_EMIT_LOC_STRINGS = YES;
				SWIFT_VERSION = 5.0;
			};
			name = Debug;
		};
		E11473D92CBE0F0B00318EE4 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ARCHS = "$(ARCHS_STANDARD)";
				ASSETCATALOG_COMPILER_APPICON_NAME = AppIcon;
				ASSETCATALOG_COMPILER_GLOBAL_ACCENT_COLOR_NAME = AccentColor;
				CODE_SIGN_ENTITLEMENTS = VoiceInk/VoiceInk.entitlements;
				"CODE_SIGN_IDENTITY[sdk=macosx*]" = "Apple Development";
				CODE_SIGN_STYLE = Automatic;
				COMBINE_HIDPI_IMAGES = YES;
				CURRENT_PROJECT_VERSION = 114;
				DEVELOPMENT_ASSET_PATHS = "\"VoiceInk/Preview Content\"";
				DEVELOPMENT_TEAM = V6J6A3VWY2;
				ENABLE_HARDENED_RUNTIME = YES;
				ENABLE_PREVIEWS = YES;
				GENERATE_INFOPLIST_FILE = YES;
				INFOPLIST_FILE = VoiceInk/Info.plist;
				INFOPLIST_KEY_CFBundleDisplayName = VoiceInk;
				INFOPLIST_KEY_LSApplicationCategoryType = "public.app-category.productivity";
				INFOPLIST_KEY_NSHumanReadableCopyright = "";
				LD_RUNPATH_SEARCH_PATHS = (
					"$(inherited)",
					"@executable_path/../Frameworks",
				);
				MACOSX_DEPLOYMENT_TARGET = 14.0;
				MARKETING_VERSION = 1.14;
				PRODUCT_BUNDLE_IDENTIFIER = com.prakashjoshipax.VoiceInk;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SWIFT_EMIT_LOC_STRINGS = YES;
				SWIFT_VERSION = 5.0;
			};
			name = Release;
		};
		E11473DB2CBE0F0B00318EE4 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				BUNDLE_LOADER = "$(TEST_HOST)";
				CODE_SIGN_STYLE = Automatic;
				CURRENT_PROJECT_VERSION = 1;
				DEVELOPMENT_TEAM = V6J6A3VWY2;
				GENERATE_INFOPLIST_FILE = YES;
				MACOSX_DEPLOYMENT_TARGET = 14.0;
				MARKETING_VERSION = 1.0;
				PRODUCT_BUNDLE_IDENTIFIER = com.prakashjoshipax.VoiceInkTests;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SWIFT_EMIT_LOC_STRINGS = NO;
				SWIFT_VERSION = 5.0;
				TEST_HOST = "$(BUILT_PRODUCTS_DIR)/VoiceInk.app/$(BUNDLE_EXECUTABLE_FOLDER_PATH)/VoiceInk";
			};
			name = Debug;
		};
		E11473DC2CBE0F0B00318EE4 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				BUNDLE_LOADER = "$(TEST_HOST)";
				CODE_SIGN_STYLE = Automatic;
				CURRENT_PROJECT_VERSION = 1;
				DEVELOPMENT_TEAM = V6J6A3VWY2;
				GENERATE_INFOPLIST_FILE = YES;
				MACOSX_DEPLOYMENT_TARGET = 14.0;
				MARKETING_VERSION = 1.0;
				PRODUCT_BUNDLE_IDENTIFIER = com.prakashjoshipax.VoiceInkTests;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SWIFT_EMIT_LOC_STRINGS = NO;
				SWIFT_VERSION = 5.0;
				TEST_HOST = "$(BUILT_PRODUCTS_DIR)/VoiceInk.app/$(BUNDLE_EXECUTABLE_FOLDER_PATH)/VoiceInk";
			};
			name = Release;
		};
		E11473DE2CBE0F0B00318EE4 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				CODE_SIGN_STYLE = Automatic;
				CURRENT_PROJECT_VERSION = 1;
				DEVELOPMENT_TEAM = V6J6A3VWY2;
				GENERATE_INFOPLIST_FILE = YES;
				MARKETING_VERSION = 1.0;
				PRODUCT_BUNDLE_IDENTIFIER = com.prakashjoshipax.VoiceInkUITests;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SWIFT_EMIT_LOC_STRINGS = NO;
				SWIFT_VERSION = 5.0;
				TEST_TARGET_NAME = VoiceInk;
			};
			name = Debug;
		};
		E11473DF2CBE0F0B00318EE4 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				CODE_SIGN_STYLE = Automatic;
				CURRENT_PROJECT_VERSION = 1;
				DEVELOPMENT_TEAM = V6J6A3VWY2;
				GENERATE_INFOPLIST_FILE = YES;
				MARKETING_VERSION = 1.0;
				PRODUCT_BUNDLE_IDENTIFIER = com.prakashjoshipax.VoiceInkUITests;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SWIFT_EMIT_LOC_STRINGS = NO;
				SWIFT_VERSION = 5.0;
				TEST_TARGET_NAME = VoiceInk;
			};
			name = Release;
		};
/* End XCBuildConfiguration section */

/* Begin XCConfigurationList section */
		E11473AB2CBE0F0A00318EE4 /* Build configuration list for PBXProject "VoiceInk" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				E11473D52CBE0F0B00318EE4 /* Debug */,
				E11473D62CBE0F0B00318EE4 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
		E11473D72CBE0F0B00318EE4 /* Build configuration list for PBXNativeTarget "VoiceInk" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				E11473D82CBE0F0B00318EE4 /* Debug */,
				E11473D92CBE0F0B00318EE4 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
		E11473DA2CBE0F0B00318EE4 /* Build configuration list for PBXNativeTarget "VoiceInkTests" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				E11473DB2CBE0F0B00318EE4 /* Debug */,
				E11473DC2CBE0F0B00318EE4 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
		E11473DD2CBE0F0B00318EE4 /* Build configuration list for PBXNativeTarget "VoiceInkUITests" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				E11473DE2CBE0F0B00318EE4 /* Debug */,
				E11473DF2CBE0F0B00318EE4 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
/* End XCConfigurationList section */

/* Begin XCRemoteSwiftPackageReference section */
		E1A261102CC143AC00B233D1 /* XCRemoteSwiftPackageReference "KeyboardShortcuts" */ = {
			isa = XCRemoteSwiftPackageReference;
			repositoryURL = "https://github.com/sindresorhus/KeyboardShortcuts";
			requirement = {
				kind = upToNextMajorVersion;
				minimumVersion = 2.2.0;
			};
		};
		E1ADD4582CC5352A00303ECB /* XCRemoteSwiftPackageReference "LaunchAtLogin-Modern" */ = {
			isa = XCRemoteSwiftPackageReference;
			repositoryURL = "https://github.com/sindresorhus/LaunchAtLogin-Modern";
			requirement = {
				branch = main;
				kind = branch;
			};
		};
		E1ADD45D2CC544F100303ECB /* XCRemoteSwiftPackageReference "Sparkle" */ = {
			isa = XCRemoteSwiftPackageReference;
			repositoryURL = "https://github.com/sparkle-project/Sparkle";
			requirement = {
				kind = upToNextMajorVersion;
				minimumVersion = 2.6.4;
			};
		};
/* End XCRemoteSwiftPackageReference section */

/* Begin XCSwiftPackageProductDependency section */
		E1A261112CC143AC00B233D1 /* KeyboardShortcuts */ = {
			isa = XCSwiftPackageProductDependency;
			package = E1A261102CC143AC00B233D1 /* XCRemoteSwiftPackageReference "KeyboardShortcuts" */;
			productName = KeyboardShortcuts;
		};
		E1ADD4592CC5352A00303ECB /* LaunchAtLogin */ = {
			isa = XCSwiftPackageProductDependency;
			package = E1ADD4582CC5352A00303ECB /* XCRemoteSwiftPackageReference "LaunchAtLogin-Modern" */;
			productName = LaunchAtLogin;
		};
		E1ADD45E2CC544F100303ECB /* Sparkle */ = {
			isa = XCSwiftPackageProductDependency;
			package = E1ADD45D2CC544F100303ECB /* XCRemoteSwiftPackageReference "Sparkle" */;
			productName = Sparkle;
		};
/* End XCSwiftPackageProductDependency section */
	};
	rootObject = E11473A82CBE0F0A00318EE4 /* Project object */;
}

================
File: VoiceInkTests/VoiceInkTests.swift
================
//
//  VoiceInkTests.swift
//  VoiceInkTests
//
//  Created by Prakash Joshi on 15/10/2024.
//

import Testing
@testable import VoiceInk

struct VoiceInkTests {

    @Test func example() async throws {
        // Write your test here and use APIs like `#expect(...)` to check expected conditions.
    }

}

================
File: VoiceInkUITests/VoiceInkUITests.swift
================
//
//  VoiceInkUITests.swift
//  VoiceInkUITests
//
//  Created by Prakash Joshi on 15/10/2024.
//

import XCTest

final class VoiceInkUITests: XCTestCase {

    override func setUpWithError() throws {
        // Put setup code here. This method is called before the invocation of each test method in the class.

        // In UI tests it is usually best to stop immediately when a failure occurs.
        continueAfterFailure = false

        // In UI tests it‚Äôs important to set the initial state - such as interface orientation - required for your tests before they run. The setUp method is a good place to do this.
    }

    override func tearDownWithError() throws {
        // Put teardown code here. This method is called after the invocation of each test method in the class.
    }

    @MainActor
    func testExample() throws {
        // UI tests must launch the application that they test.
        let app = XCUIApplication()
        app.launch()

        // Use XCTAssert and related functions to verify your tests produce the correct results.
    }

    @MainActor
    func testLaunchPerformance() throws {
        if #available(macOS 10.15, iOS 13.0, tvOS 13.0, watchOS 7.0, *) {
            // This measures how long it takes to launch your application.
            measure(metrics: [XCTApplicationLaunchMetric()]) {
                XCUIApplication().launch()
            }
        }
    }
}

================
File: VoiceInkUITests/VoiceInkUITestsLaunchTests.swift
================
//
//  VoiceInkUITestsLaunchTests.swift
//  VoiceInkUITests
//
//  Created by Prakash Joshi on 15/10/2024.
//

import XCTest

final class VoiceInkUITestsLaunchTests: XCTestCase {

    override class var runsForEachTargetApplicationUIConfiguration: Bool {
        true
    }

    override func setUpWithError() throws {
        continueAfterFailure = false
    }

    @MainActor
    func testLaunch() throws {
        let app = XCUIApplication()
        app.launch()

        // Insert steps here to perform after app launch but before taking a screenshot,
        // such as logging into a test account or navigating somewhere in the app

        let attachment = XCTAttachment(screenshot: app.screenshot())
        attachment.name = "Launch Screen"
        attachment.lifetime = .keepAlways
        add(attachment)
    }
}

================
File: .gitignore
================
# Xcode
#
# gitignore contributors: remember to update Global/Xcode.gitignore, Objective-C.gitignore & Swift.gitignore

## User settings
xcuserdata/

## Obj-C/Swift specific
*.hmap

## App packaging
*.ipa
*.dSYM.zip
*.dSYM

## Playgrounds
timeline.xctimeline
playground.xcworkspace

# Swift Package Manager
#
# Add this line if you want to avoid checking in source code from Swift Package Manager dependencies.
# Packages/
# Package.pins
# Package.resolved
# *.xcodeproj
#
# Xcode automatically generates this directory with a .xcworkspacedata file and xcuserdata
# hence it is not needed unless you have added a package configuration file to your project
# .swiftpm

.build/

# CocoaPods
#
# We recommend against adding the Pods directory to your .gitignore. However
# you should judge for yourself, the pros and cons are mentioned at:
# https://guides.cocoapods.org/using/using-cocoapods.html#should-i-check-the-pods-directory-into-source-control
#
# Pods/
#
# Add this line if you want to avoid checking in source code from the Xcode workspace
# *.xcworkspace

# Carthage
#
# Add this line if you want to avoid checking in source code from Carthage dependencies.
# Carthage/Checkouts

Carthage/Build/

# Accio dependency management
Dependencies/
.accio/

# fastlane
#
# It is recommended to not store the screenshots in the git repo.
# Instead, use fastlane to re-generate the screenshots whenever they are needed.
# For more information about the recommended setup visit:
# https://docs.fastlane.tools/best-practices/source-control/#source-control

fastlane/report.xml
fastlane/Preview.html
fastlane/screenshots/**/*.png
fastlane/test_output

# Code Injection
#
# After new code Injection tools there's a generated folder /iOSInjectionProject
# https://github.com/johnno1962/injectionforxcode

iOSInjectionProject/

# macOS
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon

# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

================
File: appcast.xml
================
<?xml version="1.0" standalone="yes"?>
<rss xmlns:sparkle="http://www.andymatuschak.org/xml-namespaces/sparkle" version="2.0">
    <channel>
        <title>VoiceInk Releases</title>
        <item>
            <title>1.13</title>
            <pubDate>Thu, 18 Mar 2024 12:00:00 +0545</pubDate>
            <sparkle:version>113</sparkle:version>
            <sparkle:shortVersionString>1.13</sparkle:shortVersionString>
            <sparkle:minimumSystemVersion>14.0</sparkle:minimumSystemVersion>
            <description><![CDATA[
                    <h3>What's New in Version 1.13 üöÄ‚ö°</h3>
                        <ol>
                            <li>üéµ Support for uploading recorded audio files to transcribe</li>
                            <li>üîÑ Retranscribe audio files from transcript history incase of bad results from AI enhancement</li>
                            <li>üìù Word replacement feature works locally using regex implementation</li>
                            <li>üéØ Enhanced default prompt for better results</li>
                        </ol>
            ]]></description>
            <enclosure url="https://github.com/Beingpax/VoiceInk/releases/download/v1.13/VoiceInk.dmg" length="5878992" type="application/octet-stream" sparkle:edSignature="o2IW5QVk6UZb2nH9Tirz/zKLcCNnBpAAt4rNfdn5Fk2yvu7yJzwbLP3Awz6pCj+OQ0mEE2f/jq2WnSih5+yEBg=="/>
        </item>
    </channel>
</rss>

================
File: BUILDING.md
================
# Building VoiceInk

This guide provides detailed instructions for building VoiceInk from source.

## Prerequisites

Before you begin, ensure you have:
- macOS 14.0 or later
- Xcode (latest version recommended)
- Swift (latest version recommended)

## Building whisper.cpp Framework

1. Clone and build whisper.cpp:
```bash
git clone https://github.com/ggerganov/whisper.cpp.git
cd whisper.cpp
./build-xcframework.sh
```
This will create the XCFramework at `build-apple/whisper.xcframework`.

## Building VoiceInk

1. Clone the VoiceInk repository:
```bash
git clone https://github.com/Beingpax/VoiceInk.git
cd VoiceInk
```

2. Add the whisper.xcframework to your project:
   - Drag and drop `../whisper.cpp/build-apple/whisper.xcframework` into the project navigator, or
   - Add it manually in the "Frameworks, Libraries, and Embedded Content" section of project settings

3. Build and Run
   - Build the project using Cmd+B or Product > Build
   - Run the project using Cmd+R or Product > Run

## Development Setup

1. **Xcode Configuration**
   - Ensure you have the latest Xcode version
   - Install any required Xcode Command Line Tools

2. **Dependencies**
   - The project uses [whisper.cpp](https://github.com/ggerganov/whisper.cpp) for transcription
   - Ensure the whisper.xcframework is properly linked in your Xcode project
   - Test the whisper.cpp installation independently before proceeding

3. **Building for Development**
   - Use the Debug configuration for development
   - Enable relevant debugging options in Xcode

4. **Testing**
   - Run the test suite before making changes
   - Ensure all tests pass after your modifications

## Troubleshooting

If you encounter any build issues:
1. Clean the build folder (Cmd+Shift+K)
2. Clean the build cache (Cmd+Shift+K twice)
3. Check Xcode and macOS versions
4. Verify all dependencies are properly installed
5. Make sure whisper.xcframework is properly built and linked

For more help, please check the [issues](https://github.com/Beingpax/VoiceInk/issues) section or create a new issue.

================
File: CODE_OF_CONDUCT.md
================
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement.
All complaints will be reviewed and investigated promptly and fairly.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

[homepage]: https://www.contributor-covenant.org

================
File: CONTRIBUTING.md
================
# Contributing to VoiceInk

First off, thank you for considering contributing to VoiceInk! It's people like you that make VoiceInk such a great tool.

## Important Notice About Pull Requests

We welcome forks and improvements to VoiceInk! However, please note:

1. **The acceptance of Pull Requests is solely at the discretion of the project maintainers**
2. **Before making significant changes or starting work on major features:**
   - Open an issue to discuss your proposed changes
   - Wait for maintainer feedback and approval
   - This helps ensure your time and effort align with the project's direction
3. **For fundamental or architectural changes:**
   - Direct consultation with the maintainers is required
   - These discussions should happen before you start the implementation

This policy helps ensure:
- Your valuable time is spent on changes that align with the project's vision
- The codebase maintains its consistency and quality
- We can provide proper guidance and support for your contribution

## Important Notice

Before starting work on any new feature or fix, please reach out to us first by opening an issue or discussion. This is crucial because:

1. We want to ensure your contribution aligns with the project's goals and vision
2. Someone else might already be working on something similar
3. We might have valuable insights or requirements that could save you time
4. Your proposed changes might need some adjustments to fit with our roadmap

## Code of Conduct

By participating in this project, you agree to abide by our [Code of Conduct](CODE_OF_CONDUCT.md).

## How Can I Contribute?

### Reporting Bugs

- Before submitting a bug report, please check if the issue has already been reported
- Use the bug report template when creating an issue
- Include as much relevant information as possible
- Include steps to reproduce the issue

### Suggesting Enhancements

- Open an issue using the feature request template
- Clearly describe the feature and its benefits
- Discuss potential implementation approaches
- Consider the feature's impact on existing functionality

### Pull Requests

1. Fork the repository
2. Create a new branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Run tests and ensure they pass
5. Commit your changes (`git commit -m 'Add some amazing feature'`)
6. Push to the branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

### Development Process

1. Ensure you have all the requirements installed:
   - macOS 14.0 or later
   - Latest version of Xcode
   - Latest version of Swift
   - whisper.cpp properly set up

2. Follow our coding standards:
   - Use Swift style guidelines
   - Write meaningful commit messages
   - Include comments where necessary
   - Add tests for new features

3. Testing:
   - Run existing tests
   - Add new tests for new functionality
   - Ensure all tests pass before submitting PR

## Style Guidelines

- Follow Swift style guidelines
- Use meaningful variable and function names
- Keep functions focused and concise
- Comment complex logic
- Write self-documenting code where possible

## Community

- Join our discussions
- Help other contributors
- Share your ideas
- Be respectful and constructive

## Questions?

If you have any questions or need clarification, feel free to:
1. Open an issue
2. Start a discussion
3. Reach out to the maintainers

Thank you for contributing to VoiceInk! üéâ

================
File: LICENSE
================
GNU GENERAL PUBLIC LICENSE
                       Version 3, 29 June 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The GNU General Public License is a free, copyleft license for
software and other kinds of works.

  The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
the GNU General Public License is intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.  We, the Free Software Foundation, use the
GNU General Public License for most of our software; it applies also to
any other work released this way by its authors.  You can apply it to
your programs, too.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

[For the complete license text, please visit: https://www.gnu.org/licenses/gpl-3.0.txt]

================
File: README.md
================
<div align="center">
  <img src="VoiceInk/Assets.xcassets/AppIcon.appiconset/256-mac.png" width="180" height="180" />
  <h1>VoiceInk</h1>
  <p>Voice to text app for macOS to transcribe what you say to text almost instantly</p>

  [![License](https://img.shields.io/badge/License-GPL%20v3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
  ![Platform](https://img.shields.io/badge/platform-macOS%2014.0%2B-brightgreen)
  [![GitHub release (latest by date)](https://img.shields.io/github/v/release/Beingpax/VoiceInk)](https://github.com/Beingpax/VoiceInk/releases)
  ![GitHub all releases](https://img.shields.io/github/downloads/Beingpax/VoiceInk/total)
  ![GitHub stars](https://img.shields.io/github/stars/Beingpax/VoiceInk?style=social)
  <p>
    <a href="https://tryvoiceink.com">Website</a> ‚Ä¢
    <a href="https://www.youtube.com/@tryvoiceink">YouTube</a>
  </p>

  <a href="https://tryvoiceink.com">
    <img src="https://img.shields.io/badge/Download%20Now-Latest%20Version-blue?style=for-the-badge&logo=apple" alt="Download VoiceInk" width="250"/>
  </a>
</div>

---

VoiceInk is a native macOS application that transcribes what you say to text almost instantly. You can find all the information and download the app from [here](https://tryvoiceink.com). 

![VoiceInk Mac App](https://github.com/user-attachments/assets/12367379-83e7-48a6-b52c-4488a6a04bba)

After dedicating the past 5 months to developing this app, I've decided to open source it for the greater good. 

My goal is to make it **the most efficient and privacy-focused voice-to-text solution for macOS** that is a joy to use. While the source code is now open for experienced developers to build and contribute, purchasing a license helps support continued development and gives you access to automatic updates, priority support, and upcoming features.

## Features

- üéôÔ∏è **Accurate Transcription**: Local AI models that transcribe your voice to text with 99% accuracy, almost instantly
- üîí **Privacy First**: 100% offline processing ensures your data never leaves your device
- ‚ö° **Power Mode**: Intelligent app detection automatically applies your perfect pre-configured settings based on the app/ URL you're on
- üß† **Context Aware**: Smart AI that understands your screen content and adapts to the context
- üéØ **Global Shortcuts**: Configurable keyboard shortcuts for quick recording and push-to-talk functionality
- üìù **Personal Dictionary**: Train the AI to understand your unique terminology with custom words, industry terms, and smart text replacements
- üîÑ **Smart Modes**: Instantly switch between AI-powered modes optimized for different writing styles and contexts
- ü§ñ **AI Assistant**: Built-in voice assistant mode for a quick chatGPT like conversational assistant

## Get Started

### Download
Get the latest version with a free trial from [tryvoiceink.com](https://tryvoiceink.com). Your purchase helps me work on VoiceInk full-time and continuously improve it with new features and updates.

### Build from Source
As an open-source project, you can build VoiceInk yourself by following the instructions in [BUILDING.md](BUILDING.md). However, the compiled version includes additional benefits like automatic updates, priority support via Discord and email, and helps fund ongoing development.

## Requirements

- macOS 14.0 or later

## Documentation

- [Building from Source](BUILDING.md) - Detailed instructions for building the project
- [Contributing Guidelines](CONTRIBUTING.md) - How to contribute to VoiceInk
- [Code of Conduct](CODE_OF_CONDUCT.md) - Our community standards

## Contributing

We welcome contributions! However, please note that all contributions should align with the project's goals and vision. Before starting work on any feature or fix:

1. Read our [Contributing Guidelines](CONTRIBUTING.md)
2. Open an issue to discuss your proposed changes
3. Wait for maintainer feedback

For build instructions, see our [Building Guide](BUILDING.md).

## License

This project is licensed under the GNU General Public License v3.0 - see the [LICENSE](LICENSE) file for details.

## Support

If you encounter any issues or have questions, please:
1. Check the existing issues in the GitHub repository
2. Create a new issue if your problem isn't already reported
3. Provide as much detail as possible about your environment and the problem

## Acknowledgments

### Core Technology
- [whisper.cpp](https://github.com/ggerganov/whisper.cpp) - High-performance inference of OpenAI's Whisper model

### Essential Dependencies
- [Sparkle](https://github.com/sparkle-project/Sparkle) - Keeping VoiceInk up to date
- [KeyboardShortcuts](https://github.com/sindresorhus/KeyboardShortcuts) - User-customizable keyboard shortcuts
- [LaunchAtLogin](https://github.com/sindresorhus/LaunchAtLogin) - Launch at login functionality


---

Made with ‚ù§Ô∏è by Pax



================================================================
End of Codebase
================================================================
